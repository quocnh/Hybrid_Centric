{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import wfdb\n",
    "import datetime\n",
    "import talos \n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import ConfusionMatrixDisplay,confusion_matrix\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from kerashypetune import KerasGridSearchCV, KerasGridSearch\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "print(tf.__version__)\n",
    "seed = 42\n",
    "# test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup and load processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RR_INTERVALS_INTERPOLATION 240\n",
    "sequence_length = 240\n",
    "FS = 100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def z_norm(result):\n",
    "    result_mean = np.mean(result)\n",
    "    result_std = np.std(result)\n",
    "    result = (result - result_mean) / result_std\n",
    "    return result\n",
    "\n",
    "def split_data(X):\n",
    "    X1 = []\n",
    "    X2 = []\n",
    "    for index in range(len(X)):\n",
    "        X1.append([X[index][0], X[index][1]])\n",
    "        X2.append([X[index][2], X[index][3]])\n",
    "\n",
    "    return np.array(X1).astype('float64'), np.array(X2).astype('float64')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    X_train = np.load('new_train_input.npy', allow_pickle=True)\n",
    "    y_train = np.load('new_train_label.npy', allow_pickle=True)\n",
    "\n",
    "    X_test = np.load('new_test_input.npy', allow_pickle=True)\n",
    "    y_test = np.load('new_test_label.npy', allow_pickle=True)\n",
    "    print(\"X_train: \", X_train.shape)\n",
    "    \n",
    "    # # Load SAD dataset\n",
    "    # X_test_sad = np.load('spaches_test.npy', allow_pickle=True)\n",
    "    # y_test_sad = np.load('spaches_test_label.npy', allow_pickle=True)\n",
    "    \n",
    "    #X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "    '''\n",
    "    X_train = X_train[:, 0, :]\n",
    "    X_test = X_test[:, 0, :]\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "    '''\n",
    "    #X_train1 shape (number_of_independent_sequences, length_or_steps_of_a_sequence, variables_or_features_per_step)\n",
    "    X_train1, X_train2 = split_data(X_train)\n",
    "    X_test1, X_test2 = split_data(X_test)\n",
    "\n",
    "    print(\"X_train1: \", X_train1.shape)\n",
    "    \n",
    "    X_train1 = np.transpose(X_train1, (0, 2, 1))\n",
    "    print(\"X_train1 transpose: \", X_train1.shape)\n",
    "  \n",
    "    X_train2 = np.reshape(X_train2, (X_train2.shape[0], X_train2.shape[1], 1))\n",
    "    print(\"X_train2: \", X_train2.shape)\n",
    "   \n",
    "    X_test1 = np.transpose(X_test1, (0, 2, 1))\n",
    "   \n",
    "    X_test2 = np.reshape(X_test2, (X_test2.shape[0], X_test2.shape[1], 1))\n",
    "\n",
    "    return X_train1, X_train2, y_train, X_test1, X_test2, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  (28233, 4)\n",
      "X_train1:  (28233, 2, 240)\n",
      "X_train1 transpose:  (28233, 240, 2)\n",
      "X_train2:  (28233, 2, 1)\n",
      "(28233, 240, 2)\n",
      "(28233, 2, 1)\n",
      "(4960, 240, 2)\n",
      "(4960, 2, 1)\n",
      "(28233,)\n",
      "(4960,)\n",
      "[[[51.]\n",
      "  [ 1.]]\n",
      "\n",
      " [[51.]\n",
      "  [ 1.]]\n",
      "\n",
      " [[51.]\n",
      "  [ 1.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[55.]\n",
      "  [ 1.]]\n",
      "\n",
      " [[55.]\n",
      "  [ 1.]]\n",
      "\n",
      " [[55.]\n",
      "  [ 1.]]]\n"
     ]
    }
   ],
   "source": [
    "#---------------Shuffle data--------------------------\n",
    "X_train1, X_train2, y_train, X_test1, X_test2, y_test = get_data()\n",
    "print (X_train1.shape)\n",
    "print (X_train2.shape)\n",
    "print (X_test1.shape)\n",
    "print (X_test2.shape)\n",
    "print (y_train.shape)\n",
    "print (y_test.shape)\n",
    "print (X_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33193, 240, 2)\n",
      "(33193, 2, 1)\n",
      "(33193,)\n"
     ]
    }
   ],
   "source": [
    "## join X_train1 and X_test1, X_train2 and X_test2, y_train and y_test,\n",
    "X_tmp1 = np.concatenate((X_train1, X_test1), axis = 0)\n",
    "X_tmp2 = np.concatenate((X_train2, X_test2), axis = 0)\n",
    "Y_tmp = np.concatenate((y_train, y_test), axis = 0)\n",
    "print(X_tmp1.shape)\n",
    "print(X_tmp2.shape)\n",
    "print(Y_tmp.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test with SAD dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29873, 240, 2)\n",
      "(29873,)\n",
      "(3320, 240, 2)\n",
      "(3320,)\n"
     ]
    }
   ],
   "source": [
    "## then use train_test_split to shuffe data\n",
    "X_train1, X_test1, y_train, y_test = train_test_split(X_tmp1, Y_tmp, test_size=0.1, random_state=42, shuffle=True)\n",
    "print(X_train1.shape)\n",
    "# print(X_train)\n",
    "print(y_train.shape)\n",
    "# print(y_train)\n",
    "print(X_test1.shape)\n",
    "# print(X_test1)\n",
    "print(y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29873, 2, 1)\n",
      "(3320, 2, 1)\n",
      "(29873,)\n"
     ]
    }
   ],
   "source": [
    "X_train2, X_test2, y_train, y_test = train_test_split(X_tmp2, Y_tmp, test_size=0.1, random_state=42, shuffle=True)\n",
    "print(X_train2.shape)\n",
    "# print(X_train2)\n",
    "print(X_test2.shape)\n",
    "print(y_train.shape)\n",
    "# print(y_train)\n",
    "#--------------close shuffle data--------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform hyper parameter tuning with cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(param):\n",
    "    # The number of hidden units is a direct representation of the learning capacity of a neural network -- it reflects the number of learned parameters. \n",
    "    # The value 256 was selected arbitrarily or empirically \n",
    "    layers = {'input': 2, 'hidden1': param['unit'], 'hidden2': param['unit'], 'hidden3': param['unit'], 'output': 1}\n",
    "    # sequence_length is the timestep (Tx) ( a 1' window)\n",
    "    #The `Input()` layer is used for defining the input `X` as well as the initial hidden state 'a0' and cell state `c0`.\n",
    "    #The `shape` parameter takes a tuple that does not include the batch dimension (`m`).\n",
    "    #Samples. One sequence is one sample. A batch is comprised of one or more samples.\n",
    "    #Time Steps. One time step is one point of observation in the sample.\n",
    "    #Features. One feature is one observation at a time step.\n",
    "    #shape=(240,2) indicates that the expected input will be batches of 240-dimensional vectors, and 2 input features (RRI + R-peak amplitude)\n",
    "    x1 = tf.keras.layers.Input(shape=(sequence_length, layers['input']))\n",
    "    \n",
    "    #units (256)- dimensionality of the output space.\n",
    "    #fraction of the units to drop for the linear transformation of the recurrent state = 0.5\n",
    "    # return sequences return the hidden state output for each input time step (many-to-many)\n",
    "    m1 = tf.keras.layers.LSTM(layers['hidden1'],\n",
    "                              use_bias=True,\n",
    "                              dropout=param['dr1'],\n",
    "                    recurrent_dropout=0,\n",
    "                   return_sequences=True)(x1)\n",
    "    m1 = tf.keras.layers.LSTM(\n",
    "            layers['hidden2'],\n",
    "            use_bias=True,\n",
    "            dropout=param['dr2'],\n",
    "            recurrent_dropout=0,\n",
    "            return_sequences=True)(m1)\n",
    "\n",
    "    m1 = tf.keras.layers.LSTM(\n",
    "            layers['hidden3'],\n",
    "            use_bias=True,\n",
    "            dropout=param['dr3'],\n",
    "            recurrent_dropout=0,\n",
    "            return_sequences=False)(m1)\n",
    "\n",
    "    m1 = tf.keras.layers.Dense(128)(m1)\n",
    "    m1 = tf.keras.layers.Dense(64)(m1)\n",
    "    m1 = tf.keras.layers.Dense(32)(m1)\n",
    "    \n",
    "    x2 = tf.keras.layers.Input(shape=(2,))\n",
    "    m2 = tf.keras.layers.Dense(128)(x2)\n",
    "    m2 = tf.keras.layers.Dense(64)(m2) \n",
    "    m2 = tf.keras.layers.Dense(32)(m2)\n",
    "    \n",
    "    merged = tf.keras.layers.Concatenate(axis=1)([m1, m2])\n",
    "\n",
    "    out = tf.keras.layers.Dense(8)(merged)\n",
    "    out = tf.keras.layers.Dense(layers['output'], kernel_initializer='normal')(out)\n",
    "    out = tf.keras.layers.Activation(\"sigmoid\")(out)\n",
    "    \n",
    "    model = tf.keras.models.Model(inputs=[x1, x2], outputs=[out])\n",
    "\n",
    "    start = time.time()\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=tf.keras.optimizers.Adam(learning_rate=param['lr']), metrics=\"accuracy\")\n",
    "    print (\"Compilation Time : \", time.time() - start)\n",
    "    \n",
    "    #he None dimension in the shape tuple refers to the batch dimension which simply means that the layer can accept input of any size.\n",
    "    # plot_model(model, to_file='model_plot_quoc.png', show_shapes=True, show_layer_names=True)\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on baseline models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://keras.io/api/layers/recurrent_layers/lstm/\n",
    "model_params = {\n",
    "    # 'rnn': {\n",
    "    #     'model': svm.SVC(gamma='auto'),\n",
    "    #     'params' : {\n",
    "    #         'C': [1,10,20],\n",
    "    #         'kernel': ['rbf','linear']\n",
    "    #     }  \n",
    "    # },\n",
    "    # 'gru': {\n",
    "    #     'model': RandomForestClassifier(),\n",
    "    #     'params' : {\n",
    "    #         'n_estimators': [1,5,10]\n",
    "    #     }\n",
    "    # },\n",
    "    # 'cnn': {\n",
    "    #     'model': cnn(),\n",
    "    #     'params' : {\n",
    "    #       'unit': [256, 384],\n",
    "    #       'lr': [1e-2, 1e-3],\n",
    "    #      'activ': ['elu','relu'],\n",
    "    #      'epochs': 50,\n",
    "    #      'batch_size': 64\n",
    "    #     }  \n",
    "    # },\n",
    "    'our_model': {\n",
    "        'model': get_model,\n",
    "        'params': {\n",
    "            'dr1': [0.1, 0.2],\n",
    "            'dr2': [0.1, 0.2],\n",
    "            'dr3': [0.1, 0.2],\n",
    "            'unit': [256, 384],\n",
    "            'lr': [1e-2, 1e-3],\n",
    "            # 'activ': ['elu','relu'],\n",
    "            'epochs': 50,\n",
    "            'batch_size': 64\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = KFold(n_splits=5, random_state=33, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##################\n",
      "###  Fold 001  ###\n",
      "##################\n",
      "\n",
      "32 trials detected for ('dr1', 'dr2', 'dr3', 'unit', 'lr', 'epochs', 'batch_size')\n",
      "Compilation Time :  0.008445978164672852\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 240, 256)     265216      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 240, 256)     525312      lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, 256)          525312      lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 128)          32896       lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 128)          384         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 64)           8256        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 64)           8256        dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 32)           2080        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 32)           2080        dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 64)           0           dense_2[0][0]                    \n",
      "                                                                 dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 8)            520         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 1)            9           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 1)            0           dense_7[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,370,321\n",
      "Trainable params: 1,370,321\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (1/32) *****\n",
      "Search({'dr1': 0.1, 'dr2': 0.1, 'dr3': 0.1, 'unit': 256, 'lr': 0.01, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.70711, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.70711 to 0.72519, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.72519 to 0.73607, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.73607\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.73607\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.73607\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.73607\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.73607\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.73607 to 0.76485, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.76485\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.76485\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.76485\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.76485\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.76485\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.76485\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.76485\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.76485\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.76485\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.76485\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.76485\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.76485\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.76485\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.76485\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.76485\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.76485\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.76485\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.76485\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.76485\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.76485\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.76485\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.76485\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.76485\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.76485\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.76485\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.76485\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.76485\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.76485\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.76485\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.76485\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.76485\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.76485\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.76485\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.76485\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.76485\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.76485\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.76485\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.76485\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.76485\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.76485\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.76485\n",
      "SCORE: 0.76485 at epoch 9\n",
      "Compilation Time :  0.002193927764892578\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   (None, 240, 256)     265216      input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                   (None, 240, 256)     525312      lstm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_5 (LSTM)                   (None, 256)          525312      lstm_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 128)          32896       lstm_5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 128)          384         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 64)           8256        dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 64)           8256        dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 32)           2080        dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 32)           2080        dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 64)           0           dense_10[0][0]                   \n",
      "                                                                 dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 8)            520         concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 1)            9           dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 1)            0           dense_15[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,370,321\n",
      "Trainable params: 1,370,321\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (2/32) *****\n",
      "Search({'dr1': 0.1, 'dr2': 0.1, 'dr3': 0.1, 'unit': 256, 'lr': 0.001, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.77155, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.77155\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.77155 to 0.78192, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.78192 to 0.79866, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.79866 to 0.81071, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.81071\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.81071\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.81071\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.81071 to 0.82142, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.82142\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.82142\n",
      "\n",
      "Epoch 00012: val_accuracy improved from 0.82142 to 0.83180, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.83180\n",
      "\n",
      "Epoch 00014: val_accuracy improved from 0.83180 to 0.84151, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.84151\n",
      "\n",
      "Epoch 00016: val_accuracy improved from 0.84151 to 0.84184, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00017: val_accuracy improved from 0.84184 to 0.84268, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.84268\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.84268\n",
      "\n",
      "Epoch 00020: val_accuracy improved from 0.84268 to 0.85238, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.85238\n",
      "\n",
      "Epoch 00022: val_accuracy improved from 0.85238 to 0.85473, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.85473\n",
      "\n",
      "Epoch 00024: val_accuracy improved from 0.85473 to 0.85724, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.85724\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.85724\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.85724\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.85724\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.85724\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.85724\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.85724\n",
      "\n",
      "Epoch 00032: val_accuracy improved from 0.85724 to 0.85891, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.85891\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.85891\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.85891\n",
      "\n",
      "Epoch 00036: val_accuracy improved from 0.85891 to 0.85958, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.85958\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.85958\n",
      "\n",
      "Epoch 00039: val_accuracy improved from 0.85958 to 0.86008, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.86008\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.86008\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.86008\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.86008\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.86008\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.86008\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.86008\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.86008\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.86008\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.86008\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.86008\n",
      "SCORE: 0.86008 at epoch 39\n",
      "Compilation Time :  0.0021944046020507812\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_6 (LSTM)                   (None, 240, 384)     594432      input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_7 (LSTM)                   (None, 240, 384)     1181184     lstm_6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_8 (LSTM)                   (None, 384)          1181184     lstm_7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 128)          49280       lstm_8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 128)          384         input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 64)           8256        dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 64)           8256        dense_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 32)           2080        dense_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_21 (Dense)                (None, 32)           2080        dense_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 64)           0           dense_18[0][0]                   \n",
      "                                                                 dense_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_22 (Dense)                (None, 8)            520         concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_23 (Dense)                (None, 1)            9           dense_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 1)            0           dense_23[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 3,027,665\n",
      "Trainable params: 3,027,665\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (3/32) *****\n",
      "Search({'dr1': 0.1, 'dr2': 0.1, 'dr3': 0.1, 'unit': 384, 'lr': 0.01, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.75582, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.75582\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.75582\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.75582\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.75582\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.75582\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.75582\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.75582\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.75582\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.75582\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.75582\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.75582\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.75582\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.75582\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.75582\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.75582\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.75582\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.75582\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.75582\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.75582\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.75582\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.75582\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.75582\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.75582\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.75582\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.75582\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.75582\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.75582\n",
      "\n",
      "Epoch 00029: val_accuracy improved from 0.75582 to 0.76201, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.76201\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.76201\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.76201\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.76201\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.76201\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.76201\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.76201\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.76201\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.76201\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.76201\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.76201\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.76201\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.76201\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.76201\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.76201\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.76201\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.76201\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.76201\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.76201\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.76201\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.76201\n",
      "SCORE: 0.76201 at epoch 29\n",
      "Compilation Time :  0.002185821533203125\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_9 (LSTM)                   (None, 240, 384)     594432      input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_10 (LSTM)                  (None, 240, 384)     1181184     lstm_9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_11 (LSTM)                  (None, 384)          1181184     lstm_10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_24 (Dense)                (None, 128)          49280       lstm_11[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_27 (Dense)                (None, 128)          384         input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_25 (Dense)                (None, 64)           8256        dense_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_28 (Dense)                (None, 64)           8256        dense_27[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_26 (Dense)                (None, 32)           2080        dense_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_29 (Dense)                (None, 32)           2080        dense_28[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 64)           0           dense_26[0][0]                   \n",
      "                                                                 dense_29[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_30 (Dense)                (None, 8)            520         concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_31 (Dense)                (None, 1)            9           dense_30[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 1)            0           dense_31[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 3,027,665\n",
      "Trainable params: 3,027,665\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (4/32) *****\n",
      "Search({'dr1': 0.1, 'dr2': 0.1, 'dr3': 0.1, 'unit': 384, 'lr': 0.001, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.74142, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.74142 to 0.79113, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.79113 to 0.79548, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.79548 to 0.79749, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.79749\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.79749 to 0.79950, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.79950 to 0.80151, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.80151 to 0.82243, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.82243 to 0.83397, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.83397\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.83397\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.83397\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.83397\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.83397\n",
      "\n",
      "Epoch 00015: val_accuracy improved from 0.83397 to 0.84301, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00016: val_accuracy improved from 0.84301 to 0.84669, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00017: val_accuracy improved from 0.84669 to 0.84870, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.84870\n",
      "\n",
      "Epoch 00019: val_accuracy improved from 0.84870 to 0.85054, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.85054\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.85054\n",
      "\n",
      "Epoch 00022: val_accuracy improved from 0.85054 to 0.85607, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.85607\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.85607\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.85607\n",
      "\n",
      "Epoch 00026: val_accuracy improved from 0.85607 to 0.85992, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.85992\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.85992\n",
      "\n",
      "Epoch 00029: val_accuracy improved from 0.85992 to 0.86276, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.86276\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.86276\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.86276\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.86276\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.86276\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.86276\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.86276\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.86276\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.86276\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.86276\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.86276\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.86276\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.86276\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.86276\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.86276\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.86276\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.86276\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.86276\n",
      "\n",
      "Epoch 00048: val_accuracy improved from 0.86276 to 0.86494, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.86494\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.86494\n",
      "SCORE: 0.86494 at epoch 48\n",
      "Compilation Time :  0.00214385986328125\n",
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_9 (InputLayer)            [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_12 (LSTM)                  (None, 240, 256)     265216      input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_13 (LSTM)                  (None, 240, 256)     525312      lstm_12[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_14 (LSTM)                  (None, 256)          525312      lstm_13[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_10 (InputLayer)           [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_32 (Dense)                (None, 128)          32896       lstm_14[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_35 (Dense)                (None, 128)          384         input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_33 (Dense)                (None, 64)           8256        dense_32[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_36 (Dense)                (None, 64)           8256        dense_35[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_34 (Dense)                (None, 32)           2080        dense_33[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_37 (Dense)                (None, 32)           2080        dense_36[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 64)           0           dense_34[0][0]                   \n",
      "                                                                 dense_37[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_38 (Dense)                (None, 8)            520         concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_39 (Dense)                (None, 1)            9           dense_38[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 1)            0           dense_39[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,370,321\n",
      "Trainable params: 1,370,321\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (5/32) *****\n",
      "Search({'dr1': 0.1, 'dr2': 0.1, 'dr3': 0.2, 'unit': 256, 'lr': 0.01, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.74996, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.74996\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.74996\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.74996\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.74996 to 0.75565, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.75565\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.75565\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.75565\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.75565 to 0.76201, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.76201\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.76201\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.76201\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.76201\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.76201\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.76201\n",
      "\n",
      "Epoch 00016: val_accuracy improved from 0.76201 to 0.76887, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00017: val_accuracy improved from 0.76887 to 0.77272, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.77272\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.77272\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.77272\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.77272\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.77272\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.77272\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.77272\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.77272\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.77272\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.77272\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.77272\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.77272\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.77272\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.77272\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.77272\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.77272\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.77272\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.77272\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.77272\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.77272\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.77272\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.77272\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.77272\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.77272\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.77272\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.77272\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.77272\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.77272\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.77272\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.77272\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.77272\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.77272\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.77272\n",
      "SCORE: 0.77272 at epoch 17\n",
      "Compilation Time :  0.0022563934326171875\n",
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_11 (InputLayer)           [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_15 (LSTM)                  (None, 240, 256)     265216      input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_16 (LSTM)                  (None, 240, 256)     525312      lstm_15[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_17 (LSTM)                  (None, 256)          525312      lstm_16[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_12 (InputLayer)           [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_40 (Dense)                (None, 128)          32896       lstm_17[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_43 (Dense)                (None, 128)          384         input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_41 (Dense)                (None, 64)           8256        dense_40[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_44 (Dense)                (None, 64)           8256        dense_43[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_42 (Dense)                (None, 32)           2080        dense_41[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_45 (Dense)                (None, 32)           2080        dense_44[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 64)           0           dense_42[0][0]                   \n",
      "                                                                 dense_45[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_46 (Dense)                (None, 8)            520         concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_47 (Dense)                (None, 1)            9           dense_46[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 1)            0           dense_47[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,370,321\n",
      "Trainable params: 1,370,321\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (6/32) *****\n",
      "Search({'dr1': 0.1, 'dr2': 0.1, 'dr3': 0.2, 'unit': 256, 'lr': 0.001, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.77121, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.77121 to 0.78711, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.78711 to 0.80351, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.80351 to 0.80586, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.80586 to 0.81071, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.81071\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.81071\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.81071 to 0.81356, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.81356\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.81356 to 0.83213, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.83213 to 0.84218, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.84218\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.84218\n",
      "\n",
      "Epoch 00014: val_accuracy improved from 0.84218 to 0.84368, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.84368\n",
      "\n",
      "Epoch 00016: val_accuracy improved from 0.84368 to 0.84787, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00017: val_accuracy improved from 0.84787 to 0.85406, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.85406\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.85406\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.85406\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.85406\n",
      "\n",
      "Epoch 00022: val_accuracy improved from 0.85406 to 0.85506, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.85506\n",
      "\n",
      "Epoch 00024: val_accuracy improved from 0.85506 to 0.86075, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.86075\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.86075\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.86075\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.86075\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.86075\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.86075\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.86075\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.86075\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.86075\n",
      "\n",
      "Epoch 00034: val_accuracy improved from 0.86075 to 0.86410, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.86410\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.86410\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.86410\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.86410\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.86410\n",
      "\n",
      "Epoch 00040: val_accuracy improved from 0.86410 to 0.86594, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.86594\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.86594\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.86594\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.86594\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.86594\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.86594\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.86594\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.86594\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.86594\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.86594\n",
      "SCORE: 0.86594 at epoch 40\n",
      "Compilation Time :  0.002184152603149414\n",
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_13 (InputLayer)           [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_18 (LSTM)                  (None, 240, 384)     594432      input_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_19 (LSTM)                  (None, 240, 384)     1181184     lstm_18[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_20 (LSTM)                  (None, 384)          1181184     lstm_19[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_14 (InputLayer)           [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_48 (Dense)                (None, 128)          49280       lstm_20[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_51 (Dense)                (None, 128)          384         input_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_49 (Dense)                (None, 64)           8256        dense_48[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_52 (Dense)                (None, 64)           8256        dense_51[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_50 (Dense)                (None, 32)           2080        dense_49[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_53 (Dense)                (None, 32)           2080        dense_52[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 64)           0           dense_50[0][0]                   \n",
      "                                                                 dense_53[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_54 (Dense)                (None, 8)            520         concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_55 (Dense)                (None, 1)            9           dense_54[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 1)            0           dense_55[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 3,027,665\n",
      "Trainable params: 3,027,665\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (7/32) *****\n",
      "Search({'dr1': 0.1, 'dr2': 0.1, 'dr3': 0.2, 'unit': 384, 'lr': 0.01, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.65858, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.65858 to 0.74410, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.74410\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.74410\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.74410 to 0.74845, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.74845\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.74845\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.74845\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.74845\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.74845\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.74845\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.74845\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.74845 to 0.75280, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.75280\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.75280\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.75280\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.75280\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.75280\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.75280\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.75280\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.75280\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.75280\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.75280\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.75280\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.75280\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.75280\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.75280\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.75280\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.75280\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.75280\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.75280\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.75280\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.75280\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.75280\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.75280\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.75280\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.75280\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.75280\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.75280\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.75280\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.75280\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.75280\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.75280\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.75280\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.75280\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.75280\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.75280\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.75280\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.75280\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.75280\n",
      "SCORE: 0.7528 at epoch 13\n",
      "Compilation Time :  0.0021429061889648438\n",
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_15 (InputLayer)           [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_21 (LSTM)                  (None, 240, 384)     594432      input_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_22 (LSTM)                  (None, 240, 384)     1181184     lstm_21[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_23 (LSTM)                  (None, 384)          1181184     lstm_22[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_16 (InputLayer)           [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_56 (Dense)                (None, 128)          49280       lstm_23[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_59 (Dense)                (None, 128)          384         input_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_57 (Dense)                (None, 64)           8256        dense_56[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_60 (Dense)                (None, 64)           8256        dense_59[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_58 (Dense)                (None, 32)           2080        dense_57[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_61 (Dense)                (None, 32)           2080        dense_60[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 64)           0           dense_58[0][0]                   \n",
      "                                                                 dense_61[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_62 (Dense)                (None, 8)            520         concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_63 (Dense)                (None, 1)            9           dense_62[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 1)            0           dense_63[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 3,027,665\n",
      "Trainable params: 3,027,665\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (8/32) *****\n",
      "Search({'dr1': 0.1, 'dr2': 0.1, 'dr3': 0.2, 'unit': 384, 'lr': 0.001, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.78728, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.78728 to 0.81004, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.81004\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.81004 to 0.82109, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.82109\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.82109 to 0.82946, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.82946\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.82946 to 0.83699, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.83699 to 0.84000, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.84000 to 0.84418, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.84418\n",
      "\n",
      "Epoch 00012: val_accuracy improved from 0.84418 to 0.84469, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.84469 to 0.85339, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.85339\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.85339\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.85339\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.85339\n",
      "\n",
      "Epoch 00018: val_accuracy improved from 0.85339 to 0.86259, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.86259\n",
      "\n",
      "Epoch 00020: val_accuracy improved from 0.86259 to 0.86310, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.86310\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.86310\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.86310\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.86310\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.86310\n",
      "\n",
      "Epoch 00026: val_accuracy improved from 0.86310 to 0.86377, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.86377\n",
      "\n",
      "Epoch 00028: val_accuracy improved from 0.86377 to 0.86577, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.86577\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.86577\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.86577\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.86577\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.86577\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.86577\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.86577\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.86577\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.86577\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.86577\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.86577\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.86577\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.86577\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.86577\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.86577\n",
      "\n",
      "Epoch 00044: val_accuracy improved from 0.86577 to 0.86828, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.86828\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.86828\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.86828\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.86828\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.86828\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.86828\n",
      "SCORE: 0.86828 at epoch 44\n",
      "Compilation Time :  0.002247333526611328\n",
      "Model: \"model_8\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_17 (InputLayer)           [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_24 (LSTM)                  (None, 240, 256)     265216      input_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_25 (LSTM)                  (None, 240, 256)     525312      lstm_24[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_26 (LSTM)                  (None, 256)          525312      lstm_25[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_18 (InputLayer)           [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_64 (Dense)                (None, 128)          32896       lstm_26[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_67 (Dense)                (None, 128)          384         input_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_65 (Dense)                (None, 64)           8256        dense_64[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_68 (Dense)                (None, 64)           8256        dense_67[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_66 (Dense)                (None, 32)           2080        dense_65[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_69 (Dense)                (None, 32)           2080        dense_68[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 64)           0           dense_66[0][0]                   \n",
      "                                                                 dense_69[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_70 (Dense)                (None, 8)            520         concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_71 (Dense)                (None, 1)            9           dense_70[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 1)            0           dense_71[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,370,321\n",
      "Trainable params: 1,370,321\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (9/32) *****\n",
      "Search({'dr1': 0.1, 'dr2': 0.2, 'dr3': 0.1, 'unit': 256, 'lr': 0.01, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.74778, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.74778\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.74778\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.74778\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.74778 to 0.75498, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.75498\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.75498\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.75498\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.75498\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.75498\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.75498\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.75498\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.75498\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.75498\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.75498\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.75498\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.75498\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.75498\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.75498\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.75498\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.75498\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.75498\n",
      "\n",
      "Epoch 00023: val_accuracy improved from 0.75498 to 0.76134, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.76134\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.76134\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.76134\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.76134\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.76134\n",
      "\n",
      "Epoch 00029: val_accuracy improved from 0.76134 to 0.76251, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.76251\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.76251\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.76251\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.76251\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.76251\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.76251\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.76251\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.76251\n",
      "\n",
      "Epoch 00038: val_accuracy improved from 0.76251 to 0.77054, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.77054\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.77054\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.77054\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.77054\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.77054\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.77054\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.77054\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.77054\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.77054\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.77054\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.77054\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.77054\n",
      "SCORE: 0.77054 at epoch 38\n",
      "Compilation Time :  0.002206087112426758\n",
      "Model: \"model_9\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_19 (InputLayer)           [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_27 (LSTM)                  (None, 240, 256)     265216      input_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_28 (LSTM)                  (None, 240, 256)     525312      lstm_27[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_29 (LSTM)                  (None, 256)          525312      lstm_28[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_20 (InputLayer)           [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_72 (Dense)                (None, 128)          32896       lstm_29[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_75 (Dense)                (None, 128)          384         input_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_73 (Dense)                (None, 64)           8256        dense_72[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_76 (Dense)                (None, 64)           8256        dense_75[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_74 (Dense)                (None, 32)           2080        dense_73[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_77 (Dense)                (None, 32)           2080        dense_76[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 64)           0           dense_74[0][0]                   \n",
      "                                                                 dense_77[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_78 (Dense)                (None, 8)            520         concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_79 (Dense)                (None, 1)            9           dense_78[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 1)            0           dense_79[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,370,321\n",
      "Trainable params: 1,370,321\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (10/32) *****\n",
      "Search({'dr1': 0.1, 'dr2': 0.2, 'dr3': 0.1, 'unit': 256, 'lr': 0.001, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.78310, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.78310 to 0.78895, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.78895 to 0.79833, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.79833 to 0.81406, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.81406\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.81406\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.81406 to 0.82025, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.82025 to 0.83063, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.83063 to 0.83548, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.83548 to 0.84067, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.84067\n",
      "\n",
      "Epoch 00012: val_accuracy improved from 0.84067 to 0.84954, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.84954\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.84954\n",
      "\n",
      "Epoch 00015: val_accuracy improved from 0.84954 to 0.85456, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.85456\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.85456\n",
      "\n",
      "Epoch 00018: val_accuracy improved from 0.85456 to 0.85573, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00019: val_accuracy improved from 0.85573 to 0.85690, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.85690\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.85690\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.85690\n",
      "\n",
      "Epoch 00023: val_accuracy improved from 0.85690 to 0.85707, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00024: val_accuracy improved from 0.85707 to 0.86293, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00025: val_accuracy improved from 0.86293 to 0.86494, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.86494\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.86494\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.86494\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.86494\n",
      "\n",
      "Epoch 00030: val_accuracy improved from 0.86494 to 0.86644, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.86644\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.86644\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.86644\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.86644\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.86644\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.86644\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.86644\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.86644\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.86644\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.86644\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.86644\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.86644\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.86644\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.86644\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.86644\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.86644\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.86644\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.86644\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.86644\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.86644\n",
      "SCORE: 0.86644 at epoch 30\n",
      "Compilation Time :  0.0021657943725585938\n",
      "Model: \"model_10\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_21 (InputLayer)           [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_30 (LSTM)                  (None, 240, 384)     594432      input_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_31 (LSTM)                  (None, 240, 384)     1181184     lstm_30[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_32 (LSTM)                  (None, 384)          1181184     lstm_31[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_22 (InputLayer)           [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_80 (Dense)                (None, 128)          49280       lstm_32[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_83 (Dense)                (None, 128)          384         input_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_81 (Dense)                (None, 64)           8256        dense_80[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_84 (Dense)                (None, 64)           8256        dense_83[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_82 (Dense)                (None, 32)           2080        dense_81[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_85 (Dense)                (None, 32)           2080        dense_84[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 64)           0           dense_82[0][0]                   \n",
      "                                                                 dense_85[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_86 (Dense)                (None, 8)            520         concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_87 (Dense)                (None, 1)            9           dense_86[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 1)            0           dense_87[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 3,027,665\n",
      "Trainable params: 3,027,665\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (11/32) *****\n",
      "Search({'dr1': 0.1, 'dr2': 0.2, 'dr3': 0.1, 'unit': 384, 'lr': 0.01, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.72368 to 0.74862, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.74862\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.74862\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.74862 to 0.74912, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.74912 to 0.75063, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.75063\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.75063\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.75063\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.75063\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.75063\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.75063\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.75063\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.75063\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.75063\n",
      "\n",
      "Epoch 00019: val_accuracy improved from 0.75063 to 0.75883, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.75883\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.75883\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.75883\n",
      "\n",
      "Epoch 00023: val_accuracy improved from 0.75883 to 0.76017, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.76017\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.76017\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.76017\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.76017\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.76017\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.76017\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.76017\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.76017\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.76017\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.76017\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.76017\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.76017\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.76017\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.76017\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.76017\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.76017\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.76017\n",
      "\n",
      "Epoch 00041: val_accuracy improved from 0.76017 to 0.76954, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.76954\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.76954\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.76954\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.76954\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.76954\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.76954\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.76954\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.76954\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.76954\n",
      "SCORE: 0.76954 at epoch 41\n",
      "Compilation Time :  0.0021865367889404297\n",
      "Model: \"model_11\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_23 (InputLayer)           [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_33 (LSTM)                  (None, 240, 384)     594432      input_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_34 (LSTM)                  (None, 240, 384)     1181184     lstm_33[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_35 (LSTM)                  (None, 384)          1181184     lstm_34[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_24 (InputLayer)           [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_88 (Dense)                (None, 128)          49280       lstm_35[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_91 (Dense)                (None, 128)          384         input_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_89 (Dense)                (None, 64)           8256        dense_88[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_92 (Dense)                (None, 64)           8256        dense_91[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_90 (Dense)                (None, 32)           2080        dense_89[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_93 (Dense)                (None, 32)           2080        dense_92[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 64)           0           dense_90[0][0]                   \n",
      "                                                                 dense_93[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_94 (Dense)                (None, 8)            520         concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_95 (Dense)                (None, 1)            9           dense_94[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 1)            0           dense_95[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 3,027,665\n",
      "Trainable params: 3,027,665\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (12/32) *****\n",
      "Search({'dr1': 0.1, 'dr2': 0.2, 'dr3': 0.1, 'unit': 384, 'lr': 0.001, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.76402, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.76402 to 0.77874, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.77874 to 0.78510, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.78510 to 0.79916, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.79916\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.79916\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.79916\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.79916 to 0.80452, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.80452 to 0.80536, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.80536 to 0.83063, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.83063\n",
      "\n",
      "Epoch 00012: val_accuracy improved from 0.83063 to 0.84335, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.84335\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.84335\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.84335\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.84335\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.84335\n",
      "\n",
      "Epoch 00018: val_accuracy improved from 0.84335 to 0.84753, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00019: val_accuracy improved from 0.84753 to 0.85054, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.85054\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.85054\n",
      "\n",
      "Epoch 00022: val_accuracy improved from 0.85054 to 0.85289, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.85289\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.85289\n",
      "\n",
      "Epoch 00025: val_accuracy improved from 0.85289 to 0.85439, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.85439\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.85439\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.85439\n",
      "\n",
      "Epoch 00029: val_accuracy improved from 0.85439 to 0.85556, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00030: val_accuracy improved from 0.85556 to 0.85640, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.85640\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.85640\n",
      "\n",
      "Epoch 00033: val_accuracy improved from 0.85640 to 0.85891, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.85891\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.85891\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.85891\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.85891\n",
      "\n",
      "Epoch 00038: val_accuracy improved from 0.85891 to 0.86075, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.86075\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.86075\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.86075\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.86075\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.86075\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.86075\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.86075\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.86075\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.86075\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.86075\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.86075\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.86075\n",
      "SCORE: 0.86075 at epoch 38\n",
      "Compilation Time :  0.002171754837036133\n",
      "Model: \"model_12\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_25 (InputLayer)           [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_36 (LSTM)                  (None, 240, 256)     265216      input_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_37 (LSTM)                  (None, 240, 256)     525312      lstm_36[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_38 (LSTM)                  (None, 256)          525312      lstm_37[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_26 (InputLayer)           [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_96 (Dense)                (None, 128)          32896       lstm_38[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_99 (Dense)                (None, 128)          384         input_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_97 (Dense)                (None, 64)           8256        dense_96[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_100 (Dense)               (None, 64)           8256        dense_99[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_98 (Dense)                (None, 32)           2080        dense_97[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_101 (Dense)               (None, 32)           2080        dense_100[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 64)           0           dense_98[0][0]                   \n",
      "                                                                 dense_101[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_102 (Dense)               (None, 8)            520         concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_103 (Dense)               (None, 1)            9           dense_102[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 1)            0           dense_103[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,370,321\n",
      "Trainable params: 1,370,321\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (13/32) *****\n",
      "Search({'dr1': 0.1, 'dr2': 0.2, 'dr3': 0.2, 'unit': 256, 'lr': 0.01, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.67515, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.67515 to 0.69556, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.69556\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.69556\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.69556 to 0.71397, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.71397\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.71397 to 0.71766, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.71766 to 0.73941, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.73941\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.73941\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.73941\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.73941\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.73941\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.73941\n",
      "\n",
      "Epoch 00015: val_accuracy improved from 0.73941 to 0.75397, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.75397\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.75397\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.75397\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.75397\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.75397\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.75397\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.75397\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.75397\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.75397\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.75397\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.75397\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.75397\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.75397\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.75397\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.75397\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.75397\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.75397\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.75397\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.75397\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.75397\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.75397\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.75397\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.75397\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.75397\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.75397\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.75397\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.75397\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.75397\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.75397\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.75397\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.75397\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.75397\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.75397\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.75397\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.75397\n",
      "SCORE: 0.75397 at epoch 15\n",
      "Compilation Time :  0.002209901809692383\n",
      "Model: \"model_13\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_27 (InputLayer)           [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_39 (LSTM)                  (None, 240, 256)     265216      input_27[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_40 (LSTM)                  (None, 240, 256)     525312      lstm_39[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_41 (LSTM)                  (None, 256)          525312      lstm_40[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_28 (InputLayer)           [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_104 (Dense)               (None, 128)          32896       lstm_41[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_107 (Dense)               (None, 128)          384         input_28[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_105 (Dense)               (None, 64)           8256        dense_104[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_108 (Dense)               (None, 64)           8256        dense_107[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_106 (Dense)               (None, 32)           2080        dense_105[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_109 (Dense)               (None, 32)           2080        dense_108[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 64)           0           dense_106[0][0]                  \n",
      "                                                                 dense_109[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_110 (Dense)               (None, 8)            520         concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_111 (Dense)               (None, 1)            9           dense_110[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 1)            0           dense_111[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,370,321\n",
      "Trainable params: 1,370,321\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (14/32) *****\n",
      "Search({'dr1': 0.1, 'dr2': 0.2, 'dr3': 0.2, 'unit': 256, 'lr': 0.001, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.75531, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.75531 to 0.77088, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.77088\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.77088 to 0.79866, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.79866\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.79866 to 0.81640, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.81640\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.81640\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.81640 to 0.82025, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.82025 to 0.82979, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.82979\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.82979\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.82979\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.82979\n",
      "\n",
      "Epoch 00015: val_accuracy improved from 0.82979 to 0.83732, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00016: val_accuracy improved from 0.83732 to 0.83933, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00017: val_accuracy improved from 0.83933 to 0.84000, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00018: val_accuracy improved from 0.84000 to 0.84402, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.84402\n",
      "\n",
      "Epoch 00020: val_accuracy improved from 0.84402 to 0.84536, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00021: val_accuracy improved from 0.84536 to 0.84636, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00022: val_accuracy improved from 0.84636 to 0.84653, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.84653\n",
      "\n",
      "Epoch 00024: val_accuracy improved from 0.84653 to 0.84921, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.84921\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.84921\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.84921\n",
      "\n",
      "Epoch 00028: val_accuracy improved from 0.84921 to 0.84937, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00029: val_accuracy improved from 0.84937 to 0.85021, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.85021\n",
      "\n",
      "Epoch 00031: val_accuracy improved from 0.85021 to 0.85841, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.85841\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.85841\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.85841\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.85841\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.85841\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.85841\n",
      "\n",
      "Epoch 00038: val_accuracy improved from 0.85841 to 0.85908, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.85908\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.85908\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.85908\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.85908\n",
      "\n",
      "Epoch 00043: val_accuracy improved from 0.85908 to 0.86042, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.86042\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.86042\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.86042\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.86042\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.86042\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.86042\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.86042\n",
      "SCORE: 0.86042 at epoch 43\n",
      "Compilation Time :  0.002207040786743164\n",
      "Model: \"model_14\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_29 (InputLayer)           [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_42 (LSTM)                  (None, 240, 384)     594432      input_29[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_43 (LSTM)                  (None, 240, 384)     1181184     lstm_42[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_44 (LSTM)                  (None, 384)          1181184     lstm_43[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_30 (InputLayer)           [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_112 (Dense)               (None, 128)          49280       lstm_44[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_115 (Dense)               (None, 128)          384         input_30[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_113 (Dense)               (None, 64)           8256        dense_112[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_116 (Dense)               (None, 64)           8256        dense_115[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_114 (Dense)               (None, 32)           2080        dense_113[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_117 (Dense)               (None, 32)           2080        dense_116[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 64)           0           dense_114[0][0]                  \n",
      "                                                                 dense_117[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_118 (Dense)               (None, 8)            520         concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_119 (Dense)               (None, 1)            9           dense_118[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 1)            0           dense_119[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,027,665\n",
      "Trainable params: 3,027,665\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (15/32) *****\n",
      "Search({'dr1': 0.1, 'dr2': 0.2, 'dr3': 0.2, 'unit': 384, 'lr': 0.01, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.68552, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.68552\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.68552\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.68552 to 0.73305, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.73305\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.73305\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.73305\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.73305\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.73305\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.73305\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.73305\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.73305\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.73305\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.73305\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.73305\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.73305\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.73305\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.73305\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.73305\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.73305\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.73305\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.73305\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.73305\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.73305\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.73305\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.73305\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.73305\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.73305\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.73305\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.73305\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.73305\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.73305\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.73305\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.73305\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.73305\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.73305\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.73305\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.73305\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.73305\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.73305\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.73305\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.73305\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.73305\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.73305\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.73305\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.73305\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.73305\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.73305\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.73305\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.73305\n",
      "SCORE: 0.73305 at epoch 4\n",
      "Compilation Time :  0.0022165775299072266\n",
      "Model: \"model_15\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_31 (InputLayer)           [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_45 (LSTM)                  (None, 240, 384)     594432      input_31[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_46 (LSTM)                  (None, 240, 384)     1181184     lstm_45[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_47 (LSTM)                  (None, 384)          1181184     lstm_46[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_32 (InputLayer)           [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_120 (Dense)               (None, 128)          49280       lstm_47[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_123 (Dense)               (None, 128)          384         input_32[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_121 (Dense)               (None, 64)           8256        dense_120[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_124 (Dense)               (None, 64)           8256        dense_123[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_122 (Dense)               (None, 32)           2080        dense_121[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_125 (Dense)               (None, 32)           2080        dense_124[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 64)           0           dense_122[0][0]                  \n",
      "                                                                 dense_125[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_126 (Dense)               (None, 8)            520         concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_127 (Dense)               (None, 1)            9           dense_126[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 1)            0           dense_127[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,027,665\n",
      "Trainable params: 3,027,665\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (16/32) *****\n",
      "Search({'dr1': 0.1, 'dr2': 0.2, 'dr3': 0.2, 'unit': 384, 'lr': 0.001, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.76301, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.76301 to 0.78092, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.78092 to 0.78326, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.78326\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.78326\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.78326 to 0.79515, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.79515 to 0.80720, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.80720\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.80720 to 0.82326, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.82326\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.82326 to 0.83029, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00012: val_accuracy improved from 0.83029 to 0.84067, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.84067\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.84067\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.84067\n",
      "\n",
      "Epoch 00016: val_accuracy improved from 0.84067 to 0.84100, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00017: val_accuracy improved from 0.84100 to 0.84485, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00018: val_accuracy improved from 0.84485 to 0.84803, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.84803\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.84803\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.84803\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.84803\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.84803\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.84803\n",
      "\n",
      "Epoch 00025: val_accuracy improved from 0.84803 to 0.85105, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00026: val_accuracy improved from 0.85105 to 0.86075, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.86075\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.86075\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.86075\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.86075\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.86075\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.86075\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.86075\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.86075\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.86075\n",
      "\n",
      "Epoch 00036: val_accuracy improved from 0.86075 to 0.86092, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00037: val_accuracy improved from 0.86092 to 0.86293, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.86293\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.86293\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.86293\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.86293\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.86293\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.86293\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.86293\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.86293\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.86293\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.86293\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.86293\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.86293\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.86293\n",
      "SCORE: 0.86293 at epoch 37\n",
      "Compilation Time :  0.002170562744140625\n",
      "Model: \"model_16\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_33 (InputLayer)           [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_48 (LSTM)                  (None, 240, 256)     265216      input_33[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_49 (LSTM)                  (None, 240, 256)     525312      lstm_48[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_50 (LSTM)                  (None, 256)          525312      lstm_49[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_34 (InputLayer)           [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_128 (Dense)               (None, 128)          32896       lstm_50[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_131 (Dense)               (None, 128)          384         input_34[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_129 (Dense)               (None, 64)           8256        dense_128[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_132 (Dense)               (None, 64)           8256        dense_131[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_130 (Dense)               (None, 32)           2080        dense_129[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_133 (Dense)               (None, 32)           2080        dense_132[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, 64)           0           dense_130[0][0]                  \n",
      "                                                                 dense_133[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_134 (Dense)               (None, 8)            520         concatenate_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_135 (Dense)               (None, 1)            9           dense_134[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 1)            0           dense_135[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,370,321\n",
      "Trainable params: 1,370,321\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (17/32) *****\n",
      "Search({'dr1': 0.2, 'dr2': 0.1, 'dr3': 0.1, 'unit': 256, 'lr': 0.01, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.73238, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.73238\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.73238\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.73238 to 0.73423, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.73423\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.73423 to 0.73607, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.73607\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.73607\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.73607\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.73607\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.73607\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.73607\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.73607\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.73607\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.73607\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.73607\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.73607\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.73607\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.73607\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.73607\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.73607\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.73607\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.73607\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.73607\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.73607\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.73607\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.73607\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.73607\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.73607\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.73607\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.73607\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.73607\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.73607\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.73607\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.73607\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.73607\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.73607\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.73607\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.73607\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.73607\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.73607\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.73607\n",
      "\n",
      "Epoch 00043: val_accuracy improved from 0.73607 to 0.74226, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.74226\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.74226\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.74226\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.74226\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.74226\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.74226\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.74226\n",
      "SCORE: 0.74226 at epoch 43\n",
      "Compilation Time :  0.002191781997680664\n",
      "Model: \"model_17\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_35 (InputLayer)           [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_51 (LSTM)                  (None, 240, 256)     265216      input_35[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_52 (LSTM)                  (None, 240, 256)     525312      lstm_51[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_53 (LSTM)                  (None, 256)          525312      lstm_52[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_36 (InputLayer)           [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_136 (Dense)               (None, 128)          32896       lstm_53[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_139 (Dense)               (None, 128)          384         input_36[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_137 (Dense)               (None, 64)           8256        dense_136[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_140 (Dense)               (None, 64)           8256        dense_139[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_138 (Dense)               (None, 32)           2080        dense_137[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_141 (Dense)               (None, 32)           2080        dense_140[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_17 (Concatenate)    (None, 64)           0           dense_138[0][0]                  \n",
      "                                                                 dense_141[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_142 (Dense)               (None, 8)            520         concatenate_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_143 (Dense)               (None, 1)            9           dense_142[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 1)            0           dense_143[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,370,321\n",
      "Trainable params: 1,370,321\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (18/32) *****\n",
      "Search({'dr1': 0.2, 'dr2': 0.1, 'dr3': 0.1, 'unit': 256, 'lr': 0.001, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.71531, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.71531 to 0.75063, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.75063\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.75063 to 0.76368, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.76368\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.76368 to 0.76937, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.76937\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.76937\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.76937\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.76937\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.76937\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.76937\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.76937 to 0.78561, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00014: val_accuracy improved from 0.78561 to 0.80151, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.80151\n",
      "\n",
      "Epoch 00016: val_accuracy improved from 0.80151 to 0.80703, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.80703\n",
      "\n",
      "Epoch 00018: val_accuracy improved from 0.80703 to 0.81858, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.81858\n",
      "\n",
      "Epoch 00020: val_accuracy improved from 0.81858 to 0.82360, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00021: val_accuracy improved from 0.82360 to 0.84301, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.84301\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.84301\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.84301\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.84301\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.84301\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.84301\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.84301\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.84301\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.84301\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.84301\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.84301\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.84301\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.84301\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.84301\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.84301\n",
      "\n",
      "Epoch 00037: val_accuracy improved from 0.84301 to 0.84351, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.84351\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.84351\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.84351\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.84351\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.84351\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.84351\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.84351\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.84351\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.84351\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.84351\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.84351\n",
      "\n",
      "Epoch 00049: val_accuracy improved from 0.84351 to 0.85188, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.85188\n",
      "SCORE: 0.85188 at epoch 49\n",
      "Compilation Time :  0.0022313594818115234\n",
      "Model: \"model_18\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_37 (InputLayer)           [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_54 (LSTM)                  (None, 240, 384)     594432      input_37[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_55 (LSTM)                  (None, 240, 384)     1181184     lstm_54[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_56 (LSTM)                  (None, 384)          1181184     lstm_55[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_38 (InputLayer)           [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_144 (Dense)               (None, 128)          49280       lstm_56[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_147 (Dense)               (None, 128)          384         input_38[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_145 (Dense)               (None, 64)           8256        dense_144[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_148 (Dense)               (None, 64)           8256        dense_147[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_146 (Dense)               (None, 32)           2080        dense_145[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_149 (Dense)               (None, 32)           2080        dense_148[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_18 (Concatenate)    (None, 64)           0           dense_146[0][0]                  \n",
      "                                                                 dense_149[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_150 (Dense)               (None, 8)            520         concatenate_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_151 (Dense)               (None, 1)            9           dense_150[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 1)            0           dense_151[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,027,665\n",
      "Trainable params: 3,027,665\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (19/32) *****\n",
      "Search({'dr1': 0.2, 'dr2': 0.1, 'dr3': 0.1, 'unit': 384, 'lr': 0.01, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.71331, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.71331\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.71331\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.71331 to 0.71799, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.71799\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.71799 to 0.72033, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.72033\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.72033 to 0.75448, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.75448\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.75448\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.75448\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.75448\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.75448\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.75448\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.75448\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.75448\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.75448\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.75448\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.75448\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.75448\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.75448\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.75448\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.75448\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.75448\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.75448\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.75448\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.75448\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.75448\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.75448\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.75448\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.75448\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.75448\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.75448\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.75448\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.75448\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.75448\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.75448\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.75448\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.75448\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.75448\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.75448\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.75448\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.75448\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.75448\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.75448\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.75448\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.75448\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.75448\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.75448\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.75448\n",
      "SCORE: 0.75448 at epoch 8\n",
      "Compilation Time :  0.0022363662719726562\n",
      "Model: \"model_19\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_39 (InputLayer)           [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_57 (LSTM)                  (None, 240, 384)     594432      input_39[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_58 (LSTM)                  (None, 240, 384)     1181184     lstm_57[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_59 (LSTM)                  (None, 384)          1181184     lstm_58[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_40 (InputLayer)           [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_152 (Dense)               (None, 128)          49280       lstm_59[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_155 (Dense)               (None, 128)          384         input_40[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_153 (Dense)               (None, 64)           8256        dense_152[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_156 (Dense)               (None, 64)           8256        dense_155[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_154 (Dense)               (None, 32)           2080        dense_153[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_157 (Dense)               (None, 32)           2080        dense_156[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_19 (Concatenate)    (None, 64)           0           dense_154[0][0]                  \n",
      "                                                                 dense_157[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_158 (Dense)               (None, 8)            520         concatenate_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_159 (Dense)               (None, 1)            9           dense_158[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 1)            0           dense_159[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,027,665\n",
      "Trainable params: 3,027,665\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (20/32) *****\n",
      "Search({'dr1': 0.2, 'dr2': 0.1, 'dr3': 0.1, 'unit': 384, 'lr': 0.001, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.69874, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.69874 to 0.72067, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.72067\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.72067 to 0.73138, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.73138\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.73138 to 0.74025, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.74025 to 0.76552, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.76552\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.76552\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.76552\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.76552 to 0.81038, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00012: val_accuracy improved from 0.81038 to 0.81305, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.81305 to 0.82243, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.82243\n",
      "\n",
      "Epoch 00015: val_accuracy improved from 0.82243 to 0.82862, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.82862\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.82862\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.82862\n",
      "\n",
      "Epoch 00019: val_accuracy improved from 0.82862 to 0.83665, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.83665\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.83665\n",
      "\n",
      "Epoch 00022: val_accuracy improved from 0.83665 to 0.84402, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.84402\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.84402\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.84402\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.84402\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.84402\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.84402\n",
      "\n",
      "Epoch 00029: val_accuracy improved from 0.84402 to 0.85506, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.85506\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.85506\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.85506\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.85506\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.85506\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.85506\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.85506\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.85506\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.85506\n",
      "\n",
      "Epoch 00039: val_accuracy improved from 0.85506 to 0.85925, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.85925\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.85925\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.85925\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.85925\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.85925\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.85925\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.85925\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.85925\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.85925\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.85925\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.85925\n",
      "SCORE: 0.85925 at epoch 39\n",
      "Compilation Time :  0.0021724700927734375\n",
      "Model: \"model_20\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_41 (InputLayer)           [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_60 (LSTM)                  (None, 240, 256)     265216      input_41[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_61 (LSTM)                  (None, 240, 256)     525312      lstm_60[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_62 (LSTM)                  (None, 256)          525312      lstm_61[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_42 (InputLayer)           [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_160 (Dense)               (None, 128)          32896       lstm_62[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_163 (Dense)               (None, 128)          384         input_42[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_161 (Dense)               (None, 64)           8256        dense_160[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_164 (Dense)               (None, 64)           8256        dense_163[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_162 (Dense)               (None, 32)           2080        dense_161[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_165 (Dense)               (None, 32)           2080        dense_164[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_20 (Concatenate)    (None, 64)           0           dense_162[0][0]                  \n",
      "                                                                 dense_165[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_166 (Dense)               (None, 8)            520         concatenate_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_167 (Dense)               (None, 1)            9           dense_166[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 1)            0           dense_167[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,370,321\n",
      "Trainable params: 1,370,321\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (21/32) *****\n",
      "Search({'dr1': 0.2, 'dr2': 0.1, 'dr3': 0.2, 'unit': 256, 'lr': 0.01, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.70644, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.70644 to 0.71849, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.71849 to 0.75096, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.75096\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.75096 to 0.76837, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.76837\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.76837\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.76837\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.76837\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.76837\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.76837\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.76837\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.76837\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.76837\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.76837\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.76837\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.76837\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.76837\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.76837\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.76837\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.76837\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.76837\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.76837\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.76837\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.76837\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.76837\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.76837\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.76837\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.76837\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.76837\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.76837\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.76837\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.76837\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.76837\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.76837\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.76837\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.76837\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.76837\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.76837\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.76837\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.76837\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.76837\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.76837\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.76837\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.76837\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.76837\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.76837\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.76837\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.76837\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.76837\n",
      "SCORE: 0.76837 at epoch 5\n",
      "Compilation Time :  0.00220489501953125\n",
      "Model: \"model_21\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_43 (InputLayer)           [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_63 (LSTM)                  (None, 240, 256)     265216      input_43[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_64 (LSTM)                  (None, 240, 256)     525312      lstm_63[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_65 (LSTM)                  (None, 256)          525312      lstm_64[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_44 (InputLayer)           [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_168 (Dense)               (None, 128)          32896       lstm_65[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_171 (Dense)               (None, 128)          384         input_44[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_169 (Dense)               (None, 64)           8256        dense_168[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_172 (Dense)               (None, 64)           8256        dense_171[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_170 (Dense)               (None, 32)           2080        dense_169[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_173 (Dense)               (None, 32)           2080        dense_172[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_21 (Concatenate)    (None, 64)           0           dense_170[0][0]                  \n",
      "                                                                 dense_173[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_174 (Dense)               (None, 8)            520         concatenate_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_175 (Dense)               (None, 1)            9           dense_174[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 1)            0           dense_175[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,370,321\n",
      "Trainable params: 1,370,321\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (22/32) *****\n",
      "Search({'dr1': 0.2, 'dr2': 0.1, 'dr3': 0.2, 'unit': 256, 'lr': 0.001, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.76385, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.76385\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.76385 to 0.77272, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.77272\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.77272\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.77272 to 0.80151, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.80151 to 0.80937, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.80937\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.80937\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.80937\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.80937 to 0.81925, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.81925\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.81925 to 0.82577, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00014: val_accuracy improved from 0.82577 to 0.83414, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.83414\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.83414\n",
      "\n",
      "Epoch 00017: val_accuracy improved from 0.83414 to 0.84151, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.84151\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.84151\n",
      "\n",
      "Epoch 00020: val_accuracy improved from 0.84151 to 0.85172, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.85172\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.85172\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.85172\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.85172\n",
      "\n",
      "Epoch 00025: val_accuracy improved from 0.85172 to 0.85590, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00026: val_accuracy improved from 0.85590 to 0.86059, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.86059\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.86059\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.86059\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.86059\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.86059\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.86059\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.86059\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.86059\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.86059\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.86059\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.86059\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.86059\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.86059\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.86059\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.86059\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.86059\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.86059\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.86059\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.86059\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.86059\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.86059\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.86059\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.86059\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.86059\n",
      "SCORE: 0.86059 at epoch 26\n",
      "Compilation Time :  0.002252817153930664\n",
      "Model: \"model_22\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_45 (InputLayer)           [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_66 (LSTM)                  (None, 240, 384)     594432      input_45[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_67 (LSTM)                  (None, 240, 384)     1181184     lstm_66[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_68 (LSTM)                  (None, 384)          1181184     lstm_67[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_46 (InputLayer)           [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_176 (Dense)               (None, 128)          49280       lstm_68[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_179 (Dense)               (None, 128)          384         input_46[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_177 (Dense)               (None, 64)           8256        dense_176[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_180 (Dense)               (None, 64)           8256        dense_179[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_178 (Dense)               (None, 32)           2080        dense_177[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_181 (Dense)               (None, 32)           2080        dense_180[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_22 (Concatenate)    (None, 64)           0           dense_178[0][0]                  \n",
      "                                                                 dense_181[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_182 (Dense)               (None, 8)            520         concatenate_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_183 (Dense)               (None, 1)            9           dense_182[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 1)            0           dense_183[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,027,665\n",
      "Trainable params: 3,027,665\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (23/32) *****\n",
      "Search({'dr1': 0.2, 'dr2': 0.1, 'dr3': 0.2, 'unit': 384, 'lr': 0.01, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.73088, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.73088 to 0.73222, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.73222\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.73222\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.73222\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.73222\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.73222\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.73222\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.73222 to 0.73941, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.73941\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.73941 to 0.74176, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.74176\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.74176 to 0.74544, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00014: val_accuracy improved from 0.74544 to 0.75264, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.75264\n",
      "\n",
      "Epoch 00016: val_accuracy improved from 0.75264 to 0.75849, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.75849\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.75849\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.75849\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.75849\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.75849\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.75849\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.75849\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.75849\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.75849\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.75849\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.75849\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.75849\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.75849\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.75849\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.75849\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.75849\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.75849\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.75849\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.75849\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.75849\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.75849\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.75849\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.75849\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.75849\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.75849\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.75849\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.75849\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.75849\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.75849\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.75849\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.75849\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.75849\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.75849\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.75849\n",
      "SCORE: 0.75849 at epoch 16\n",
      "Compilation Time :  0.002177000045776367\n",
      "Model: \"model_23\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_47 (InputLayer)           [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_69 (LSTM)                  (None, 240, 384)     594432      input_47[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_70 (LSTM)                  (None, 240, 384)     1181184     lstm_69[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_71 (LSTM)                  (None, 384)          1181184     lstm_70[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_48 (InputLayer)           [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_184 (Dense)               (None, 128)          49280       lstm_71[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_187 (Dense)               (None, 128)          384         input_48[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_185 (Dense)               (None, 64)           8256        dense_184[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_188 (Dense)               (None, 64)           8256        dense_187[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_186 (Dense)               (None, 32)           2080        dense_185[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_189 (Dense)               (None, 32)           2080        dense_188[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_23 (Concatenate)    (None, 64)           0           dense_186[0][0]                  \n",
      "                                                                 dense_189[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_190 (Dense)               (None, 8)            520         concatenate_23[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_191 (Dense)               (None, 1)            9           dense_190[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 1)            0           dense_191[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,027,665\n",
      "Trainable params: 3,027,665\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (24/32) *****\n",
      "Search({'dr1': 0.2, 'dr2': 0.1, 'dr3': 0.2, 'unit': 384, 'lr': 0.001, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.75548, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.75548 to 0.75665, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.75665 to 0.77155, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.77155\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.77155\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.77155\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.77155\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.77155 to 0.81724, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.81724\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.81724\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.81724\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.81724\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.81724 to 0.82209, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00014: val_accuracy improved from 0.82209 to 0.83163, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.83163\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.83163\n",
      "\n",
      "Epoch 00017: val_accuracy improved from 0.83163 to 0.84435, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00018: val_accuracy improved from 0.84435 to 0.85105, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.85105\n",
      "\n",
      "Epoch 00020: val_accuracy improved from 0.85105 to 0.85155, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.85155\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.85155\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.85155\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.85155\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.85155\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.85155\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.85155\n",
      "\n",
      "Epoch 00028: val_accuracy improved from 0.85155 to 0.85389, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.85389\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.85389\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.85389\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.85389\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.85389\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.85389\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.85389\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.85389\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.85389\n",
      "\n",
      "Epoch 00038: val_accuracy improved from 0.85389 to 0.85607, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.85607\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.85607\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.85607\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.85607\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.85607\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.85607\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.85607\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.85607\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.85607\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.85607\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.85607\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.85607\n",
      "SCORE: 0.85607 at epoch 38\n",
      "Compilation Time :  0.002217531204223633\n",
      "Model: \"model_24\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_49 (InputLayer)           [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_72 (LSTM)                  (None, 240, 256)     265216      input_49[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_73 (LSTM)                  (None, 240, 256)     525312      lstm_72[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_74 (LSTM)                  (None, 256)          525312      lstm_73[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_50 (InputLayer)           [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_192 (Dense)               (None, 128)          32896       lstm_74[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_195 (Dense)               (None, 128)          384         input_50[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_193 (Dense)               (None, 64)           8256        dense_192[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_196 (Dense)               (None, 64)           8256        dense_195[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_194 (Dense)               (None, 32)           2080        dense_193[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_197 (Dense)               (None, 32)           2080        dense_196[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_24 (Concatenate)    (None, 64)           0           dense_194[0][0]                  \n",
      "                                                                 dense_197[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_198 (Dense)               (None, 8)            520         concatenate_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_199 (Dense)               (None, 1)            9           dense_198[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 1)            0           dense_199[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,370,321\n",
      "Trainable params: 1,370,321\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (25/32) *****\n",
      "Search({'dr1': 0.2, 'dr2': 0.2, 'dr3': 0.1, 'unit': 256, 'lr': 0.01, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.74410, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.74410\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.74410\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.74410\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.74410\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.74410\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.74410\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.74410\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.74410 to 0.75933, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.75933\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.75933\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.75933\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.75933\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.75933\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.75933\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.75933\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.75933\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.75933\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.75933\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.75933\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.75933\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.75933\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.75933\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.75933\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.75933\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.75933\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.75933\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.75933\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.75933\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.75933\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.75933\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.75933\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.75933\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.75933\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.75933\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.75933\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.75933\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.75933\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.75933\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.75933\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.75933\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.75933\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.75933\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.75933\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.75933\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.75933\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.75933\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.75933\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.75933\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.75933\n",
      "SCORE: 0.75933 at epoch 9\n",
      "Compilation Time :  0.0021963119506835938\n",
      "Model: \"model_25\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_51 (InputLayer)           [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_75 (LSTM)                  (None, 240, 256)     265216      input_51[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_76 (LSTM)                  (None, 240, 256)     525312      lstm_75[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_77 (LSTM)                  (None, 256)          525312      lstm_76[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_52 (InputLayer)           [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_200 (Dense)               (None, 128)          32896       lstm_77[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_203 (Dense)               (None, 128)          384         input_52[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_201 (Dense)               (None, 64)           8256        dense_200[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_204 (Dense)               (None, 64)           8256        dense_203[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_202 (Dense)               (None, 32)           2080        dense_201[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_205 (Dense)               (None, 32)           2080        dense_204[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_25 (Concatenate)    (None, 64)           0           dense_202[0][0]                  \n",
      "                                                                 dense_205[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_206 (Dense)               (None, 8)            520         concatenate_25[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_207 (Dense)               (None, 1)            9           dense_206[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 1)            0           dense_207[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,370,321\n",
      "Trainable params: 1,370,321\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (26/32) *****\n",
      "Search({'dr1': 0.2, 'dr2': 0.2, 'dr3': 0.1, 'unit': 256, 'lr': 0.001, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.75615, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.75615\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.75615 to 0.76100, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.76100\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.76100\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.76100 to 0.80285, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.80285\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.80285 to 0.80335, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.80335 to 0.81925, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.81925\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.81925\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.81925\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.81925\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.81925\n",
      "\n",
      "Epoch 00015: val_accuracy improved from 0.81925 to 0.81958, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.81958\n",
      "\n",
      "Epoch 00017: val_accuracy improved from 0.81958 to 0.83146, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.83146\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.83146\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.83146\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.83146\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.83146\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.83146\n",
      "\n",
      "Epoch 00024: val_accuracy improved from 0.83146 to 0.83950, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.83950\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.83950\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.83950\n",
      "\n",
      "Epoch 00028: val_accuracy improved from 0.83950 to 0.84285, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00029: val_accuracy improved from 0.84285 to 0.85506, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.85506\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.85506\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.85506\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.85506\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.85506\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.85506\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.85506\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.85506\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.85506\n",
      "\n",
      "Epoch 00039: val_accuracy improved from 0.85506 to 0.85640, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.85640\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.85640\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.85640\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.85640\n",
      "\n",
      "Epoch 00044: val_accuracy improved from 0.85640 to 0.85808, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.85808\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.85808\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.85808\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.85808\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.85808\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.85808\n",
      "SCORE: 0.85808 at epoch 44\n",
      "Compilation Time :  0.0022084712982177734\n",
      "Model: \"model_26\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_53 (InputLayer)           [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_78 (LSTM)                  (None, 240, 384)     594432      input_53[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_79 (LSTM)                  (None, 240, 384)     1181184     lstm_78[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_80 (LSTM)                  (None, 384)          1181184     lstm_79[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_54 (InputLayer)           [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_208 (Dense)               (None, 128)          49280       lstm_80[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_211 (Dense)               (None, 128)          384         input_54[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_209 (Dense)               (None, 64)           8256        dense_208[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_212 (Dense)               (None, 64)           8256        dense_211[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_210 (Dense)               (None, 32)           2080        dense_209[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_213 (Dense)               (None, 32)           2080        dense_212[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_26 (Concatenate)    (None, 64)           0           dense_210[0][0]                  \n",
      "                                                                 dense_213[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_214 (Dense)               (None, 8)            520         concatenate_26[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_215 (Dense)               (None, 1)            9           dense_214[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 1)            0           dense_215[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,027,665\n",
      "Trainable params: 3,027,665\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (27/32) *****\n",
      "Search({'dr1': 0.2, 'dr2': 0.2, 'dr3': 0.1, 'unit': 384, 'lr': 0.01, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.63481, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.63481\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.63481\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.63481\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.63481 to 0.63515, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.63515 to 0.66393, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.66393\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.66393\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.66393\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.66393\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.66393 to 0.70159, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.70159\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.70159 to 0.72435, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.72435\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.72435\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.72435\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.72435\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.72435\n",
      "\n",
      "Epoch 00019: val_accuracy improved from 0.72435 to 0.75799, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.75799\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.75799\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.75799\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.75799\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.75799\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.75799\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.75799\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.75799\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.75799\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.75799\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.75799\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.75799\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.75799\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.75799\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.75799\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.75799\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.75799\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.75799\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.75799\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.75799\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.75799\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.75799\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.75799\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.75799\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.75799\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.75799\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.75799\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.75799\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.75799\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.75799\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.75799\n",
      "SCORE: 0.75799 at epoch 19\n",
      "Compilation Time :  0.0021800994873046875\n",
      "Model: \"model_27\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_55 (InputLayer)           [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_81 (LSTM)                  (None, 240, 384)     594432      input_55[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_82 (LSTM)                  (None, 240, 384)     1181184     lstm_81[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_83 (LSTM)                  (None, 384)          1181184     lstm_82[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_56 (InputLayer)           [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_216 (Dense)               (None, 128)          49280       lstm_83[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_219 (Dense)               (None, 128)          384         input_56[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_217 (Dense)               (None, 64)           8256        dense_216[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_220 (Dense)               (None, 64)           8256        dense_219[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_218 (Dense)               (None, 32)           2080        dense_217[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_221 (Dense)               (None, 32)           2080        dense_220[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_27 (Concatenate)    (None, 64)           0           dense_218[0][0]                  \n",
      "                                                                 dense_221[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_222 (Dense)               (None, 8)            520         concatenate_27[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_223 (Dense)               (None, 1)            9           dense_222[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 1)            0           dense_223[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,027,665\n",
      "Trainable params: 3,027,665\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (28/32) *****\n",
      "Search({'dr1': 0.2, 'dr2': 0.2, 'dr3': 0.1, 'unit': 384, 'lr': 0.001, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.75582, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.75582\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.75582 to 0.77088, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.77088\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.77088\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.77088 to 0.78008, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.78008\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.78008\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.78008 to 0.79230, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.79230\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.79230\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.79230\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.79230\n",
      "\n",
      "Epoch 00014: val_accuracy improved from 0.79230 to 0.80000, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00015: val_accuracy improved from 0.80000 to 0.81992, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.81992\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.81992\n",
      "\n",
      "Epoch 00018: val_accuracy improved from 0.81992 to 0.83347, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.83347\n",
      "\n",
      "Epoch 00020: val_accuracy improved from 0.83347 to 0.84067, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.84067\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.84067\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.84067\n",
      "\n",
      "Epoch 00024: val_accuracy improved from 0.84067 to 0.84736, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.84736\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.84736\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.84736\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.84736\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.84736\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.84736\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.84736\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.84736\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.84736\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.84736\n",
      "\n",
      "Epoch 00035: val_accuracy improved from 0.84736 to 0.85071, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.85071\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.85071\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.85071\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.85071\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.85071\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.85071\n",
      "\n",
      "Epoch 00042: val_accuracy improved from 0.85071 to 0.85255, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.85255\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.85255\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.85255\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.85255\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.85255\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.85255\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.85255\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.85255\n",
      "SCORE: 0.85255 at epoch 42\n",
      "Compilation Time :  0.0021982192993164062\n",
      "Model: \"model_28\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_57 (InputLayer)           [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_84 (LSTM)                  (None, 240, 256)     265216      input_57[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_85 (LSTM)                  (None, 240, 256)     525312      lstm_84[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_86 (LSTM)                  (None, 256)          525312      lstm_85[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_58 (InputLayer)           [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_224 (Dense)               (None, 128)          32896       lstm_86[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_227 (Dense)               (None, 128)          384         input_58[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_225 (Dense)               (None, 64)           8256        dense_224[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_228 (Dense)               (None, 64)           8256        dense_227[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_226 (Dense)               (None, 32)           2080        dense_225[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_229 (Dense)               (None, 32)           2080        dense_228[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_28 (Concatenate)    (None, 64)           0           dense_226[0][0]                  \n",
      "                                                                 dense_229[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_230 (Dense)               (None, 8)            520         concatenate_28[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_231 (Dense)               (None, 1)            9           dense_230[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 1)            0           dense_231[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,370,321\n",
      "Trainable params: 1,370,321\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (29/32) *****\n",
      "Search({'dr1': 0.2, 'dr2': 0.2, 'dr3': 0.2, 'unit': 256, 'lr': 0.01, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.66259, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.66259 to 0.72669, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.72669\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.72669 to 0.74895, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.74895\n",
      "SCORE: 0.74895 at epoch 4\n",
      "Compilation Time :  0.002208232879638672\n",
      "Model: \"model_29\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_59 (InputLayer)           [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_87 (LSTM)                  (None, 240, 256)     265216      input_59[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_88 (LSTM)                  (None, 240, 256)     525312      lstm_87[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_89 (LSTM)                  (None, 256)          525312      lstm_88[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_60 (InputLayer)           [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_232 (Dense)               (None, 128)          32896       lstm_89[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_235 (Dense)               (None, 128)          384         input_60[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_233 (Dense)               (None, 64)           8256        dense_232[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_236 (Dense)               (None, 64)           8256        dense_235[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_234 (Dense)               (None, 32)           2080        dense_233[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_237 (Dense)               (None, 32)           2080        dense_236[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_29 (Concatenate)    (None, 64)           0           dense_234[0][0]                  \n",
      "                                                                 dense_237[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_238 (Dense)               (None, 8)            520         concatenate_29[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_239 (Dense)               (None, 1)            9           dense_238[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 1)            0           dense_239[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,370,321\n",
      "Trainable params: 1,370,321\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (30/32) *****\n",
      "Search({'dr1': 0.2, 'dr2': 0.2, 'dr3': 0.2, 'unit': 256, 'lr': 0.001, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.69473, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.69473\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.69473 to 0.75230, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.75230 to 0.75916, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.75916 to 0.78728, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.78728\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.78728\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.78728 to 0.79732, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.79732\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.79732\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.79732\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.79732\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.79732\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.79732\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.79732\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.79732\n",
      "\n",
      "Epoch 00017: val_accuracy improved from 0.79732 to 0.80033, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.80033\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.80033\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.80033\n",
      "\n",
      "Epoch 00021: val_accuracy improved from 0.80033 to 0.81439, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00022: val_accuracy improved from 0.81439 to 0.83146, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.83146\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.83146\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.83146\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.83146\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.83146\n",
      "\n",
      "Epoch 00028: val_accuracy improved from 0.83146 to 0.84285, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.84285\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.84285\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.84285\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.84285\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.84285\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.84285\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.84285\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.84285\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.84285\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.84285\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.84285\n",
      "\n",
      "Epoch 00040: val_accuracy improved from 0.84285 to 0.84402, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.84402\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.84402\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.84402\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.84402\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.84402\n",
      "\n",
      "Epoch 00046: val_accuracy improved from 0.84402 to 0.84536, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.84536\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.84536\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.84536\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.84536\n",
      "SCORE: 0.84536 at epoch 46\n",
      "Compilation Time :  0.0022499561309814453\n",
      "Model: \"model_30\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_61 (InputLayer)           [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_90 (LSTM)                  (None, 240, 384)     594432      input_61[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_91 (LSTM)                  (None, 240, 384)     1181184     lstm_90[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_92 (LSTM)                  (None, 384)          1181184     lstm_91[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_62 (InputLayer)           [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_240 (Dense)               (None, 128)          49280       lstm_92[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_243 (Dense)               (None, 128)          384         input_62[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_241 (Dense)               (None, 64)           8256        dense_240[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_244 (Dense)               (None, 64)           8256        dense_243[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_242 (Dense)               (None, 32)           2080        dense_241[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_245 (Dense)               (None, 32)           2080        dense_244[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_30 (Concatenate)    (None, 64)           0           dense_242[0][0]                  \n",
      "                                                                 dense_245[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_246 (Dense)               (None, 8)            520         concatenate_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_247 (Dense)               (None, 1)            9           dense_246[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 1)            0           dense_247[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,027,665\n",
      "Trainable params: 3,027,665\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (31/32) *****\n",
      "Search({'dr1': 0.2, 'dr2': 0.2, 'dr3': 0.2, 'unit': 384, 'lr': 0.01, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.63481, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.63481\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.63481\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.63481\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.63481\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.63481\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.63481\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.63481\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.63481\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.63481\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.63481\n",
      "\n",
      "Epoch 00012: val_accuracy improved from 0.63481 to 0.66393, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.66393\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.66393\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.66393\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.66393\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.66393\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.66393\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.66393\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.66393\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.66393\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.66393\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.66393\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.66393\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.66393\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.66393\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.66393\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.66393\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.66393\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.66393\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.66393\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.66393\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.66393\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.66393\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.66393\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.66393\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.66393\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.66393\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.66393\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.66393\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.66393\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.66393\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.66393\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.66393\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.66393\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.66393\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.66393\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.66393\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.66393\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.66393\n",
      "SCORE: 0.66393 at epoch 12\n",
      "Compilation Time :  0.002197265625\n",
      "Model: \"model_31\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_63 (InputLayer)           [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_93 (LSTM)                  (None, 240, 384)     594432      input_63[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_94 (LSTM)                  (None, 240, 384)     1181184     lstm_93[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_95 (LSTM)                  (None, 384)          1181184     lstm_94[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_64 (InputLayer)           [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_248 (Dense)               (None, 128)          49280       lstm_95[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_251 (Dense)               (None, 128)          384         input_64[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_249 (Dense)               (None, 64)           8256        dense_248[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_252 (Dense)               (None, 64)           8256        dense_251[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_250 (Dense)               (None, 32)           2080        dense_249[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_253 (Dense)               (None, 32)           2080        dense_252[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_31 (Concatenate)    (None, 64)           0           dense_250[0][0]                  \n",
      "                                                                 dense_253[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_254 (Dense)               (None, 8)            520         concatenate_31[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_255 (Dense)               (None, 1)            9           dense_254[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 1)            0           dense_255[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,027,665\n",
      "Trainable params: 3,027,665\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (32/32) *****\n",
      "Search({'dr1': 0.2, 'dr2': 0.2, 'dr3': 0.2, 'unit': 384, 'lr': 0.001, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.74477, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.74477\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.74477 to 0.75180, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.75180 to 0.76837, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.76837 to 0.78594, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.78594\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.78594\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.78594\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.78594 to 0.80569, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.80569\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.80569\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.80569\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.80569\n",
      "\n",
      "Epoch 00014: val_accuracy improved from 0.80569 to 0.81640, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00015: val_accuracy improved from 0.81640 to 0.83013, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00016: val_accuracy improved from 0.83013 to 0.83732, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00017: val_accuracy improved from 0.83732 to 0.83833, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.83833\n",
      "\n",
      "Epoch 00019: val_accuracy improved from 0.83833 to 0.84017, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00020: val_accuracy improved from 0.84017 to 0.84418, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.84418\n",
      "\n",
      "Epoch 00022: val_accuracy improved from 0.84418 to 0.84703, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.84703\n",
      "\n",
      "Epoch 00024: val_accuracy improved from 0.84703 to 0.84736, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00025: val_accuracy improved from 0.84736 to 0.85222, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.85222\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.85222\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.85222\n",
      "\n",
      "Epoch 00029: val_accuracy improved from 0.85222 to 0.86192, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.86192\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.86192\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.86192\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.86192\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.86192\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.86192\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.86192\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.86192\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.86192\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.86192\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.86192\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.86192\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.86192\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.86192\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.86192\n",
      "\n",
      "Epoch 00045: val_accuracy improved from 0.86192 to 0.86276, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.86276\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.86276\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.86276\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.86276\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.86276\n",
      "SCORE: 0.86276 at epoch 45\n",
      "\n",
      "##################\n",
      "###  Fold 002  ###\n",
      "##################\n",
      "\n",
      "32 trials detected for ('dr1', 'dr2', 'dr3', 'unit', 'lr', 'epochs', 'batch_size')\n",
      "Compilation Time :  0.002187490463256836\n",
      "Model: \"model_32\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_65 (InputLayer)           [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_96 (LSTM)                  (None, 240, 256)     265216      input_65[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_97 (LSTM)                  (None, 240, 256)     525312      lstm_96[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_98 (LSTM)                  (None, 256)          525312      lstm_97[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_66 (InputLayer)           [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_256 (Dense)               (None, 128)          32896       lstm_98[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_259 (Dense)               (None, 128)          384         input_66[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_257 (Dense)               (None, 64)           8256        dense_256[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_260 (Dense)               (None, 64)           8256        dense_259[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_258 (Dense)               (None, 32)           2080        dense_257[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_261 (Dense)               (None, 32)           2080        dense_260[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_32 (Concatenate)    (None, 64)           0           dense_258[0][0]                  \n",
      "                                                                 dense_261[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_262 (Dense)               (None, 8)            520         concatenate_32[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_263 (Dense)               (None, 1)            9           dense_262[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 1)            0           dense_263[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,370,321\n",
      "Trainable params: 1,370,321\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (1/32) *****\n",
      "Search({'dr1': 0.1, 'dr2': 0.1, 'dr3': 0.1, 'unit': 256, 'lr': 0.01, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.62126, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.62126 to 0.73757, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.73757\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.73757\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.73757 to 0.75397, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.75397\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.75397\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.75397\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.75397\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.75397\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.75397\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.75397\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.75397\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.75397\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.75397\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.75397\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.75397\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.75397\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.75397\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.75397\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.75397\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.75397\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.75397\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.75397\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.75397\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.75397\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.75397\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.75397\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.75397\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.75397\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.75397\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.75397\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.75397\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.75397\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.75397\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.75397\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.75397\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.75397\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.75397\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.75397\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.75397\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.75397\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.75397\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.75397\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.75397\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.75397\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.75397\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.75397\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.75397\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.75397\n",
      "SCORE: 0.75397 at epoch 5\n",
      "Compilation Time :  0.0021796226501464844\n",
      "Model: \"model_33\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_67 (InputLayer)           [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_99 (LSTM)                  (None, 240, 256)     265216      input_67[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_100 (LSTM)                 (None, 240, 256)     525312      lstm_99[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_101 (LSTM)                 (None, 256)          525312      lstm_100[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_68 (InputLayer)           [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_264 (Dense)               (None, 128)          32896       lstm_101[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_267 (Dense)               (None, 128)          384         input_68[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_265 (Dense)               (None, 64)           8256        dense_264[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_268 (Dense)               (None, 64)           8256        dense_267[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_266 (Dense)               (None, 32)           2080        dense_265[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_269 (Dense)               (None, 32)           2080        dense_268[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_33 (Concatenate)    (None, 64)           0           dense_266[0][0]                  \n",
      "                                                                 dense_269[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_270 (Dense)               (None, 8)            520         concatenate_33[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_271 (Dense)               (None, 1)            9           dense_270[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 1)            0           dense_271[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,370,321\n",
      "Trainable params: 1,370,321\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (2/32) *****\n",
      "Search({'dr1': 0.1, 'dr2': 0.1, 'dr3': 0.1, 'unit': 256, 'lr': 0.001, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.74795, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.74795 to 0.75699, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.75699 to 0.80067, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.80067\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.80067 to 0.80803, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.80803\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.80803\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.80803 to 0.82494, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.82494\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.82494\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.82494\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.82494\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.82494 to 0.84033, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00014: val_accuracy improved from 0.84033 to 0.84536, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.84536\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.84536\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.84536\n",
      "\n",
      "Epoch 00018: val_accuracy improved from 0.84536 to 0.84887, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00019: val_accuracy improved from 0.84887 to 0.86008, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.86008\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.86008\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.86008\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.86008\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.86008\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.86008\n",
      "\n",
      "Epoch 00026: val_accuracy improved from 0.86008 to 0.86661, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.86661\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.86661\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.86661\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.86661\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.86661\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.86661\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.86661\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.86661\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.86661\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.86661\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.86661\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.86661\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.86661\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.86661\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.86661\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.86661\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.86661\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.86661\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.86661\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.86661\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.86661\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.86661\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.86661\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.86661\n",
      "SCORE: 0.86661 at epoch 26\n",
      "Compilation Time :  0.0022020339965820312\n",
      "Model: \"model_34\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_69 (InputLayer)           [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_102 (LSTM)                 (None, 240, 384)     594432      input_69[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_103 (LSTM)                 (None, 240, 384)     1181184     lstm_102[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_104 (LSTM)                 (None, 384)          1181184     lstm_103[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_70 (InputLayer)           [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_272 (Dense)               (None, 128)          49280       lstm_104[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_275 (Dense)               (None, 128)          384         input_70[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_273 (Dense)               (None, 64)           8256        dense_272[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_276 (Dense)               (None, 64)           8256        dense_275[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_274 (Dense)               (None, 32)           2080        dense_273[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_277 (Dense)               (None, 32)           2080        dense_276[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_34 (Concatenate)    (None, 64)           0           dense_274[0][0]                  \n",
      "                                                                 dense_277[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_278 (Dense)               (None, 8)            520         concatenate_34[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_279 (Dense)               (None, 1)            9           dense_278[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 1)            0           dense_279[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,027,665\n",
      "Trainable params: 3,027,665\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (3/32) *****\n",
      "Search({'dr1': 0.1, 'dr2': 0.1, 'dr3': 0.1, 'unit': 384, 'lr': 0.01, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.73138, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.73138\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.73138\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.73138 to 0.75816, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.75816\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.75816\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.75816\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.75816\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.75816\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.75816\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.75816\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.75816\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.75816 to 0.76201, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.76201\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.76201\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.76201\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.76201\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.76201\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.76201\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.76201\n",
      "\n",
      "Epoch 00021: val_accuracy improved from 0.76201 to 0.76686, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.76686\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.76686\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.76686\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.76686\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.76686\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.76686\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.76686\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.76686\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.76686\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.76686\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.76686\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.76686\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.76686\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.76686\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.76686\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.76686\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.76686\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.76686\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.76686\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.76686\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.76686\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.76686\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.76686\n",
      "\n",
      "Epoch 00045: val_accuracy improved from 0.76686 to 0.76787, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.76787\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.76787\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.76787\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.76787\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.76787\n",
      "SCORE: 0.76787 at epoch 45\n",
      "Compilation Time :  0.0021820068359375\n",
      "Model: \"model_35\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_71 (InputLayer)           [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_105 (LSTM)                 (None, 240, 384)     594432      input_71[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_106 (LSTM)                 (None, 240, 384)     1181184     lstm_105[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_107 (LSTM)                 (None, 384)          1181184     lstm_106[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_72 (InputLayer)           [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_280 (Dense)               (None, 128)          49280       lstm_107[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_283 (Dense)               (None, 128)          384         input_72[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_281 (Dense)               (None, 64)           8256        dense_280[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_284 (Dense)               (None, 64)           8256        dense_283[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_282 (Dense)               (None, 32)           2080        dense_281[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_285 (Dense)               (None, 32)           2080        dense_284[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_35 (Concatenate)    (None, 64)           0           dense_282[0][0]                  \n",
      "                                                                 dense_285[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_286 (Dense)               (None, 8)            520         concatenate_35[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_287 (Dense)               (None, 1)            9           dense_286[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 1)            0           dense_287[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,027,665\n",
      "Trainable params: 3,027,665\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (4/32) *****\n",
      "Search({'dr1': 0.1, 'dr2': 0.1, 'dr3': 0.1, 'unit': 384, 'lr': 0.001, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.74745, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.74745 to 0.79883, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.79883\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.79883 to 0.80435, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.80435\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.80435 to 0.81925, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.81925 to 0.83063, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.83063\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.83063\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.83063\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.83063\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.83063\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.83063\n",
      "\n",
      "Epoch 00014: val_accuracy improved from 0.83063 to 0.84084, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.84084\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.84084\n",
      "\n",
      "Epoch 00017: val_accuracy improved from 0.84084 to 0.84954, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00018: val_accuracy improved from 0.84954 to 0.85071, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.85071\n",
      "\n",
      "Epoch 00020: val_accuracy improved from 0.85071 to 0.85757, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.85757\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.85757\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.85757\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.85757\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.85757\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.85757\n",
      "\n",
      "Epoch 00027: val_accuracy improved from 0.85757 to 0.86109, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.86109\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.86109\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.86109\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.86109\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.86109\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.86109\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.86109\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.86109\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.86109\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.86109\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.86109\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.86109\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.86109\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.86109\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.86109\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.86109\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.86109\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.86109\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.86109\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.86109\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.86109\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.86109\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.86109\n",
      "SCORE: 0.86109 at epoch 27\n",
      "Compilation Time :  0.0022242069244384766\n",
      "Model: \"model_36\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_73 (InputLayer)           [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_108 (LSTM)                 (None, 240, 256)     265216      input_73[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_109 (LSTM)                 (None, 240, 256)     525312      lstm_108[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_110 (LSTM)                 (None, 256)          525312      lstm_109[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_74 (InputLayer)           [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_288 (Dense)               (None, 128)          32896       lstm_110[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_291 (Dense)               (None, 128)          384         input_74[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_289 (Dense)               (None, 64)           8256        dense_288[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_292 (Dense)               (None, 64)           8256        dense_291[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_290 (Dense)               (None, 32)           2080        dense_289[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_293 (Dense)               (None, 32)           2080        dense_292[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_36 (Concatenate)    (None, 64)           0           dense_290[0][0]                  \n",
      "                                                                 dense_293[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_294 (Dense)               (None, 8)            520         concatenate_36[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_295 (Dense)               (None, 1)            9           dense_294[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 1)            0           dense_295[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,370,321\n",
      "Trainable params: 1,370,321\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (5/32) *****\n",
      "Search({'dr1': 0.1, 'dr2': 0.1, 'dr3': 0.2, 'unit': 256, 'lr': 0.01, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.70979, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.70979 to 0.72536, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.72536 to 0.73640, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.73640\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.73640\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.73640\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.73640\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.73640\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.73640\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.73640\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.73640\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.73640\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.73640\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.73640\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.73640\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.73640\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.73640\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.73640\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.73640\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.73640\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.73640\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.73640\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.73640\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.73640\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.73640\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.73640\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.73640\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.73640\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.73640\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.73640\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.73640\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.73640\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.73640\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.73640\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.73640\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.73640\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.73640\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.73640\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.73640\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.73640\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.73640\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.73640\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.73640\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.73640\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.73640\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.73640\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.73640\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.73640\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.73640\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.73640\n",
      "SCORE: 0.7364 at epoch 3\n",
      "Compilation Time :  0.0022132396697998047\n",
      "Model: \"model_37\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_75 (InputLayer)           [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_111 (LSTM)                 (None, 240, 256)     265216      input_75[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_112 (LSTM)                 (None, 240, 256)     525312      lstm_111[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_113 (LSTM)                 (None, 256)          525312      lstm_112[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_76 (InputLayer)           [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_296 (Dense)               (None, 128)          32896       lstm_113[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_299 (Dense)               (None, 128)          384         input_76[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_297 (Dense)               (None, 64)           8256        dense_296[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_300 (Dense)               (None, 64)           8256        dense_299[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_298 (Dense)               (None, 32)           2080        dense_297[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_301 (Dense)               (None, 32)           2080        dense_300[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_37 (Concatenate)    (None, 64)           0           dense_298[0][0]                  \n",
      "                                                                 dense_301[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_302 (Dense)               (None, 8)            520         concatenate_37[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_303 (Dense)               (None, 1)            9           dense_302[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 1)            0           dense_303[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,370,321\n",
      "Trainable params: 1,370,321\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (6/32) *****\n",
      "Search({'dr1': 0.1, 'dr2': 0.1, 'dr3': 0.2, 'unit': 256, 'lr': 0.001, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.78678, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.78678\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.78678 to 0.79766, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.79766 to 0.81607, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.81607\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.81607 to 0.82393, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.82393 to 0.83314, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.83314 to 0.83615, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.83615\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.83615\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.83615\n",
      "\n",
      "Epoch 00012: val_accuracy improved from 0.83615 to 0.84385, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.84385 to 0.84653, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00014: val_accuracy improved from 0.84653 to 0.84921, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.84921\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.84921\n",
      "\n",
      "Epoch 00017: val_accuracy improved from 0.84921 to 0.85155, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00018: val_accuracy improved from 0.85155 to 0.85925, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.85925\n",
      "\n",
      "Epoch 00020: val_accuracy improved from 0.85925 to 0.86142, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.86142\n",
      "\n",
      "Epoch 00022: val_accuracy improved from 0.86142 to 0.86510, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.86510\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.86510\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.86510\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.86510\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.86510\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.86510\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.86510\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.86510\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.86510\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.86510\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.86510\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.86510\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.86510\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.86510\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.86510\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.86510\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.86510\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.86510\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.86510\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.86510\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.86510\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.86510\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.86510\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.86510\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.86510\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.86510\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.86510\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.86510\n",
      "SCORE: 0.8651 at epoch 22\n",
      "Compilation Time :  0.0021800994873046875\n",
      "Model: \"model_38\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_77 (InputLayer)           [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_114 (LSTM)                 (None, 240, 384)     594432      input_77[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_115 (LSTM)                 (None, 240, 384)     1181184     lstm_114[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_116 (LSTM)                 (None, 384)          1181184     lstm_115[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_78 (InputLayer)           [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_304 (Dense)               (None, 128)          49280       lstm_116[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_307 (Dense)               (None, 128)          384         input_78[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_305 (Dense)               (None, 64)           8256        dense_304[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_308 (Dense)               (None, 64)           8256        dense_307[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_306 (Dense)               (None, 32)           2080        dense_305[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_309 (Dense)               (None, 32)           2080        dense_308[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_38 (Concatenate)    (None, 64)           0           dense_306[0][0]                  \n",
      "                                                                 dense_309[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_310 (Dense)               (None, 8)            520         concatenate_38[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_311 (Dense)               (None, 1)            9           dense_310[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 1)            0           dense_311[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,027,665\n",
      "Trainable params: 3,027,665\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (7/32) *****\n",
      "Search({'dr1': 0.1, 'dr2': 0.1, 'dr3': 0.2, 'unit': 384, 'lr': 0.01, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.68084, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.68084\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.68084\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.68084 to 0.74293, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.74293\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.74293\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.74293\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.74293\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.74293\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.74293 to 0.74577, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.74577\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.74577\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.74577\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.74577\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.74577\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.74577\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.74577\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.74577\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.74577\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.74577\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.74577\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.74577\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.74577\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.74577\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.74577\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.74577\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.74577\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.74577\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.74577\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.74577\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.74577\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.74577\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.74577\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.74577\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.74577\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.74577\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.74577\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.74577\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.74577\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.74577\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.74577\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.74577\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.74577\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.74577\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.74577\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.74577\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.74577\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.74577\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.74577\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.74577\n",
      "SCORE: 0.74577 at epoch 10\n",
      "Compilation Time :  0.002236604690551758\n",
      "Model: \"model_39\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_79 (InputLayer)           [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_117 (LSTM)                 (None, 240, 384)     594432      input_79[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_118 (LSTM)                 (None, 240, 384)     1181184     lstm_117[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_119 (LSTM)                 (None, 384)          1181184     lstm_118[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_80 (InputLayer)           [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_312 (Dense)               (None, 128)          49280       lstm_119[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_315 (Dense)               (None, 128)          384         input_80[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_313 (Dense)               (None, 64)           8256        dense_312[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_316 (Dense)               (None, 64)           8256        dense_315[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_314 (Dense)               (None, 32)           2080        dense_313[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_317 (Dense)               (None, 32)           2080        dense_316[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_39 (Concatenate)    (None, 64)           0           dense_314[0][0]                  \n",
      "                                                                 dense_317[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_318 (Dense)               (None, 8)            520         concatenate_39[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_319 (Dense)               (None, 1)            9           dense_318[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 1)            0           dense_319[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,027,665\n",
      "Trainable params: 3,027,665\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (8/32) *****\n",
      "Search({'dr1': 0.1, 'dr2': 0.1, 'dr3': 0.2, 'unit': 384, 'lr': 0.001, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.77088, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.77088 to 0.77356, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.77356 to 0.79414, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.79414\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.79414\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.79414 to 0.80151, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.80151 to 0.80268, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.80268\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.80268\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.80268\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.80268 to 0.81757, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.81757\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.81757 to 0.82176, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00014: val_accuracy improved from 0.82176 to 0.84100, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.84100\n",
      "\n",
      "Epoch 00016: val_accuracy improved from 0.84100 to 0.84502, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.84502\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.84502\n",
      "\n",
      "Epoch 00019: val_accuracy improved from 0.84502 to 0.84736, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00020: val_accuracy improved from 0.84736 to 0.84753, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00021: val_accuracy improved from 0.84753 to 0.85021, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.85021\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.85021\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.85021\n",
      "\n",
      "Epoch 00025: val_accuracy improved from 0.85021 to 0.85322, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.85322\n",
      "\n",
      "Epoch 00027: val_accuracy improved from 0.85322 to 0.85590, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00028: val_accuracy improved from 0.85590 to 0.85841, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.85841\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.85841\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.85841\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.85841\n",
      "\n",
      "Epoch 00033: val_accuracy improved from 0.85841 to 0.86209, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.86209\n",
      "\n",
      "Epoch 00035: val_accuracy improved from 0.86209 to 0.86527, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.86527\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.86527\n",
      "\n",
      "Epoch 00038: val_accuracy improved from 0.86527 to 0.86728, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.86728\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.86728\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.86728\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.86728\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.86728\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.86728\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.86728\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.86728\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.86728\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.86728\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.86728\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.86728\n",
      "SCORE: 0.86728 at epoch 38\n",
      "Compilation Time :  0.0022797584533691406\n",
      "Model: \"model_40\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_81 (InputLayer)           [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_120 (LSTM)                 (None, 240, 256)     265216      input_81[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_121 (LSTM)                 (None, 240, 256)     525312      lstm_120[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_122 (LSTM)                 (None, 256)          525312      lstm_121[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_82 (InputLayer)           [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_320 (Dense)               (None, 128)          32896       lstm_122[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_323 (Dense)               (None, 128)          384         input_82[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_321 (Dense)               (None, 64)           8256        dense_320[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_324 (Dense)               (None, 64)           8256        dense_323[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_322 (Dense)               (None, 32)           2080        dense_321[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_325 (Dense)               (None, 32)           2080        dense_324[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_40 (Concatenate)    (None, 64)           0           dense_322[0][0]                  \n",
      "                                                                 dense_325[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_326 (Dense)               (None, 8)            520         concatenate_40[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_327 (Dense)               (None, 1)            9           dense_326[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 1)            0           dense_327[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,370,321\n",
      "Trainable params: 1,370,321\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (9/32) *****\n",
      "Search({'dr1': 0.1, 'dr2': 0.2, 'dr3': 0.1, 'unit': 256, 'lr': 0.01, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.60619, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.60619 to 0.76167, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.76167\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.76167\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.76167\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.76167\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.76167\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.76167\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.76167\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.76167\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.76167\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.76167\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.76167\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.76167\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.76167\n",
      "\n",
      "Epoch 00016: val_accuracy improved from 0.76167 to 0.76469, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.76469\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.76469\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.76469\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.76469\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.76469\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.76469\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.76469\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.76469\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.76469\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.76469\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.76469\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.76469\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.76469\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.76469\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.76469\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.76469\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.76469\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.76469\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.76469\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.76469\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.76469\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.76469\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.76469\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.76469\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.76469\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.76469\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.76469\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.76469\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.76469\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.76469\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.76469\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.76469\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.76469\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.76469\n",
      "SCORE: 0.76469 at epoch 16\n",
      "Compilation Time :  0.002187013626098633\n",
      "Model: \"model_41\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_83 (InputLayer)           [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_123 (LSTM)                 (None, 240, 256)     265216      input_83[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_124 (LSTM)                 (None, 240, 256)     525312      lstm_123[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_125 (LSTM)                 (None, 256)          525312      lstm_124[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_84 (InputLayer)           [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_328 (Dense)               (None, 128)          32896       lstm_125[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_331 (Dense)               (None, 128)          384         input_84[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_329 (Dense)               (None, 64)           8256        dense_328[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_332 (Dense)               (None, 64)           8256        dense_331[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_330 (Dense)               (None, 32)           2080        dense_329[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_333 (Dense)               (None, 32)           2080        dense_332[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_41 (Concatenate)    (None, 64)           0           dense_330[0][0]                  \n",
      "                                                                 dense_333[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_334 (Dense)               (None, 8)            520         concatenate_41[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_335 (Dense)               (None, 1)            9           dense_334[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 1)            0           dense_335[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,370,321\n",
      "Trainable params: 1,370,321\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (10/32) *****\n",
      "Search({'dr1': 0.1, 'dr2': 0.2, 'dr3': 0.1, 'unit': 256, 'lr': 0.001, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.79883, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.79883\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.79883\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.79883 to 0.80736, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.80736\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.80736 to 0.81808, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.81808 to 0.81992, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.81992 to 0.83046, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.83046 to 0.83331, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.83331 to 0.83381, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.83381\n",
      "\n",
      "Epoch 00012: val_accuracy improved from 0.83381 to 0.83548, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.83548 to 0.84753, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.84753\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.84753\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.84753\n",
      "\n",
      "Epoch 00017: val_accuracy improved from 0.84753 to 0.84887, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.84887\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.84887\n",
      "\n",
      "Epoch 00020: val_accuracy improved from 0.84887 to 0.85155, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.85155\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.85155\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.85155\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.85155\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.85155\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.85155\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.85155\n",
      "\n",
      "Epoch 00028: val_accuracy improved from 0.85155 to 0.86142, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.86142\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.86142\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.86142\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.86142\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.86142\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.86142\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.86142\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.86142\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.86142\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.86142\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.86142\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.86142\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.86142\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.86142\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.86142\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.86142\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.86142\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.86142\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.86142\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.86142\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.86142\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.86142\n",
      "SCORE: 0.86142 at epoch 28\n",
      "Compilation Time :  0.002179861068725586\n",
      "Model: \"model_42\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_85 (InputLayer)           [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_126 (LSTM)                 (None, 240, 384)     594432      input_85[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_127 (LSTM)                 (None, 240, 384)     1181184     lstm_126[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_128 (LSTM)                 (None, 384)          1181184     lstm_127[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_86 (InputLayer)           [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_336 (Dense)               (None, 128)          49280       lstm_128[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_339 (Dense)               (None, 128)          384         input_86[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_337 (Dense)               (None, 64)           8256        dense_336[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_340 (Dense)               (None, 64)           8256        dense_339[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_338 (Dense)               (None, 32)           2080        dense_337[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_341 (Dense)               (None, 32)           2080        dense_340[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_42 (Concatenate)    (None, 64)           0           dense_338[0][0]                  \n",
      "                                                                 dense_341[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_342 (Dense)               (None, 8)            520         concatenate_42[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_343 (Dense)               (None, 1)            9           dense_342[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 1)            0           dense_343[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,027,665\n",
      "Trainable params: 3,027,665\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (11/32) *****\n",
      "Search({'dr1': 0.1, 'dr2': 0.2, 'dr3': 0.1, 'unit': 384, 'lr': 0.01, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.62176, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.62176\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.62176\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.62176\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.62176\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.62176\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.62176\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.62176\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.62176\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.62176\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.62176\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.62176\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.62176\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.62176\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.62176\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.62176\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.62176\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.62176\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.62176\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.62176\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.62176\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.62176\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.62176\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.62176\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.62176\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.62176\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.62176\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.62176\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.62176\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.62176\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.62176\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.62176\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.62176\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.62176\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.62176\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.62176\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.62176\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.62176\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.62176\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.62176\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.62176\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.62176\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.62176\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.62176\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.62176\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.62176\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.62176\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.62176\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.62176\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.62176\n",
      "SCORE: 0.62176 at epoch 1\n",
      "Compilation Time :  0.0022246837615966797\n",
      "Model: \"model_43\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_87 (InputLayer)           [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_129 (LSTM)                 (None, 240, 384)     594432      input_87[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_130 (LSTM)                 (None, 240, 384)     1181184     lstm_129[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_131 (LSTM)                 (None, 384)          1181184     lstm_130[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_88 (InputLayer)           [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_344 (Dense)               (None, 128)          49280       lstm_131[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_347 (Dense)               (None, 128)          384         input_88[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_345 (Dense)               (None, 64)           8256        dense_344[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_348 (Dense)               (None, 64)           8256        dense_347[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_346 (Dense)               (None, 32)           2080        dense_345[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_349 (Dense)               (None, 32)           2080        dense_348[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_43 (Concatenate)    (None, 64)           0           dense_346[0][0]                  \n",
      "                                                                 dense_349[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_350 (Dense)               (None, 8)            520         concatenate_43[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_351 (Dense)               (None, 1)            9           dense_350[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 1)            0           dense_351[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,027,665\n",
      "Trainable params: 3,027,665\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (12/32) *****\n",
      "Search({'dr1': 0.1, 'dr2': 0.2, 'dr3': 0.1, 'unit': 384, 'lr': 0.001, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.76720, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.76720\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.76720 to 0.77155, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.77155 to 0.80954, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.80954\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.80954\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.80954 to 0.82109, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.82109 to 0.82795, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.82795 to 0.83615, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.83615\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.83615 to 0.84586, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.84586\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.84586\n",
      "\n",
      "Epoch 00014: val_accuracy improved from 0.84586 to 0.84837, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00015: val_accuracy improved from 0.84837 to 0.84954, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.84954\n",
      "\n",
      "Epoch 00017: val_accuracy improved from 0.84954 to 0.85573, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.85573\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.85573\n",
      "\n",
      "Epoch 00020: val_accuracy improved from 0.85573 to 0.85741, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.85741\n",
      "\n",
      "Epoch 00022: val_accuracy improved from 0.85741 to 0.85992, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.85992\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.85992\n",
      "\n",
      "Epoch 00025: val_accuracy improved from 0.85992 to 0.86444, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.86444\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.86444\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.86444\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.86444\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.86444\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.86444\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.86444\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.86444\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.86444\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.86444\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.86444\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.86444\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.86444\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.86444\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.86444\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.86444\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.86444\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.86444\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.86444\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.86444\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.86444\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.86444\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.86444\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.86444\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.86444\n",
      "SCORE: 0.86444 at epoch 25\n",
      "Compilation Time :  0.0023996829986572266\n",
      "Model: \"model_44\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_89 (InputLayer)           [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_132 (LSTM)                 (None, 240, 256)     265216      input_89[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_133 (LSTM)                 (None, 240, 256)     525312      lstm_132[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_134 (LSTM)                 (None, 256)          525312      lstm_133[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_90 (InputLayer)           [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_352 (Dense)               (None, 128)          32896       lstm_134[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_355 (Dense)               (None, 128)          384         input_90[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_353 (Dense)               (None, 64)           8256        dense_352[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_356 (Dense)               (None, 64)           8256        dense_355[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_354 (Dense)               (None, 32)           2080        dense_353[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_357 (Dense)               (None, 32)           2080        dense_356[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_44 (Concatenate)    (None, 64)           0           dense_354[0][0]                  \n",
      "                                                                 dense_357[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_358 (Dense)               (None, 8)            520         concatenate_44[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_359 (Dense)               (None, 1)            9           dense_358[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 1)            0           dense_359[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,370,321\n",
      "Trainable params: 1,370,321\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (13/32) *****\n",
      "Search({'dr1': 0.1, 'dr2': 0.2, 'dr3': 0.2, 'unit': 256, 'lr': 0.01, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.63247, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.63247 to 0.67515, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.67515 to 0.71682, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.71682\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.71682 to 0.74879, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.74879\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.74879\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.74879\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.74879\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.74879\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.74879\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.74879\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.74879\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.74879\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.74879\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.74879\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.74879\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.74879\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.74879\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.74879\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.74879\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.74879\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.74879\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.74879\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.74879\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.74879\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.74879\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.74879\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.74879\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.74879\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.74879\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.74879\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.74879\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.74879\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.74879\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.74879\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.74879\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.74879\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.74879\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.74879\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.74879\n",
      "\n",
      "Epoch 00042: val_accuracy improved from 0.74879 to 0.75013, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.75013\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.75013\n",
      "\n",
      "Epoch 00045: val_accuracy improved from 0.75013 to 0.75096, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00046: val_accuracy improved from 0.75096 to 0.75130, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.75130\n",
      "\n",
      "Epoch 00048: val_accuracy improved from 0.75130 to 0.77339, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.77339\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.77339\n",
      "SCORE: 0.77339 at epoch 48\n",
      "Compilation Time :  0.002176046371459961\n",
      "Model: \"model_45\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_91 (InputLayer)           [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_135 (LSTM)                 (None, 240, 256)     265216      input_91[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_136 (LSTM)                 (None, 240, 256)     525312      lstm_135[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_137 (LSTM)                 (None, 256)          525312      lstm_136[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_92 (InputLayer)           [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_360 (Dense)               (None, 128)          32896       lstm_137[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_363 (Dense)               (None, 128)          384         input_92[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_361 (Dense)               (None, 64)           8256        dense_360[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_364 (Dense)               (None, 64)           8256        dense_363[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_362 (Dense)               (None, 32)           2080        dense_361[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_365 (Dense)               (None, 32)           2080        dense_364[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_45 (Concatenate)    (None, 64)           0           dense_362[0][0]                  \n",
      "                                                                 dense_365[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_366 (Dense)               (None, 8)            520         concatenate_45[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_367 (Dense)               (None, 1)            9           dense_366[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 1)            0           dense_367[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,370,321\n",
      "Trainable params: 1,370,321\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (14/32) *****\n",
      "Search({'dr1': 0.1, 'dr2': 0.2, 'dr3': 0.2, 'unit': 256, 'lr': 0.001, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.79715, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.79715\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.79715 to 0.80017, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.80017 to 0.81808, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.81808\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.81808\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.81808 to 0.82176, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.82176 to 0.83163, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.83163\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.83163\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.83163 to 0.83699, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00012: val_accuracy improved from 0.83699 to 0.83950, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.83950\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.83950\n",
      "\n",
      "Epoch 00015: val_accuracy improved from 0.83950 to 0.85021, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.85021\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.85021\n",
      "\n",
      "Epoch 00018: val_accuracy improved from 0.85021 to 0.85071, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00019: val_accuracy improved from 0.85071 to 0.85172, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00020: val_accuracy improved from 0.85172 to 0.85473, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00021: val_accuracy improved from 0.85473 to 0.85891, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.85891\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.85891\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.85891\n",
      "\n",
      "Epoch 00025: val_accuracy improved from 0.85891 to 0.86243, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.86243\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.86243\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.86243\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.86243\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.86243\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.86243\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.86243\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.86243\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.86243\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.86243\n",
      "\n",
      "Epoch 00036: val_accuracy improved from 0.86243 to 0.86377, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.86377\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.86377\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.86377\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.86377\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.86377\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.86377\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.86377\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.86377\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.86377\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.86377\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.86377\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.86377\n",
      "\n",
      "Epoch 00049: val_accuracy improved from 0.86377 to 0.86410, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.86410\n",
      "SCORE: 0.8641 at epoch 49\n",
      "Compilation Time :  0.0022025108337402344\n",
      "Model: \"model_46\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_93 (InputLayer)           [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_138 (LSTM)                 (None, 240, 384)     594432      input_93[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_139 (LSTM)                 (None, 240, 384)     1181184     lstm_138[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_140 (LSTM)                 (None, 384)          1181184     lstm_139[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_94 (InputLayer)           [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_368 (Dense)               (None, 128)          49280       lstm_140[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_371 (Dense)               (None, 128)          384         input_94[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_369 (Dense)               (None, 64)           8256        dense_368[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_372 (Dense)               (None, 64)           8256        dense_371[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_370 (Dense)               (None, 32)           2080        dense_369[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_373 (Dense)               (None, 32)           2080        dense_372[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_46 (Concatenate)    (None, 64)           0           dense_370[0][0]                  \n",
      "                                                                 dense_373[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_374 (Dense)               (None, 8)            520         concatenate_46[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_375 (Dense)               (None, 1)            9           dense_374[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 1)            0           dense_375[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,027,665\n",
      "Trainable params: 3,027,665\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (15/32) *****\n",
      "Search({'dr1': 0.1, 'dr2': 0.2, 'dr3': 0.2, 'unit': 384, 'lr': 0.01, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.75715, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.75715\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.75715\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.75715\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.75715\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.75715\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.75715\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.75715\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.75715\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.75715\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.75715\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.75715\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.75715\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.75715\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.75715\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.75715\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.75715\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.75715\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.75715\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.75715\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.75715\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.75715\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.75715\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.75715\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.75715\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.75715\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.75715\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.75715\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.75715\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.75715\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.75715\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.75715\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.75715\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.75715\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.75715\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.75715\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.75715\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.75715\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.75715\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.75715\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.75715\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.75715\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.75715\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.75715\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.75715\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.75715\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.75715\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.75715\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.75715\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.75715\n",
      "SCORE: 0.75715 at epoch 1\n",
      "Compilation Time :  0.0022420883178710938\n",
      "Model: \"model_47\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_95 (InputLayer)           [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_141 (LSTM)                 (None, 240, 384)     594432      input_95[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_142 (LSTM)                 (None, 240, 384)     1181184     lstm_141[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_143 (LSTM)                 (None, 384)          1181184     lstm_142[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_96 (InputLayer)           [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_376 (Dense)               (None, 128)          49280       lstm_143[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_379 (Dense)               (None, 128)          384         input_96[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_377 (Dense)               (None, 64)           8256        dense_376[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_380 (Dense)               (None, 64)           8256        dense_379[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_378 (Dense)               (None, 32)           2080        dense_377[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_381 (Dense)               (None, 32)           2080        dense_380[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_47 (Concatenate)    (None, 64)           0           dense_378[0][0]                  \n",
      "                                                                 dense_381[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_382 (Dense)               (None, 8)            520         concatenate_47[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_383 (Dense)               (None, 1)            9           dense_382[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 1)            0           dense_383[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,027,665\n",
      "Trainable params: 3,027,665\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (16/32) *****\n",
      "Search({'dr1': 0.1, 'dr2': 0.2, 'dr3': 0.2, 'unit': 384, 'lr': 0.001, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.78377, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.78377\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.78377 to 0.80418, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.80418\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.80418\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.80418\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.80418\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.80418 to 0.81958, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.81958\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.81958 to 0.83464, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.83464 to 0.84067, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.84067\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.84067\n",
      "\n",
      "Epoch 00014: val_accuracy improved from 0.84067 to 0.84117, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00015: val_accuracy improved from 0.84117 to 0.84653, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.84653\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.84653\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.84653\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.84653\n",
      "\n",
      "Epoch 00020: val_accuracy improved from 0.84653 to 0.84787, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.84787\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.84787\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.84787\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.84787\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.84787\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.84787\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.84787\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.84787\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.84787\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.84787\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.84787\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.84787\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.84787\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.84787\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.84787\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.84787\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.84787\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.84787\n",
      "\n",
      "Epoch 00039: val_accuracy improved from 0.84787 to 0.85121, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.85121\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.85121\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.85121\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.85121\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.85121\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.85121\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.85121\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.85121\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.85121\n",
      "\n",
      "Epoch 00049: val_accuracy improved from 0.85121 to 0.85941, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.85941\n",
      "SCORE: 0.85941 at epoch 49\n",
      "Compilation Time :  0.002192974090576172\n",
      "Model: \"model_48\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_97 (InputLayer)           [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_144 (LSTM)                 (None, 240, 256)     265216      input_97[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_145 (LSTM)                 (None, 240, 256)     525312      lstm_144[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_146 (LSTM)                 (None, 256)          525312      lstm_145[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_98 (InputLayer)           [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_384 (Dense)               (None, 128)          32896       lstm_146[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_387 (Dense)               (None, 128)          384         input_98[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_385 (Dense)               (None, 64)           8256        dense_384[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_388 (Dense)               (None, 64)           8256        dense_387[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_386 (Dense)               (None, 32)           2080        dense_385[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_389 (Dense)               (None, 32)           2080        dense_388[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_48 (Concatenate)    (None, 64)           0           dense_386[0][0]                  \n",
      "                                                                 dense_389[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_390 (Dense)               (None, 8)            520         concatenate_48[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_391 (Dense)               (None, 1)            9           dense_390[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 1)            0           dense_391[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,370,321\n",
      "Trainable params: 1,370,321\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (17/32) *****\n",
      "Search({'dr1': 0.2, 'dr2': 0.1, 'dr3': 0.1, 'unit': 256, 'lr': 0.01, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.65038, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.65038 to 0.65389, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.65389 to 0.67264, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.67264 to 0.67782, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.67782 to 0.68619, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.68619\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.68619\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.68619\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.68619 to 0.74494, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.74494\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.74494\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.74494\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.74494\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.74494\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.74494\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.74494\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.74494\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.74494\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.74494\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.74494\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.74494\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.74494\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.74494\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.74494\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.74494\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.74494\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.74494\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.74494\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.74494\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.74494\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.74494\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.74494\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.74494\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.74494\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.74494\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.74494\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.74494\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.74494\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.74494\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.74494\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.74494\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.74494\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.74494\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.74494\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.74494\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.74494\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.74494\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.74494\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.74494\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.74494\n",
      "SCORE: 0.74494 at epoch 9\n",
      "Compilation Time :  0.0021886825561523438\n",
      "Model: \"model_49\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_99 (InputLayer)           [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_147 (LSTM)                 (None, 240, 256)     265216      input_99[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_148 (LSTM)                 (None, 240, 256)     525312      lstm_147[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_149 (LSTM)                 (None, 256)          525312      lstm_148[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_100 (InputLayer)          [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_392 (Dense)               (None, 128)          32896       lstm_149[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_395 (Dense)               (None, 128)          384         input_100[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_393 (Dense)               (None, 64)           8256        dense_392[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_396 (Dense)               (None, 64)           8256        dense_395[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_394 (Dense)               (None, 32)           2080        dense_393[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_397 (Dense)               (None, 32)           2080        dense_396[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_49 (Concatenate)    (None, 64)           0           dense_394[0][0]                  \n",
      "                                                                 dense_397[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_398 (Dense)               (None, 8)            520         concatenate_49[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_399 (Dense)               (None, 1)            9           dense_398[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 1)            0           dense_399[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,370,321\n",
      "Trainable params: 1,370,321\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (18/32) *****\n",
      "Search({'dr1': 0.2, 'dr2': 0.1, 'dr3': 0.1, 'unit': 256, 'lr': 0.001, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.68452, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.68452 to 0.73556, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.73556 to 0.77038, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.77038\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.77038\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.77038\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.77038 to 0.77791, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.77791 to 0.80201, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.80201 to 0.82895, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.82895\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.82895\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.82895\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.82895\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.82895\n",
      "\n",
      "Epoch 00015: val_accuracy improved from 0.82895 to 0.83900, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00016: val_accuracy improved from 0.83900 to 0.84720, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00017: val_accuracy improved from 0.84720 to 0.84753, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.84753\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.84753\n",
      "\n",
      "Epoch 00020: val_accuracy improved from 0.84753 to 0.84987, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00021: val_accuracy improved from 0.84987 to 0.85423, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.85423\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.85423\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.85423\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.85423\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.85423\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.85423\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.85423\n",
      "\n",
      "Epoch 00029: val_accuracy improved from 0.85423 to 0.85774, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.85774\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.85774\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.85774\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.85774\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.85774\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.85774\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.85774\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.85774\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.85774\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.85774\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.85774\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.85774\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.85774\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.85774\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.85774\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.85774\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.85774\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.85774\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.85774\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.85774\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.85774\n",
      "SCORE: 0.85774 at epoch 29\n",
      "Compilation Time :  0.002204418182373047\n",
      "Model: \"model_50\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_101 (InputLayer)          [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_150 (LSTM)                 (None, 240, 384)     594432      input_101[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_151 (LSTM)                 (None, 240, 384)     1181184     lstm_150[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_152 (LSTM)                 (None, 384)          1181184     lstm_151[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_102 (InputLayer)          [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_400 (Dense)               (None, 128)          49280       lstm_152[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_403 (Dense)               (None, 128)          384         input_102[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_401 (Dense)               (None, 64)           8256        dense_400[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_404 (Dense)               (None, 64)           8256        dense_403[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_402 (Dense)               (None, 32)           2080        dense_401[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_405 (Dense)               (None, 32)           2080        dense_404[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_50 (Concatenate)    (None, 64)           0           dense_402[0][0]                  \n",
      "                                                                 dense_405[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_406 (Dense)               (None, 8)            520         concatenate_50[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_407 (Dense)               (None, 1)            9           dense_406[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 1)            0           dense_407[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,027,665\n",
      "Trainable params: 3,027,665\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (19/32) *****\n",
      "Search({'dr1': 0.2, 'dr2': 0.1, 'dr3': 0.1, 'unit': 384, 'lr': 0.01, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.62176, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.62176 to 0.64753, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.64753 to 0.73021, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.73021\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.73021\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.73021 to 0.73356, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.73356 to 0.76033, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.76033\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.76033\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.76033 to 0.76335, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.76335\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.76335\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.76335\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.76335\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.76335\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.76335\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.76335\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.76335\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.76335\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.76335\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.76335\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.76335\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.76335\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.76335\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.76335\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.76335\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.76335\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.76335\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.76335\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.76335\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.76335\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.76335\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.76335\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.76335\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.76335\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.76335\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.76335\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.76335\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.76335\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.76335\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.76335\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.76335\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.76335\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.76335\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.76335\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.76335\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.76335\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.76335\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.76335\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.76335\n",
      "SCORE: 0.76335 at epoch 10\n",
      "Compilation Time :  0.0022728443145751953\n",
      "Model: \"model_51\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_103 (InputLayer)          [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_153 (LSTM)                 (None, 240, 384)     594432      input_103[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_154 (LSTM)                 (None, 240, 384)     1181184     lstm_153[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_155 (LSTM)                 (None, 384)          1181184     lstm_154[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_104 (InputLayer)          [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_408 (Dense)               (None, 128)          49280       lstm_155[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_411 (Dense)               (None, 128)          384         input_104[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_409 (Dense)               (None, 64)           8256        dense_408[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_412 (Dense)               (None, 64)           8256        dense_411[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_410 (Dense)               (None, 32)           2080        dense_409[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_413 (Dense)               (None, 32)           2080        dense_412[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_51 (Concatenate)    (None, 64)           0           dense_410[0][0]                  \n",
      "                                                                 dense_413[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_414 (Dense)               (None, 8)            520         concatenate_51[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_415 (Dense)               (None, 1)            9           dense_414[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 1)            0           dense_415[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,027,665\n",
      "Trainable params: 3,027,665\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (20/32) *****\n",
      "Search({'dr1': 0.2, 'dr2': 0.1, 'dr3': 0.1, 'unit': 384, 'lr': 0.001, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.73657, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.73657\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.73657\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.73657\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.73657\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.73657 to 0.77490, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.77490\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.77490\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.77490 to 0.80770, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.80770\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.80770\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.80770\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.80770\n",
      "\n",
      "Epoch 00014: val_accuracy improved from 0.80770 to 0.82176, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00015: val_accuracy improved from 0.82176 to 0.83130, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00016: val_accuracy improved from 0.83130 to 0.83732, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.83732\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.83732\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.83732\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.83732\n",
      "\n",
      "Epoch 00021: val_accuracy improved from 0.83732 to 0.84100, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.84100\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.84100\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.84100\n",
      "\n",
      "Epoch 00025: val_accuracy improved from 0.84100 to 0.85372, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.85372\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.85372\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.85372\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.85372\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.85372\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.85372\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.85372\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.85372\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.85372\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.85372\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.85372\n",
      "\n",
      "Epoch 00037: val_accuracy improved from 0.85372 to 0.85506, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.85506\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.85506\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.85506\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.85506\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.85506\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.85506\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.85506\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.85506\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.85506\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.85506\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.85506\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.85506\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.85506\n",
      "SCORE: 0.85506 at epoch 37\n",
      "Compilation Time :  0.0021867752075195312\n",
      "Model: \"model_52\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_105 (InputLayer)          [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_156 (LSTM)                 (None, 240, 256)     265216      input_105[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_157 (LSTM)                 (None, 240, 256)     525312      lstm_156[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_158 (LSTM)                 (None, 256)          525312      lstm_157[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_106 (InputLayer)          [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_416 (Dense)               (None, 128)          32896       lstm_158[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_419 (Dense)               (None, 128)          384         input_106[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_417 (Dense)               (None, 64)           8256        dense_416[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_420 (Dense)               (None, 64)           8256        dense_419[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_418 (Dense)               (None, 32)           2080        dense_417[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_421 (Dense)               (None, 32)           2080        dense_420[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_52 (Concatenate)    (None, 64)           0           dense_418[0][0]                  \n",
      "                                                                 dense_421[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_422 (Dense)               (None, 8)            520         concatenate_52[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_423 (Dense)               (None, 1)            9           dense_422[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 1)            0           dense_423[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,370,321\n",
      "Trainable params: 1,370,321\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (21/32) *****\n",
      "Search({'dr1': 0.2, 'dr2': 0.1, 'dr3': 0.2, 'unit': 256, 'lr': 0.01, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.71113, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.71113 to 0.71381, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.71381 to 0.72770, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.72770\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.72770 to 0.74008, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.74008\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.74008 to 0.76887, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.76887\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.76887\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.76887\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.76887\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.76887\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.76887\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.76887\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.76887\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.76887\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.76887\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.76887\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.76887\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.76887\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.76887\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.76887\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.76887\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.76887\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.76887\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.76887\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.76887\n",
      "\n",
      "Epoch 00028: val_accuracy improved from 0.76887 to 0.77808, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.77808\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.77808\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.77808\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.77808\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.77808\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.77808\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.77808\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.77808\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.77808\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.77808\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.77808\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.77808\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.77808\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.77808\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.77808\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.77808\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.77808\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.77808\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.77808\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.77808\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.77808\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.77808\n",
      "SCORE: 0.77808 at epoch 28\n",
      "Compilation Time :  0.0021982192993164062\n",
      "Model: \"model_53\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_107 (InputLayer)          [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_159 (LSTM)                 (None, 240, 256)     265216      input_107[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_160 (LSTM)                 (None, 240, 256)     525312      lstm_159[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_161 (LSTM)                 (None, 256)          525312      lstm_160[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_108 (InputLayer)          [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_424 (Dense)               (None, 128)          32896       lstm_161[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_427 (Dense)               (None, 128)          384         input_108[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_425 (Dense)               (None, 64)           8256        dense_424[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_428 (Dense)               (None, 64)           8256        dense_427[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_426 (Dense)               (None, 32)           2080        dense_425[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_429 (Dense)               (None, 32)           2080        dense_428[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_53 (Concatenate)    (None, 64)           0           dense_426[0][0]                  \n",
      "                                                                 dense_429[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_430 (Dense)               (None, 8)            520         concatenate_53[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_431 (Dense)               (None, 1)            9           dense_430[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 1)            0           dense_431[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,370,321\n",
      "Trainable params: 1,370,321\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (22/32) *****\n",
      "Search({'dr1': 0.2, 'dr2': 0.1, 'dr3': 0.2, 'unit': 256, 'lr': 0.001, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.75849, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.75849\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.75849\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.75849\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.75849\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.75849 to 0.76251, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.76251 to 0.79682, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.79682 to 0.80368, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.80368\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.80368\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.80368\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.80368\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.80368 to 0.80954, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00014: val_accuracy improved from 0.80954 to 0.82912, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.82912\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.82912\n",
      "\n",
      "Epoch 00017: val_accuracy improved from 0.82912 to 0.83347, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.83347\n",
      "\n",
      "Epoch 00019: val_accuracy improved from 0.83347 to 0.83933, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.83933\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.83933\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.83933\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.83933\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.83933\n",
      "\n",
      "Epoch 00025: val_accuracy improved from 0.83933 to 0.84686, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.84686\n",
      "\n",
      "Epoch 00027: val_accuracy improved from 0.84686 to 0.85925, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.85925\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.85925\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.85925\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.85925\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.85925\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.85925\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.85925\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.85925\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.85925\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.85925\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.85925\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.85925\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.85925\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.85925\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.85925\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.85925\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.85925\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.85925\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.85925\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.85925\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.85925\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.85925\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.85925\n",
      "SCORE: 0.85925 at epoch 27\n",
      "Compilation Time :  0.0022225379943847656\n",
      "Model: \"model_54\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_109 (InputLayer)          [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_162 (LSTM)                 (None, 240, 384)     594432      input_109[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_163 (LSTM)                 (None, 240, 384)     1181184     lstm_162[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_164 (LSTM)                 (None, 384)          1181184     lstm_163[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_110 (InputLayer)          [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_432 (Dense)               (None, 128)          49280       lstm_164[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_435 (Dense)               (None, 128)          384         input_110[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_433 (Dense)               (None, 64)           8256        dense_432[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_436 (Dense)               (None, 64)           8256        dense_435[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_434 (Dense)               (None, 32)           2080        dense_433[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_437 (Dense)               (None, 32)           2080        dense_436[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_54 (Concatenate)    (None, 64)           0           dense_434[0][0]                  \n",
      "                                                                 dense_437[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_438 (Dense)               (None, 8)            520         concatenate_54[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_439 (Dense)               (None, 1)            9           dense_438[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 1)            0           dense_439[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,027,665\n",
      "Trainable params: 3,027,665\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (23/32) *****\n",
      "Search({'dr1': 0.2, 'dr2': 0.1, 'dr3': 0.2, 'unit': 384, 'lr': 0.01, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.68669, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.68669\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.68669 to 0.72921, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.72921\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.72921\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.72921 to 0.73138, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.73138\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.73138 to 0.75732, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.75732\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.75732\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.75732 to 0.77289, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.77289\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.77289\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.77289\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.77289\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.77289\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.77289\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.77289\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.77289\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.77289\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.77289\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.77289\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.77289\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.77289\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.77289\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.77289\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.77289\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.77289\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.77289\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.77289\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.77289\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.77289\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.77289\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.77289\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.77289\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.77289\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.77289\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.77289\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.77289\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.77289\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.77289\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.77289\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.77289\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.77289\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.77289\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.77289\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.77289\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.77289\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.77289\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.77289\n",
      "SCORE: 0.77289 at epoch 11\n",
      "Compilation Time :  0.0023109912872314453\n",
      "Model: \"model_55\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_111 (InputLayer)          [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_165 (LSTM)                 (None, 240, 384)     594432      input_111[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_166 (LSTM)                 (None, 240, 384)     1181184     lstm_165[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_167 (LSTM)                 (None, 384)          1181184     lstm_166[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_112 (InputLayer)          [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_440 (Dense)               (None, 128)          49280       lstm_167[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_443 (Dense)               (None, 128)          384         input_112[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_441 (Dense)               (None, 64)           8256        dense_440[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_444 (Dense)               (None, 64)           8256        dense_443[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_442 (Dense)               (None, 32)           2080        dense_441[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_445 (Dense)               (None, 32)           2080        dense_444[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_55 (Concatenate)    (None, 64)           0           dense_442[0][0]                  \n",
      "                                                                 dense_445[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_446 (Dense)               (None, 8)            520         concatenate_55[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_447 (Dense)               (None, 1)            9           dense_446[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 1)            0           dense_447[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,027,665\n",
      "Trainable params: 3,027,665\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (24/32) *****\n",
      "Search({'dr1': 0.2, 'dr2': 0.1, 'dr3': 0.2, 'unit': 384, 'lr': 0.001, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.68987, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.68987 to 0.79582, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.79582\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.79582\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.79582\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.79582\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.79582\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.79582\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.79582 to 0.81255, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.81255 to 0.82142, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.82142\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.82142\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.82142\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.82142\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.82142\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.82142\n",
      "\n",
      "Epoch 00017: val_accuracy improved from 0.82142 to 0.84084, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.84084\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.84084\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.84084\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.84084\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.84084\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.84084\n",
      "\n",
      "Epoch 00024: val_accuracy improved from 0.84084 to 0.84234, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.84234\n",
      "\n",
      "Epoch 00026: val_accuracy improved from 0.84234 to 0.85121, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.85121\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.85121\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.85121\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.85121\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.85121\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.85121\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.85121\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.85121\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.85121\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.85121\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.85121\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.85121\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.85121\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.85121\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.85121\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.85121\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.85121\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.85121\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.85121\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.85121\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.85121\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.85121\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.85121\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.85121\n",
      "SCORE: 0.85121 at epoch 26\n",
      "Compilation Time :  0.002185821533203125\n",
      "Model: \"model_56\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_113 (InputLayer)          [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_168 (LSTM)                 (None, 240, 256)     265216      input_113[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_169 (LSTM)                 (None, 240, 256)     525312      lstm_168[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_170 (LSTM)                 (None, 256)          525312      lstm_169[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_114 (InputLayer)          [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_448 (Dense)               (None, 128)          32896       lstm_170[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_451 (Dense)               (None, 128)          384         input_114[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_449 (Dense)               (None, 64)           8256        dense_448[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_452 (Dense)               (None, 64)           8256        dense_451[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_450 (Dense)               (None, 32)           2080        dense_449[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_453 (Dense)               (None, 32)           2080        dense_452[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_56 (Concatenate)    (None, 64)           0           dense_450[0][0]                  \n",
      "                                                                 dense_453[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_454 (Dense)               (None, 8)            520         concatenate_56[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_455 (Dense)               (None, 1)            9           dense_454[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 1)            0           dense_455[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,370,321\n",
      "Trainable params: 1,370,321\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (25/32) *****\n",
      "Search({'dr1': 0.2, 'dr2': 0.2, 'dr3': 0.1, 'unit': 256, 'lr': 0.01, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.69757, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.69757 to 0.74895, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.74895\n",
      "SCORE: 0.74895 at epoch 2\n",
      "Compilation Time :  0.0021719932556152344\n",
      "Model: \"model_57\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_115 (InputLayer)          [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_171 (LSTM)                 (None, 240, 256)     265216      input_115[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_172 (LSTM)                 (None, 240, 256)     525312      lstm_171[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_173 (LSTM)                 (None, 256)          525312      lstm_172[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_116 (InputLayer)          [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_456 (Dense)               (None, 128)          32896       lstm_173[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_459 (Dense)               (None, 128)          384         input_116[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_457 (Dense)               (None, 64)           8256        dense_456[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_460 (Dense)               (None, 64)           8256        dense_459[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_458 (Dense)               (None, 32)           2080        dense_457[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_461 (Dense)               (None, 32)           2080        dense_460[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_57 (Concatenate)    (None, 64)           0           dense_458[0][0]                  \n",
      "                                                                 dense_461[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_462 (Dense)               (None, 8)            520         concatenate_57[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_463 (Dense)               (None, 1)            9           dense_462[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 1)            0           dense_463[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,370,321\n",
      "Trainable params: 1,370,321\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (26/32) *****\n",
      "Search({'dr1': 0.2, 'dr2': 0.2, 'dr3': 0.1, 'unit': 256, 'lr': 0.001, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.75063, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.75063\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.75063 to 0.75397, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.75397\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.75397\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.75397\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.75397\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.75397 to 0.80904, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.80904\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.80904\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.80904\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.80904\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.80904 to 0.81908, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.81908\n",
      "\n",
      "Epoch 00015: val_accuracy improved from 0.81908 to 0.82962, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.82962\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.82962\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.82962\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.82962\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.82962\n",
      "\n",
      "Epoch 00021: val_accuracy improved from 0.82962 to 0.84837, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.84837\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.84837\n",
      "\n",
      "Epoch 00024: val_accuracy improved from 0.84837 to 0.86025, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.86025\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.86025\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.86025\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.86025\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.86025\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.86025\n",
      "\n",
      "Epoch 00031: val_accuracy improved from 0.86025 to 0.86126, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00032: val_accuracy improved from 0.86126 to 0.86259, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.86259\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.86259\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.86259\n",
      "\n",
      "Epoch 00036: val_accuracy improved from 0.86259 to 0.86326, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.86326\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.86326\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.86326\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.86326\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.86326\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.86326\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.86326\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.86326\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.86326\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.86326\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.86326\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.86326\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.86326\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.86326\n",
      "SCORE: 0.86326 at epoch 36\n",
      "Compilation Time :  0.0022072792053222656\n",
      "Model: \"model_58\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_117 (InputLayer)          [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_174 (LSTM)                 (None, 240, 384)     594432      input_117[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_175 (LSTM)                 (None, 240, 384)     1181184     lstm_174[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_176 (LSTM)                 (None, 384)          1181184     lstm_175[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_118 (InputLayer)          [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_464 (Dense)               (None, 128)          49280       lstm_176[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_467 (Dense)               (None, 128)          384         input_118[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_465 (Dense)               (None, 64)           8256        dense_464[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_468 (Dense)               (None, 64)           8256        dense_467[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_466 (Dense)               (None, 32)           2080        dense_465[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_469 (Dense)               (None, 32)           2080        dense_468[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_58 (Concatenate)    (None, 64)           0           dense_466[0][0]                  \n",
      "                                                                 dense_469[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_470 (Dense)               (None, 8)            520         concatenate_58[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_471 (Dense)               (None, 1)            9           dense_470[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 1)            0           dense_471[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,027,665\n",
      "Trainable params: 3,027,665\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (27/32) *****\n",
      "Search({'dr1': 0.2, 'dr2': 0.2, 'dr3': 0.1, 'unit': 384, 'lr': 0.01, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.70611, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.70611 to 0.74176, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.74176\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.74176\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.74176\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.74176\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.74176\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.74176\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.74176\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.74176\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.74176\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.74176\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.74176\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.74176\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.74176\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.74176\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.74176\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.74176\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.74176\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.74176\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.74176\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.74176\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.74176\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.74176\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.74176\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.74176\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.74176\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.74176\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.74176\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.74176\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.74176\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.74176\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.74176\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.74176\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.74176\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.74176\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.74176\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.74176\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.74176\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.74176\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.74176\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.74176\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.74176\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.74176\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.74176\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.74176\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.74176\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.74176\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.74176\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.74176\n",
      "SCORE: 0.74176 at epoch 2\n",
      "Compilation Time :  0.0022287368774414062\n",
      "Model: \"model_59\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_119 (InputLayer)          [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_177 (LSTM)                 (None, 240, 384)     594432      input_119[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_178 (LSTM)                 (None, 240, 384)     1181184     lstm_177[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_179 (LSTM)                 (None, 384)          1181184     lstm_178[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_120 (InputLayer)          [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_472 (Dense)               (None, 128)          49280       lstm_179[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_475 (Dense)               (None, 128)          384         input_120[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_473 (Dense)               (None, 64)           8256        dense_472[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_476 (Dense)               (None, 64)           8256        dense_475[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_474 (Dense)               (None, 32)           2080        dense_473[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_477 (Dense)               (None, 32)           2080        dense_476[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_59 (Concatenate)    (None, 64)           0           dense_474[0][0]                  \n",
      "                                                                 dense_477[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_478 (Dense)               (None, 8)            520         concatenate_59[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_479 (Dense)               (None, 1)            9           dense_478[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 1)            0           dense_479[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,027,665\n",
      "Trainable params: 3,027,665\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (28/32) *****\n",
      "Search({'dr1': 0.2, 'dr2': 0.2, 'dr3': 0.1, 'unit': 384, 'lr': 0.001, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.73088, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.73088 to 0.73941, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.73941 to 0.75297, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.75297\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.75297\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.75297\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.75297 to 0.76987, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.76987\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.76987 to 0.77741, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.77741 to 0.79632, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.79632\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.79632\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.79632 to 0.83213, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.83213\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.83213\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.83213\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.83213\n",
      "\n",
      "Epoch 00018: val_accuracy improved from 0.83213 to 0.84954, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.84954\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.84954\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.84954\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.84954\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.84954\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.84954\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.84954\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.84954\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.84954\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.84954\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.84954\n",
      "\n",
      "Epoch 00030: val_accuracy improved from 0.84954 to 0.85004, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.85004\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.85004\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.85004\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.85004\n",
      "\n",
      "Epoch 00035: val_accuracy improved from 0.85004 to 0.85339, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00036: val_accuracy improved from 0.85339 to 0.85389, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.85389\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.85389\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.85389\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.85389\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.85389\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.85389\n",
      "\n",
      "Epoch 00043: val_accuracy improved from 0.85389 to 0.85423, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.85423\n",
      "\n",
      "Epoch 00045: val_accuracy improved from 0.85423 to 0.85674, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.85674\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.85674\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.85674\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.85674\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.85674\n",
      "SCORE: 0.85674 at epoch 45\n",
      "Compilation Time :  0.002252817153930664\n",
      "Model: \"model_60\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_121 (InputLayer)          [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_180 (LSTM)                 (None, 240, 256)     265216      input_121[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_181 (LSTM)                 (None, 240, 256)     525312      lstm_180[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_182 (LSTM)                 (None, 256)          525312      lstm_181[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_122 (InputLayer)          [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_480 (Dense)               (None, 128)          32896       lstm_182[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_483 (Dense)               (None, 128)          384         input_122[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_481 (Dense)               (None, 64)           8256        dense_480[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_484 (Dense)               (None, 64)           8256        dense_483[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_482 (Dense)               (None, 32)           2080        dense_481[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_485 (Dense)               (None, 32)           2080        dense_484[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_60 (Concatenate)    (None, 64)           0           dense_482[0][0]                  \n",
      "                                                                 dense_485[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_486 (Dense)               (None, 8)            520         concatenate_60[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_487 (Dense)               (None, 1)            9           dense_486[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 1)            0           dense_487[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,370,321\n",
      "Trainable params: 1,370,321\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (29/32) *****\n",
      "Search({'dr1': 0.2, 'dr2': 0.2, 'dr3': 0.2, 'unit': 256, 'lr': 0.01, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.73423, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.73423\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.73423 to 0.73556, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.73556\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.73556\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.73556\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.73556 to 0.75113, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.75113\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.75113\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.75113 to 0.75515, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.75515\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.75515\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.75515\n",
      "\n",
      "Epoch 00014: val_accuracy improved from 0.75515 to 0.75732, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.75732\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.75732\n",
      "\n",
      "Epoch 00017: val_accuracy improved from 0.75732 to 0.75950, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.75950\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.75950\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.75950\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.75950\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.75950\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.75950\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.75950\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.75950\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.75950\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.75950\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.75950\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.75950\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.75950\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.75950\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.75950\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.75950\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.75950\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.75950\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.75950\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.75950\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.75950\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.75950\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.75950\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.75950\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.75950\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.75950\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.75950\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.75950\n",
      "\n",
      "Epoch 00046: val_accuracy improved from 0.75950 to 0.76301, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.76301\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.76301\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.76301\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.76301\n",
      "SCORE: 0.76301 at epoch 46\n",
      "Compilation Time :  0.0022211074829101562\n",
      "Model: \"model_61\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_123 (InputLayer)          [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_183 (LSTM)                 (None, 240, 256)     265216      input_123[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_184 (LSTM)                 (None, 240, 256)     525312      lstm_183[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_185 (LSTM)                 (None, 256)          525312      lstm_184[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_124 (InputLayer)          [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_488 (Dense)               (None, 128)          32896       lstm_185[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_491 (Dense)               (None, 128)          384         input_124[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_489 (Dense)               (None, 64)           8256        dense_488[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_492 (Dense)               (None, 64)           8256        dense_491[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_490 (Dense)               (None, 32)           2080        dense_489[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_493 (Dense)               (None, 32)           2080        dense_492[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_61 (Concatenate)    (None, 64)           0           dense_490[0][0]                  \n",
      "                                                                 dense_493[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_494 (Dense)               (None, 8)            520         concatenate_61[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_495 (Dense)               (None, 1)            9           dense_494[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 1)            0           dense_495[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,370,321\n",
      "Trainable params: 1,370,321\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (30/32) *****\n",
      "Search({'dr1': 0.2, 'dr2': 0.2, 'dr3': 0.2, 'unit': 256, 'lr': 0.001, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.71749, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.71749\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.71749 to 0.76318, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.76318\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.76318\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.76318\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.76318 to 0.77222, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.77222\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.77222 to 0.78343, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.78343 to 0.81607, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.81607\n",
      "\n",
      "Epoch 00012: val_accuracy improved from 0.81607 to 0.82678, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.82678\n",
      "\n",
      "Epoch 00014: val_accuracy improved from 0.82678 to 0.83699, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00015: val_accuracy improved from 0.83699 to 0.84050, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00016: val_accuracy improved from 0.84050 to 0.84552, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.84552\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.84552\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.84552\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.84552\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.84552\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.84552\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.84552\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.84552\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.84552\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.84552\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.84552\n",
      "\n",
      "Epoch 00028: val_accuracy improved from 0.84552 to 0.85757, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.85757\n",
      "\n",
      "Epoch 00030: val_accuracy improved from 0.85757 to 0.86644, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.86644\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.86644\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.86644\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.86644\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.86644\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.86644\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.86644\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.86644\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.86644\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.86644\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.86644\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.86644\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.86644\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.86644\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.86644\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.86644\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.86644\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.86644\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.86644\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.86644\n",
      "SCORE: 0.86644 at epoch 30\n",
      "Compilation Time :  0.002213001251220703\n",
      "Model: \"model_62\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_125 (InputLayer)          [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_186 (LSTM)                 (None, 240, 384)     594432      input_125[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_187 (LSTM)                 (None, 240, 384)     1181184     lstm_186[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_188 (LSTM)                 (None, 384)          1181184     lstm_187[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_126 (InputLayer)          [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_496 (Dense)               (None, 128)          49280       lstm_188[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_499 (Dense)               (None, 128)          384         input_126[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_497 (Dense)               (None, 64)           8256        dense_496[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_500 (Dense)               (None, 64)           8256        dense_499[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_498 (Dense)               (None, 32)           2080        dense_497[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_501 (Dense)               (None, 32)           2080        dense_500[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_62 (Concatenate)    (None, 64)           0           dense_498[0][0]                  \n",
      "                                                                 dense_501[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_502 (Dense)               (None, 8)            520         concatenate_62[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_503 (Dense)               (None, 1)            9           dense_502[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 1)            0           dense_503[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,027,665\n",
      "Trainable params: 3,027,665\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (31/32) *****\n",
      "Search({'dr1': 0.2, 'dr2': 0.2, 'dr3': 0.2, 'unit': 384, 'lr': 0.01, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.63464, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.63464 to 0.67297, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.67297 to 0.74025, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.74025\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.74025 to 0.75431, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.75431\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.75431\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.75431\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.75431\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.75431\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.75431 to 0.76586, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.76586\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.76586\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.76586\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.76586\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.76586\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.76586\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.76586\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.76586\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.76586\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.76586\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.76586\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.76586\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.76586\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.76586\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.76586\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.76586\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.76586\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.76586\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.76586\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.76586\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.76586\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.76586\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.76586\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.76586\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.76586\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.76586\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.76586\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.76586\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.76586\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.76586\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.76586\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.76586\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.76586\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.76586\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.76586\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.76586\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.76586\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.76586\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.76586\n",
      "SCORE: 0.76586 at epoch 11\n",
      "Compilation Time :  0.002258777618408203\n",
      "Model: \"model_63\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_127 (InputLayer)          [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_189 (LSTM)                 (None, 240, 384)     594432      input_127[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_190 (LSTM)                 (None, 240, 384)     1181184     lstm_189[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_191 (LSTM)                 (None, 384)          1181184     lstm_190[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_128 (InputLayer)          [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_504 (Dense)               (None, 128)          49280       lstm_191[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_507 (Dense)               (None, 128)          384         input_128[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_505 (Dense)               (None, 64)           8256        dense_504[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_508 (Dense)               (None, 64)           8256        dense_507[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_506 (Dense)               (None, 32)           2080        dense_505[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_509 (Dense)               (None, 32)           2080        dense_508[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_63 (Concatenate)    (None, 64)           0           dense_506[0][0]                  \n",
      "                                                                 dense_509[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_510 (Dense)               (None, 8)            520         concatenate_63[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_511 (Dense)               (None, 1)            9           dense_510[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 1)            0           dense_511[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,027,665\n",
      "Trainable params: 3,027,665\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (32/32) *****\n",
      "Search({'dr1': 0.2, 'dr2': 0.2, 'dr3': 0.2, 'unit': 384, 'lr': 0.001, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.67983, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.67983\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.67983 to 0.74711, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.74711\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.74711 to 0.75247, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.75247 to 0.77674, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.77674\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.77674\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.77674\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.77674 to 0.82109, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.82109\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.82109\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.82109\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.82109\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.82109\n",
      "\n",
      "Epoch 00016: val_accuracy improved from 0.82109 to 0.84720, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.84720\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.84720\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.84720\n",
      "\n",
      "Epoch 00020: val_accuracy improved from 0.84720 to 0.85774, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.85774\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.85774\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.85774\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.85774\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.85774\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.85774\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.85774\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.85774\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.85774\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.85774\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.85774\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.85774\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.85774\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.85774\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.85774\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.85774\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.85774\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.85774\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.85774\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.85774\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.85774\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.85774\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.85774\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.85774\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.85774\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.85774\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.85774\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.85774\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.85774\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.85774\n",
      "SCORE: 0.85774 at epoch 20\n",
      "\n",
      "##################\n",
      "###  Fold 003  ###\n",
      "##################\n",
      "\n",
      "32 trials detected for ('dr1', 'dr2', 'dr3', 'unit', 'lr', 'epochs', 'batch_size')\n",
      "Compilation Time :  0.0021898746490478516\n",
      "Model: \"model_64\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_129 (InputLayer)          [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_192 (LSTM)                 (None, 240, 256)     265216      input_129[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_193 (LSTM)                 (None, 240, 256)     525312      lstm_192[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_194 (LSTM)                 (None, 256)          525312      lstm_193[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_130 (InputLayer)          [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_512 (Dense)               (None, 128)          32896       lstm_194[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_515 (Dense)               (None, 128)          384         input_130[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_513 (Dense)               (None, 64)           8256        dense_512[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_516 (Dense)               (None, 64)           8256        dense_515[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_514 (Dense)               (None, 32)           2080        dense_513[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_517 (Dense)               (None, 32)           2080        dense_516[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_64 (Concatenate)    (None, 64)           0           dense_514[0][0]                  \n",
      "                                                                 dense_517[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_518 (Dense)               (None, 8)            520         concatenate_64[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_519 (Dense)               (None, 1)            9           dense_518[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 1)            0           dense_519[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,370,321\n",
      "Trainable params: 1,370,321\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (1/32) *****\n",
      "Search({'dr1': 0.1, 'dr2': 0.1, 'dr3': 0.1, 'unit': 256, 'lr': 0.01, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.72418, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.72418\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.72418 to 0.73406, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.73406\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.73406\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.73406\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.73406\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.73406 to 0.76100, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.76100 to 0.76418, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.76418\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.76418\n",
      "\n",
      "Epoch 00012: val_accuracy improved from 0.76418 to 0.77088, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.77088\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.77088\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.77088\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.77088\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.77088\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.77088\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.77088\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.77088\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.77088\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.77088\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.77088\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.77088\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.77088\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.77088\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.77088\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.77088\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.77088\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.77088\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.77088\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.77088\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.77088\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.77088\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.77088\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.77088\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.77088\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.77088\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.77088\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.77088\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.77088\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.77088\n",
      "\n",
      "Epoch 00043: val_accuracy improved from 0.77088 to 0.77389, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.77389\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.77389\n",
      "\n",
      "Epoch 00046: val_accuracy improved from 0.77389 to 0.78142, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.78142\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.78142\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.78142\n",
      "\n",
      "Epoch 00050: val_accuracy improved from 0.78142 to 0.79833, saving model to hyper_tuning.h5\n",
      "SCORE: 0.79833 at epoch 50\n",
      "Compilation Time :  0.0022346973419189453\n",
      "Model: \"model_65\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_131 (InputLayer)          [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_195 (LSTM)                 (None, 240, 256)     265216      input_131[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_196 (LSTM)                 (None, 240, 256)     525312      lstm_195[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_197 (LSTM)                 (None, 256)          525312      lstm_196[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_132 (InputLayer)          [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_520 (Dense)               (None, 128)          32896       lstm_197[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_523 (Dense)               (None, 128)          384         input_132[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_521 (Dense)               (None, 64)           8256        dense_520[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_524 (Dense)               (None, 64)           8256        dense_523[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_522 (Dense)               (None, 32)           2080        dense_521[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_525 (Dense)               (None, 32)           2080        dense_524[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_65 (Concatenate)    (None, 64)           0           dense_522[0][0]                  \n",
      "                                                                 dense_525[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_526 (Dense)               (None, 8)            520         concatenate_65[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_527 (Dense)               (None, 1)            9           dense_526[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 1)            0           dense_527[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,370,321\n",
      "Trainable params: 1,370,321\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (2/32) *****\n",
      "Search({'dr1': 0.1, 'dr2': 0.1, 'dr3': 0.1, 'unit': 256, 'lr': 0.001, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.76335, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.76335 to 0.79481, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.79481 to 0.79715, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.79715\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.79715 to 0.82192, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.82192 to 0.82762, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.82762\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.82762\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.82762\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.82762 to 0.83180, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.83180 to 0.84720, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.84720\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.84720\n",
      "\n",
      "Epoch 00014: val_accuracy improved from 0.84720 to 0.85088, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00015: val_accuracy improved from 0.85088 to 0.85406, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00016: val_accuracy improved from 0.85406 to 0.85506, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00017: val_accuracy improved from 0.85506 to 0.85858, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.85858\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.85858\n",
      "\n",
      "Epoch 00020: val_accuracy improved from 0.85858 to 0.86360, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.86360\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.86360\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.86360\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.86360\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.86360\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.86360\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.86360\n",
      "\n",
      "Epoch 00028: val_accuracy improved from 0.86360 to 0.86460, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.86460\n",
      "\n",
      "Epoch 00030: val_accuracy improved from 0.86460 to 0.86678, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.86678\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.86678\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.86678\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.86678\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.86678\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.86678\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.86678\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.86678\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.86678\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.86678\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.86678\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.86678\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.86678\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.86678\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.86678\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.86678\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.86678\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.86678\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.86678\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.86678\n",
      "SCORE: 0.86678 at epoch 30\n",
      "Compilation Time :  0.002144336700439453\n",
      "Model: \"model_66\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_133 (InputLayer)          [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_198 (LSTM)                 (None, 240, 384)     594432      input_133[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_199 (LSTM)                 (None, 240, 384)     1181184     lstm_198[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_200 (LSTM)                 (None, 384)          1181184     lstm_199[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_134 (InputLayer)          [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_528 (Dense)               (None, 128)          49280       lstm_200[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_531 (Dense)               (None, 128)          384         input_134[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_529 (Dense)               (None, 64)           8256        dense_528[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_532 (Dense)               (None, 64)           8256        dense_531[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_530 (Dense)               (None, 32)           2080        dense_529[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_533 (Dense)               (None, 32)           2080        dense_532[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_66 (Concatenate)    (None, 64)           0           dense_530[0][0]                  \n",
      "                                                                 dense_533[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_534 (Dense)               (None, 8)            520         concatenate_66[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_535 (Dense)               (None, 1)            9           dense_534[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 1)            0           dense_535[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,027,665\n",
      "Trainable params: 3,027,665\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (3/32) *****\n",
      "Search({'dr1': 0.1, 'dr2': 0.1, 'dr3': 0.1, 'unit': 384, 'lr': 0.01, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.67615, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.67615\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.67615\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.67615 to 0.73205, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.73205\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.73205\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.73205\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.73205\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.73205\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.73205\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.73205 to 0.75130, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.75130\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.75130\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.75130\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.75130\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.75130\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.75130\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.75130\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.75130\n",
      "\n",
      "Epoch 00020: val_accuracy improved from 0.75130 to 0.75665, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.75665\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.75665\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.75665\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.75665\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.75665\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.75665\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.75665\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.75665\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.75665\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.75665\n",
      "\n",
      "Epoch 00031: val_accuracy improved from 0.75665 to 0.77389, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.77389\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.77389\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.77389\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.77389\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.77389\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.77389\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.77389\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.77389\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.77389\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.77389\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.77389\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.77389\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.77389\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.77389\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.77389\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.77389\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.77389\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.77389\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.77389\n",
      "SCORE: 0.77389 at epoch 31\n",
      "Compilation Time :  0.0024187564849853516\n",
      "Model: \"model_67\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_135 (InputLayer)          [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_201 (LSTM)                 (None, 240, 384)     594432      input_135[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_202 (LSTM)                 (None, 240, 384)     1181184     lstm_201[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_203 (LSTM)                 (None, 384)          1181184     lstm_202[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_136 (InputLayer)          [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_536 (Dense)               (None, 128)          49280       lstm_203[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_539 (Dense)               (None, 128)          384         input_136[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_537 (Dense)               (None, 64)           8256        dense_536[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_540 (Dense)               (None, 64)           8256        dense_539[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_538 (Dense)               (None, 32)           2080        dense_537[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_541 (Dense)               (None, 32)           2080        dense_540[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_67 (Concatenate)    (None, 64)           0           dense_538[0][0]                  \n",
      "                                                                 dense_541[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_542 (Dense)               (None, 8)            520         concatenate_67[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_543 (Dense)               (None, 1)            9           dense_542[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 1)            0           dense_543[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,027,665\n",
      "Trainable params: 3,027,665\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (4/32) *****\n",
      "Search({'dr1': 0.1, 'dr2': 0.1, 'dr3': 0.1, 'unit': 384, 'lr': 0.001, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.77958, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.77958\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.77958\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.77958 to 0.79113, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.79113 to 0.80167, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.80167\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.80167 to 0.82209, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.82209\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.82209 to 0.83029, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.83029\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.83029 to 0.84720, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.84720\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.84720\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.84720\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.84720\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.84720\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.84720\n",
      "\n",
      "Epoch 00018: val_accuracy improved from 0.84720 to 0.84803, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.84803\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.84803\n",
      "\n",
      "Epoch 00021: val_accuracy improved from 0.84803 to 0.85071, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00022: val_accuracy improved from 0.85071 to 0.85255, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00023: val_accuracy improved from 0.85255 to 0.85640, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00024: val_accuracy improved from 0.85640 to 0.85941, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.85941\n",
      "\n",
      "Epoch 00026: val_accuracy improved from 0.85941 to 0.86176, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.86176\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.86176\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.86176\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.86176\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.86176\n",
      "\n",
      "Epoch 00032: val_accuracy improved from 0.86176 to 0.86695, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.86695\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.86695\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.86695\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.86695\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.86695\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.86695\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.86695\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.86695\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.86695\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.86695\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.86695\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.86695\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.86695\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.86695\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.86695\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.86695\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.86695\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.86695\n",
      "SCORE: 0.86695 at epoch 32\n",
      "Compilation Time :  0.0022020339965820312\n",
      "Model: \"model_68\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_137 (InputLayer)          [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_204 (LSTM)                 (None, 240, 256)     265216      input_137[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_205 (LSTM)                 (None, 240, 256)     525312      lstm_204[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_206 (LSTM)                 (None, 256)          525312      lstm_205[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_138 (InputLayer)          [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_544 (Dense)               (None, 128)          32896       lstm_206[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_547 (Dense)               (None, 128)          384         input_138[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_545 (Dense)               (None, 64)           8256        dense_544[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_548 (Dense)               (None, 64)           8256        dense_547[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_546 (Dense)               (None, 32)           2080        dense_545[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_549 (Dense)               (None, 32)           2080        dense_548[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_68 (Concatenate)    (None, 64)           0           dense_546[0][0]                  \n",
      "                                                                 dense_549[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_550 (Dense)               (None, 8)            520         concatenate_68[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_551 (Dense)               (None, 1)            9           dense_550[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 1)            0           dense_551[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,370,321\n",
      "Trainable params: 1,370,321\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (5/32) *****\n",
      "Search({'dr1': 0.1, 'dr2': 0.1, 'dr3': 0.2, 'unit': 256, 'lr': 0.01, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.76870, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.76870\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.76870\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.76870\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.76870\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.76870\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.76870\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.76870\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.76870\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.76870\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.76870\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.76870\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.76870\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.76870\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.76870\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.76870\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.76870\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.76870\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.76870\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.76870\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.76870\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.76870\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.76870\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.76870\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.76870\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.76870\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.76870\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.76870\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.76870\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.76870\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.76870\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.76870\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.76870\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.76870\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.76870\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.76870\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.76870\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.76870\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.76870\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.76870\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.76870\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.76870\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.76870\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.76870\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.76870\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.76870\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.76870\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.76870\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.76870\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.76870\n",
      "SCORE: 0.7687 at epoch 1\n",
      "Compilation Time :  0.0021958351135253906\n",
      "Model: \"model_69\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_139 (InputLayer)          [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_207 (LSTM)                 (None, 240, 256)     265216      input_139[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_208 (LSTM)                 (None, 240, 256)     525312      lstm_207[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_209 (LSTM)                 (None, 256)          525312      lstm_208[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_140 (InputLayer)          [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_552 (Dense)               (None, 128)          32896       lstm_209[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_555 (Dense)               (None, 128)          384         input_140[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_553 (Dense)               (None, 64)           8256        dense_552[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_556 (Dense)               (None, 64)           8256        dense_555[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_554 (Dense)               (None, 32)           2080        dense_553[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_557 (Dense)               (None, 32)           2080        dense_556[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_69 (Concatenate)    (None, 64)           0           dense_554[0][0]                  \n",
      "                                                                 dense_557[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_558 (Dense)               (None, 8)            520         concatenate_69[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_559 (Dense)               (None, 1)            9           dense_558[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 1)            0           dense_559[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,370,321\n",
      "Trainable params: 1,370,321\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (6/32) *****\n",
      "Search({'dr1': 0.1, 'dr2': 0.1, 'dr3': 0.2, 'unit': 256, 'lr': 0.001, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.78561, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.78561\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.78561 to 0.79046, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.79046 to 0.81339, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.81339 to 0.81389, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.81389 to 0.81674, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.81674\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.81674 to 0.82862, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.82862 to 0.84502, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.84502 to 0.84636, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.84636\n",
      "\n",
      "Epoch 00012: val_accuracy improved from 0.84636 to 0.84703, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.84703 to 0.85623, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.85623\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.85623\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.85623\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.85623\n",
      "\n",
      "Epoch 00018: val_accuracy improved from 0.85623 to 0.85908, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.85908\n",
      "\n",
      "Epoch 00020: val_accuracy improved from 0.85908 to 0.85925, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.85925\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.85925\n",
      "\n",
      "Epoch 00023: val_accuracy improved from 0.85925 to 0.86778, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.86778\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.86778\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.86778\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.86778\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.86778\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.86778\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.86778\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.86778\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.86778\n",
      "\n",
      "Epoch 00033: val_accuracy improved from 0.86778 to 0.87063, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.87063\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.87063\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.87063\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.87063\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.87063\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.87063\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.87063\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.87063\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.87063\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.87063\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.87063\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.87063\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.87063\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.87063\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.87063\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.87063\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.87063\n",
      "SCORE: 0.87063 at epoch 33\n",
      "Compilation Time :  0.0022003650665283203\n",
      "Model: \"model_70\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_141 (InputLayer)          [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_210 (LSTM)                 (None, 240, 384)     594432      input_141[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_211 (LSTM)                 (None, 240, 384)     1181184     lstm_210[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_212 (LSTM)                 (None, 384)          1181184     lstm_211[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_142 (InputLayer)          [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_560 (Dense)               (None, 128)          49280       lstm_212[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_563 (Dense)               (None, 128)          384         input_142[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_561 (Dense)               (None, 64)           8256        dense_560[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_564 (Dense)               (None, 64)           8256        dense_563[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_562 (Dense)               (None, 32)           2080        dense_561[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_565 (Dense)               (None, 32)           2080        dense_564[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_70 (Concatenate)    (None, 64)           0           dense_562[0][0]                  \n",
      "                                                                 dense_565[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_566 (Dense)               (None, 8)            520         concatenate_70[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_567 (Dense)               (None, 1)            9           dense_566[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 1)            0           dense_567[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,027,665\n",
      "Trainable params: 3,027,665\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (7/32) *****\n",
      "Search({'dr1': 0.1, 'dr2': 0.1, 'dr3': 0.2, 'unit': 384, 'lr': 0.01, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.68686, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.68686\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.68686\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.68686 to 0.70544, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.70544 to 0.74042, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.74042\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.74042\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.74042\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.74042\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.74042\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.74042\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.74042\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.74042\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.74042\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.74042\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.74042\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.74042\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.74042\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.74042\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.74042\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.74042\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.74042\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.74042\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.74042\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.74042\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.74042\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.74042\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.74042\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.74042\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.74042\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.74042\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.74042\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.74042\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.74042\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.74042\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.74042\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.74042\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.74042\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.74042\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.74042\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.74042\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.74042\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.74042\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.74042\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.74042\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.74042\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.74042\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.74042\n",
      "\n",
      "Epoch 00049: val_accuracy improved from 0.74042 to 0.74059, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.74059\n",
      "SCORE: 0.74059 at epoch 49\n",
      "Compilation Time :  0.002209186553955078\n",
      "Model: \"model_71\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_143 (InputLayer)          [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_213 (LSTM)                 (None, 240, 384)     594432      input_143[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_214 (LSTM)                 (None, 240, 384)     1181184     lstm_213[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_215 (LSTM)                 (None, 384)          1181184     lstm_214[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_144 (InputLayer)          [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_568 (Dense)               (None, 128)          49280       lstm_215[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_571 (Dense)               (None, 128)          384         input_144[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_569 (Dense)               (None, 64)           8256        dense_568[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_572 (Dense)               (None, 64)           8256        dense_571[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_570 (Dense)               (None, 32)           2080        dense_569[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_573 (Dense)               (None, 32)           2080        dense_572[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_71 (Concatenate)    (None, 64)           0           dense_570[0][0]                  \n",
      "                                                                 dense_573[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_574 (Dense)               (None, 8)            520         concatenate_71[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_575 (Dense)               (None, 1)            9           dense_574[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 1)            0           dense_575[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,027,665\n",
      "Trainable params: 3,027,665\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (8/32) *****\n",
      "Search({'dr1': 0.1, 'dr2': 0.1, 'dr3': 0.2, 'unit': 384, 'lr': 0.001, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.78276, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.78276\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.78276 to 0.80017, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.80017 to 0.81372, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.81372\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.81372\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.81372\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.81372 to 0.83833, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.83833\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.83833\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.83833 to 0.84971, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.84971\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.84971\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.84971\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.84971\n",
      "\n",
      "Epoch 00016: val_accuracy improved from 0.84971 to 0.85556, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.85556\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.85556\n",
      "\n",
      "Epoch 00019: val_accuracy improved from 0.85556 to 0.85741, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.85741\n",
      "\n",
      "Epoch 00021: val_accuracy improved from 0.85741 to 0.85824, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00022: val_accuracy improved from 0.85824 to 0.86310, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.86310\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.86310\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.86310\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.86310\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.86310\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.86310\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.86310\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.86310\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.86310\n",
      "\n",
      "Epoch 00032: val_accuracy improved from 0.86310 to 0.86845, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.86845\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.86845\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.86845\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.86845\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.86845\n",
      "\n",
      "Epoch 00038: val_accuracy improved from 0.86845 to 0.87029, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.87029\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.87029\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.87029\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.87029\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.87029\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.87029\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.87029\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.87029\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.87029\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.87029\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.87029\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.87029\n",
      "SCORE: 0.87029 at epoch 38\n",
      "Compilation Time :  0.0022497177124023438\n",
      "Model: \"model_72\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_145 (InputLayer)          [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_216 (LSTM)                 (None, 240, 256)     265216      input_145[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_217 (LSTM)                 (None, 240, 256)     525312      lstm_216[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_218 (LSTM)                 (None, 256)          525312      lstm_217[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_146 (InputLayer)          [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_576 (Dense)               (None, 128)          32896       lstm_218[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_579 (Dense)               (None, 128)          384         input_146[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_577 (Dense)               (None, 64)           8256        dense_576[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_580 (Dense)               (None, 64)           8256        dense_579[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_578 (Dense)               (None, 32)           2080        dense_577[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_581 (Dense)               (None, 32)           2080        dense_580[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_72 (Concatenate)    (None, 64)           0           dense_578[0][0]                  \n",
      "                                                                 dense_581[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_582 (Dense)               (None, 8)            520         concatenate_72[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_583 (Dense)               (None, 1)            9           dense_582[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 1)            0           dense_583[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,370,321\n",
      "Trainable params: 1,370,321\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (9/32) *****\n",
      "Search({'dr1': 0.1, 'dr2': 0.2, 'dr3': 0.1, 'unit': 256, 'lr': 0.01, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.75531, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.75531 to 0.77121, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.77121 to 0.77724, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.77724\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.77724\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.77724\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.77724\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.77724\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.77724\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.77724\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.77724\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.77724\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.77724\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.77724\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.77724\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.77724\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.77724\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.77724\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.77724\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.77724\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.77724\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.77724\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.77724\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.77724\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.77724\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.77724\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.77724\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.77724\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.77724\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.77724\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.77724\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.77724\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.77724\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.77724\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.77724\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.77724\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.77724\n",
      "\n",
      "Epoch 00038: val_accuracy improved from 0.77724 to 0.77741, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.77741\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.77741\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.77741\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.77741\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.77741\n",
      "\n",
      "Epoch 00044: val_accuracy improved from 0.77741 to 0.79799, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00045: val_accuracy improved from 0.79799 to 0.79950, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.79950\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.79950\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.79950\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.79950\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.79950\n",
      "SCORE: 0.7995 at epoch 45\n",
      "Compilation Time :  0.0021898746490478516\n",
      "Model: \"model_73\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_147 (InputLayer)          [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_219 (LSTM)                 (None, 240, 256)     265216      input_147[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_220 (LSTM)                 (None, 240, 256)     525312      lstm_219[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_221 (LSTM)                 (None, 256)          525312      lstm_220[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_148 (InputLayer)          [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_584 (Dense)               (None, 128)          32896       lstm_221[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_587 (Dense)               (None, 128)          384         input_148[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_585 (Dense)               (None, 64)           8256        dense_584[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_588 (Dense)               (None, 64)           8256        dense_587[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_586 (Dense)               (None, 32)           2080        dense_585[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_589 (Dense)               (None, 32)           2080        dense_588[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_73 (Concatenate)    (None, 64)           0           dense_586[0][0]                  \n",
      "                                                                 dense_589[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_590 (Dense)               (None, 8)            520         concatenate_73[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_591 (Dense)               (None, 1)            9           dense_590[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 1)            0           dense_591[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,370,321\n",
      "Trainable params: 1,370,321\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (10/32) *****\n",
      "Search({'dr1': 0.1, 'dr2': 0.2, 'dr3': 0.1, 'unit': 256, 'lr': 0.001, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.78176, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.78176 to 0.79481, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.79481\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.79481 to 0.80301, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.80301 to 0.80502, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.80502\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.80502 to 0.81791, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.81791\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.81791 to 0.82979, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.82979\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.82979 to 0.83481, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00012: val_accuracy improved from 0.83481 to 0.83983, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.83983 to 0.84218, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00014: val_accuracy improved from 0.84218 to 0.84820, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00015: val_accuracy improved from 0.84820 to 0.85356, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.85356\n",
      "\n",
      "Epoch 00017: val_accuracy improved from 0.85356 to 0.85623, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.85623\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.85623\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.85623\n",
      "\n",
      "Epoch 00021: val_accuracy improved from 0.85623 to 0.85824, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00022: val_accuracy improved from 0.85824 to 0.86477, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.86477\n",
      "\n",
      "Epoch 00024: val_accuracy improved from 0.86477 to 0.86510, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.86510\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.86510\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.86510\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.86510\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.86510\n",
      "\n",
      "Epoch 00030: val_accuracy improved from 0.86510 to 0.86594, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.86594\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.86594\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.86594\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.86594\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.86594\n",
      "\n",
      "Epoch 00036: val_accuracy improved from 0.86594 to 0.86628, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.86628\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.86628\n",
      "\n",
      "Epoch 00039: val_accuracy improved from 0.86628 to 0.86778, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.86778\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.86778\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.86778\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.86778\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.86778\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.86778\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.86778\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.86778\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.86778\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.86778\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.86778\n",
      "SCORE: 0.86778 at epoch 39\n",
      "Compilation Time :  0.002250194549560547\n",
      "Model: \"model_74\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_149 (InputLayer)          [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_222 (LSTM)                 (None, 240, 384)     594432      input_149[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_223 (LSTM)                 (None, 240, 384)     1181184     lstm_222[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_224 (LSTM)                 (None, 384)          1181184     lstm_223[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_150 (InputLayer)          [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_592 (Dense)               (None, 128)          49280       lstm_224[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_595 (Dense)               (None, 128)          384         input_150[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_593 (Dense)               (None, 64)           8256        dense_592[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_596 (Dense)               (None, 64)           8256        dense_595[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_594 (Dense)               (None, 32)           2080        dense_593[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_597 (Dense)               (None, 32)           2080        dense_596[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_74 (Concatenate)    (None, 64)           0           dense_594[0][0]                  \n",
      "                                                                 dense_597[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_598 (Dense)               (None, 8)            520         concatenate_74[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_599 (Dense)               (None, 1)            9           dense_598[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 1)            0           dense_599[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,027,665\n",
      "Trainable params: 3,027,665\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (11/32) *****\n",
      "Search({'dr1': 0.1, 'dr2': 0.2, 'dr3': 0.1, 'unit': 384, 'lr': 0.01, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.68770, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.68770\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.68770 to 0.73757, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.73757 to 0.74092, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.74092\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.74092\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.74092\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.74092\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.74092\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.74092\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.74092\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.74092\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.74092\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.74092\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.74092\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.74092\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.74092\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.74092\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.74092\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.74092\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.74092\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.74092\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.74092\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.74092\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.74092\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.74092\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.74092\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.74092\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.74092\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.74092\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.74092\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.74092\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.74092\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.74092\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.74092\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.74092\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.74092\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.74092\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.74092\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.74092\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.74092\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.74092\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.74092\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.74092\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.74092\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.74092\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.74092\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.74092\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.74092\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.74092\n",
      "SCORE: 0.74092 at epoch 4\n",
      "Compilation Time :  0.0022611618041992188\n",
      "Model: \"model_75\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_151 (InputLayer)          [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_225 (LSTM)                 (None, 240, 384)     594432      input_151[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_226 (LSTM)                 (None, 240, 384)     1181184     lstm_225[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_227 (LSTM)                 (None, 384)          1181184     lstm_226[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_152 (InputLayer)          [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_600 (Dense)               (None, 128)          49280       lstm_227[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_603 (Dense)               (None, 128)          384         input_152[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_601 (Dense)               (None, 64)           8256        dense_600[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_604 (Dense)               (None, 64)           8256        dense_603[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_602 (Dense)               (None, 32)           2080        dense_601[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_605 (Dense)               (None, 32)           2080        dense_604[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_75 (Concatenate)    (None, 64)           0           dense_602[0][0]                  \n",
      "                                                                 dense_605[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_606 (Dense)               (None, 8)            520         concatenate_75[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_607 (Dense)               (None, 1)            9           dense_606[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 1)            0           dense_607[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,027,665\n",
      "Trainable params: 3,027,665\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (12/32) *****\n",
      "Search({'dr1': 0.1, 'dr2': 0.2, 'dr3': 0.1, 'unit': 384, 'lr': 0.001, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.78879, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.78879 to 0.79715, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.79715 to 0.79782, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.79782\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.79782 to 0.82561, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.82561\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.82561 to 0.83464, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.83464\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.83464 to 0.84452, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.84452 to 0.85054, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.85054\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.85054\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.85054 to 0.85356, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00014: val_accuracy improved from 0.85356 to 0.85372, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.85372\n",
      "\n",
      "Epoch 00016: val_accuracy improved from 0.85372 to 0.85573, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.85573\n",
      "\n",
      "Epoch 00018: val_accuracy improved from 0.85573 to 0.86343, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.86343\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.86343\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.86343\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.86343\n",
      "\n",
      "Epoch 00023: val_accuracy improved from 0.86343 to 0.86879, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.86879\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.86879\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.86879\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.86879\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.86879\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.86879\n",
      "\n",
      "Epoch 00030: val_accuracy improved from 0.86879 to 0.86962, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.86962\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.86962\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.86962\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.86962\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.86962\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.86962\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.86962\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.86962\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.86962\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.86962\n",
      "\n",
      "Epoch 00041: val_accuracy improved from 0.86962 to 0.87230, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.87230\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.87230\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.87230\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.87230\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.87230\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.87230\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.87230\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.87230\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.87230\n",
      "SCORE: 0.8723 at epoch 41\n",
      "Compilation Time :  0.002183198928833008\n",
      "Model: \"model_76\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_153 (InputLayer)          [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_228 (LSTM)                 (None, 240, 256)     265216      input_153[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_229 (LSTM)                 (None, 240, 256)     525312      lstm_228[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_230 (LSTM)                 (None, 256)          525312      lstm_229[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_154 (InputLayer)          [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_608 (Dense)               (None, 128)          32896       lstm_230[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_611 (Dense)               (None, 128)          384         input_154[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_609 (Dense)               (None, 64)           8256        dense_608[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_612 (Dense)               (None, 64)           8256        dense_611[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_610 (Dense)               (None, 32)           2080        dense_609[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_613 (Dense)               (None, 32)           2080        dense_612[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_76 (Concatenate)    (None, 64)           0           dense_610[0][0]                  \n",
      "                                                                 dense_613[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_614 (Dense)               (None, 8)            520         concatenate_76[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_615 (Dense)               (None, 1)            9           dense_614[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 1)            0           dense_615[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,370,321\n",
      "Trainable params: 1,370,321\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (13/32) *****\n",
      "Search({'dr1': 0.1, 'dr2': 0.2, 'dr3': 0.2, 'unit': 256, 'lr': 0.01, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.74644, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.74644\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.74644 to 0.75347, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.75347\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.75347 to 0.75749, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.75749\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.75749\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.75749\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.75749\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.75749 to 0.76686, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.76686\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.76686\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.76686\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.76686\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.76686\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.76686\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.76686\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.76686\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.76686\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.76686\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.76686\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.76686\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.76686\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.76686\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.76686\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.76686\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.76686\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.76686\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.76686\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.76686\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.76686\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.76686\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.76686\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.76686\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.76686\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.76686\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.76686\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.76686\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.76686\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.76686\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.76686\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.76686\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.76686\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.76686\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.76686\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.76686\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.76686\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.76686\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.76686\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.76686\n",
      "SCORE: 0.76686 at epoch 10\n",
      "Compilation Time :  0.002193450927734375\n",
      "Model: \"model_77\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_155 (InputLayer)          [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_231 (LSTM)                 (None, 240, 256)     265216      input_155[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_232 (LSTM)                 (None, 240, 256)     525312      lstm_231[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_233 (LSTM)                 (None, 256)          525312      lstm_232[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_156 (InputLayer)          [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_616 (Dense)               (None, 128)          32896       lstm_233[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_619 (Dense)               (None, 128)          384         input_156[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_617 (Dense)               (None, 64)           8256        dense_616[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_620 (Dense)               (None, 64)           8256        dense_619[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_618 (Dense)               (None, 32)           2080        dense_617[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_621 (Dense)               (None, 32)           2080        dense_620[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_77 (Concatenate)    (None, 64)           0           dense_618[0][0]                  \n",
      "                                                                 dense_621[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_622 (Dense)               (None, 8)            520         concatenate_77[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_623 (Dense)               (None, 1)            9           dense_622[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 1)            0           dense_623[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,370,321\n",
      "Trainable params: 1,370,321\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (14/32) *****\n",
      "Search({'dr1': 0.1, 'dr2': 0.2, 'dr3': 0.2, 'unit': 256, 'lr': 0.001, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.79364, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.79364\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.79364\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.79364 to 0.80418, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.80418\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.80418\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.80418 to 0.82979, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.82979 to 0.83531, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.83531\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.83531\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.83531 to 0.84569, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00012: val_accuracy improved from 0.84569 to 0.84937, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.84937\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.84937\n",
      "\n",
      "Epoch 00015: val_accuracy improved from 0.84937 to 0.85473, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.85473\n",
      "\n",
      "Epoch 00017: val_accuracy improved from 0.85473 to 0.85791, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00018: val_accuracy improved from 0.85791 to 0.86025, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.86025\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.86025\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.86025\n",
      "\n",
      "Epoch 00022: val_accuracy improved from 0.86025 to 0.86444, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00023: val_accuracy improved from 0.86444 to 0.86895, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.86895\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.86895\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.86895\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.86895\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.86895\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.86895\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.86895\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.86895\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.86895\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.86895\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.86895\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.86895\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.86895\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.86895\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.86895\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.86895\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.86895\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.86895\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.86895\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.86895\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.86895\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.86895\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.86895\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.86895\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.86895\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.86895\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.86895\n",
      "SCORE: 0.86895 at epoch 23\n",
      "Compilation Time :  0.002203226089477539\n",
      "Model: \"model_78\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_157 (InputLayer)          [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_234 (LSTM)                 (None, 240, 384)     594432      input_157[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_235 (LSTM)                 (None, 240, 384)     1181184     lstm_234[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_236 (LSTM)                 (None, 384)          1181184     lstm_235[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_158 (InputLayer)          [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_624 (Dense)               (None, 128)          49280       lstm_236[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_627 (Dense)               (None, 128)          384         input_158[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_625 (Dense)               (None, 64)           8256        dense_624[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_628 (Dense)               (None, 64)           8256        dense_627[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_626 (Dense)               (None, 32)           2080        dense_625[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_629 (Dense)               (None, 32)           2080        dense_628[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_78 (Concatenate)    (None, 64)           0           dense_626[0][0]                  \n",
      "                                                                 dense_629[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_630 (Dense)               (None, 8)            520         concatenate_78[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_631 (Dense)               (None, 1)            9           dense_630[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 1)            0           dense_631[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,027,665\n",
      "Trainable params: 3,027,665\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (15/32) *****\n",
      "Search({'dr1': 0.1, 'dr2': 0.2, 'dr3': 0.2, 'unit': 384, 'lr': 0.01, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.73322, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.73322\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.73322\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.73322\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.73322\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.73322\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.73322\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.73322\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.73322\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.73322\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.73322\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.73322\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.73322\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.73322\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.73322\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.73322\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.73322\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.73322\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.73322\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.73322\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.73322\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.73322\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.73322\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.73322\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.73322\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.73322\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.73322\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.73322\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.73322\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.73322\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.73322\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.73322\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.73322\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.73322\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.73322\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.73322\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.73322\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.73322\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.73322\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.73322\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.73322\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.73322\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.73322\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.73322\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.73322\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.73322\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.73322\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.73322\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.73322\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.73322\n",
      "SCORE: 0.73322 at epoch 1\n",
      "Compilation Time :  0.002176523208618164\n",
      "Model: \"model_79\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_159 (InputLayer)          [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_237 (LSTM)                 (None, 240, 384)     594432      input_159[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_238 (LSTM)                 (None, 240, 384)     1181184     lstm_237[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_239 (LSTM)                 (None, 384)          1181184     lstm_238[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_160 (InputLayer)          [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_632 (Dense)               (None, 128)          49280       lstm_239[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_635 (Dense)               (None, 128)          384         input_160[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_633 (Dense)               (None, 64)           8256        dense_632[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_636 (Dense)               (None, 64)           8256        dense_635[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_634 (Dense)               (None, 32)           2080        dense_633[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_637 (Dense)               (None, 32)           2080        dense_636[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_79 (Concatenate)    (None, 64)           0           dense_634[0][0]                  \n",
      "                                                                 dense_637[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_638 (Dense)               (None, 8)            520         concatenate_79[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_639 (Dense)               (None, 1)            9           dense_638[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 1)            0           dense_639[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,027,665\n",
      "Trainable params: 3,027,665\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (16/32) *****\n",
      "Search({'dr1': 0.1, 'dr2': 0.2, 'dr3': 0.2, 'unit': 384, 'lr': 0.001, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.79247, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.79247 to 0.79983, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.79983\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.79983\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.79983 to 0.81088, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.81088\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.81088 to 0.82226, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.82226 to 0.83481, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.83481 to 0.83632, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.83632 to 0.84418, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.84418\n",
      "\n",
      "Epoch 00012: val_accuracy improved from 0.84418 to 0.84736, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.84736 to 0.84820, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.84820\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.84820\n",
      "\n",
      "Epoch 00016: val_accuracy improved from 0.84820 to 0.85255, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.85255\n",
      "\n",
      "Epoch 00018: val_accuracy improved from 0.85255 to 0.85490, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00019: val_accuracy improved from 0.85490 to 0.86377, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.86377\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.86377\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.86377\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.86377\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.86377\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.86377\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.86377\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.86377\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.86377\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.86377\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.86377\n",
      "\n",
      "Epoch 00031: val_accuracy improved from 0.86377 to 0.86644, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.86644\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.86644\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.86644\n",
      "\n",
      "Epoch 00035: val_accuracy improved from 0.86644 to 0.87096, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.87096\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.87096\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.87096\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.87096\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.87096\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.87096\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.87096\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.87096\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.87096\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.87096\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.87096\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.87096\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.87096\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.87096\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.87096\n",
      "SCORE: 0.87096 at epoch 35\n",
      "Compilation Time :  0.002293109893798828\n",
      "Model: \"model_80\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_161 (InputLayer)          [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_240 (LSTM)                 (None, 240, 256)     265216      input_161[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_241 (LSTM)                 (None, 240, 256)     525312      lstm_240[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_242 (LSTM)                 (None, 256)          525312      lstm_241[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_162 (InputLayer)          [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_640 (Dense)               (None, 128)          32896       lstm_242[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_643 (Dense)               (None, 128)          384         input_162[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_641 (Dense)               (None, 64)           8256        dense_640[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_644 (Dense)               (None, 64)           8256        dense_643[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_642 (Dense)               (None, 32)           2080        dense_641[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_645 (Dense)               (None, 32)           2080        dense_644[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_80 (Concatenate)    (None, 64)           0           dense_642[0][0]                  \n",
      "                                                                 dense_645[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_646 (Dense)               (None, 8)            520         concatenate_80[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_647 (Dense)               (None, 1)            9           dense_646[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 1)            0           dense_647[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,370,321\n",
      "Trainable params: 1,370,321\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (17/32) *****\n",
      "Search({'dr1': 0.2, 'dr2': 0.1, 'dr3': 0.1, 'unit': 256, 'lr': 0.01, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.65172, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.65172 to 0.71732, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.71732\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.71732\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.71732\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.71732 to 0.72485, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.72485 to 0.73238, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.73238\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.73238\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.73238 to 0.74895, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.74895\n",
      "SCORE: 0.74895 at epoch 10\n",
      "Compilation Time :  0.0021736621856689453\n",
      "Model: \"model_81\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_163 (InputLayer)          [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_243 (LSTM)                 (None, 240, 256)     265216      input_163[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_244 (LSTM)                 (None, 240, 256)     525312      lstm_243[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_245 (LSTM)                 (None, 256)          525312      lstm_244[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_164 (InputLayer)          [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_648 (Dense)               (None, 128)          32896       lstm_245[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_651 (Dense)               (None, 128)          384         input_164[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_649 (Dense)               (None, 64)           8256        dense_648[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_652 (Dense)               (None, 64)           8256        dense_651[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_650 (Dense)               (None, 32)           2080        dense_649[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_653 (Dense)               (None, 32)           2080        dense_652[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_81 (Concatenate)    (None, 64)           0           dense_650[0][0]                  \n",
      "                                                                 dense_653[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_654 (Dense)               (None, 8)            520         concatenate_81[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_655 (Dense)               (None, 1)            9           dense_654[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 1)            0           dense_655[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,370,321\n",
      "Trainable params: 1,370,321\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (18/32) *****\n",
      "Search({'dr1': 0.2, 'dr2': 0.1, 'dr3': 0.1, 'unit': 256, 'lr': 0.001, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.75749, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.75749\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.75749\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.75749 to 0.76519, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.76519 to 0.80184, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.80184\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.80184\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.80184 to 0.83013, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.83013\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.83013\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.83013\n",
      "\n",
      "Epoch 00012: val_accuracy improved from 0.83013 to 0.83113, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.83113 to 0.83531, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.83531\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.83531\n",
      "\n",
      "Epoch 00016: val_accuracy improved from 0.83531 to 0.86025, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.86025\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.86025\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.86025\n",
      "\n",
      "Epoch 00020: val_accuracy improved from 0.86025 to 0.86293, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.86293\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.86293\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.86293\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.86293\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.86293\n",
      "\n",
      "Epoch 00026: val_accuracy improved from 0.86293 to 0.86326, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.86326\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.86326\n",
      "\n",
      "Epoch 00029: val_accuracy improved from 0.86326 to 0.86561, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.86561\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.86561\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.86561\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.86561\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.86561\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.86561\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.86561\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.86561\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.86561\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.86561\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.86561\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.86561\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.86561\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.86561\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.86561\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.86561\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.86561\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.86561\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.86561\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.86561\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.86561\n",
      "SCORE: 0.86561 at epoch 29\n",
      "Compilation Time :  0.002234935760498047\n",
      "Model: \"model_82\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_165 (InputLayer)          [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_246 (LSTM)                 (None, 240, 384)     594432      input_165[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_247 (LSTM)                 (None, 240, 384)     1181184     lstm_246[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_248 (LSTM)                 (None, 384)          1181184     lstm_247[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_166 (InputLayer)          [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_656 (Dense)               (None, 128)          49280       lstm_248[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_659 (Dense)               (None, 128)          384         input_166[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_657 (Dense)               (None, 64)           8256        dense_656[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_660 (Dense)               (None, 64)           8256        dense_659[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_658 (Dense)               (None, 32)           2080        dense_657[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_661 (Dense)               (None, 32)           2080        dense_660[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_82 (Concatenate)    (None, 64)           0           dense_658[0][0]                  \n",
      "                                                                 dense_661[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_662 (Dense)               (None, 8)            520         concatenate_82[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_663 (Dense)               (None, 1)            9           dense_662[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 1)            0           dense_663[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,027,665\n",
      "Trainable params: 3,027,665\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (19/32) *****\n",
      "Search({'dr1': 0.2, 'dr2': 0.1, 'dr3': 0.1, 'unit': 384, 'lr': 0.01, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.71213, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.71213 to 0.72385, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.72385 to 0.75213, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.75213\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.75213\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.75213\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.75213\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.75213\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.75213\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.75213\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.75213\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.75213\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.75213\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.75213\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.75213\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.75213\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.75213\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.75213\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.75213\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.75213\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.75213\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.75213\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.75213\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.75213\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.75213\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.75213\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.75213\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.75213\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.75213\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.75213\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.75213\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.75213\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.75213\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.75213\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.75213\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.75213\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.75213\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.75213\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.75213\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.75213\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.75213\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.75213\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.75213\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.75213\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.75213\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.75213\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.75213\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.75213\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.75213\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.75213\n",
      "SCORE: 0.75213 at epoch 3\n",
      "Compilation Time :  0.0022077560424804688\n",
      "Model: \"model_83\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_167 (InputLayer)          [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_249 (LSTM)                 (None, 240, 384)     594432      input_167[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_250 (LSTM)                 (None, 240, 384)     1181184     lstm_249[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_251 (LSTM)                 (None, 384)          1181184     lstm_250[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_168 (InputLayer)          [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_664 (Dense)               (None, 128)          49280       lstm_251[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_667 (Dense)               (None, 128)          384         input_168[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_665 (Dense)               (None, 64)           8256        dense_664[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_668 (Dense)               (None, 64)           8256        dense_667[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_666 (Dense)               (None, 32)           2080        dense_665[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_669 (Dense)               (None, 32)           2080        dense_668[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_83 (Concatenate)    (None, 64)           0           dense_666[0][0]                  \n",
      "                                                                 dense_669[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_670 (Dense)               (None, 8)            520         concatenate_83[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_671 (Dense)               (None, 1)            9           dense_670[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 1)            0           dense_671[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,027,665\n",
      "Trainable params: 3,027,665\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (20/32) *****\n",
      "Search({'dr1': 0.2, 'dr2': 0.1, 'dr3': 0.1, 'unit': 384, 'lr': 0.001, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.71632, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.71632 to 0.74377, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.74377\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.74377 to 0.76669, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.76669\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.76669 to 0.76720, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.76720\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.76720\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.76720 to 0.79431, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.79431\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.79431 to 0.83213, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.83213\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.83213\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.83213\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.83213\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.83213\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.83213\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.83213\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.83213\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.83213\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.83213\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.83213\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.83213\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.83213\n",
      "\n",
      "Epoch 00025: val_accuracy improved from 0.83213 to 0.83598, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.83598\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.83598\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.83598\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.83598\n",
      "\n",
      "Epoch 00030: val_accuracy improved from 0.83598 to 0.83665, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.83665\n",
      "\n",
      "Epoch 00032: val_accuracy improved from 0.83665 to 0.85523, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.85523\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.85523\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.85523\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.85523\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.85523\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.85523\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.85523\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.85523\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.85523\n",
      "\n",
      "Epoch 00042: val_accuracy improved from 0.85523 to 0.85674, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.85674\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.85674\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.85674\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.85674\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.85674\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.85674\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.85674\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.85674\n",
      "SCORE: 0.85674 at epoch 42\n",
      "Compilation Time :  0.0022933483123779297\n",
      "Model: \"model_84\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_169 (InputLayer)          [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_252 (LSTM)                 (None, 240, 256)     265216      input_169[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_253 (LSTM)                 (None, 240, 256)     525312      lstm_252[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_254 (LSTM)                 (None, 256)          525312      lstm_253[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_170 (InputLayer)          [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_672 (Dense)               (None, 128)          32896       lstm_254[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_675 (Dense)               (None, 128)          384         input_170[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_673 (Dense)               (None, 64)           8256        dense_672[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_676 (Dense)               (None, 64)           8256        dense_675[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_674 (Dense)               (None, 32)           2080        dense_673[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_677 (Dense)               (None, 32)           2080        dense_676[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_84 (Concatenate)    (None, 64)           0           dense_674[0][0]                  \n",
      "                                                                 dense_677[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_678 (Dense)               (None, 8)            520         concatenate_84[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_679 (Dense)               (None, 1)            9           dense_678[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 1)            0           dense_679[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,370,321\n",
      "Trainable params: 1,370,321\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (21/32) *****\n",
      "Search({'dr1': 0.2, 'dr2': 0.1, 'dr3': 0.2, 'unit': 256, 'lr': 0.01, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.75933, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.75933\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.75933\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.75933\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.75933\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.75933\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.75933\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.75933\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.75933\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.75933\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.75933\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.75933\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.75933\n",
      "\n",
      "Epoch 00014: val_accuracy improved from 0.75933 to 0.76418, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.76418\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.76418\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.76418\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.76418\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.76418\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.76418\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.76418\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.76418\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.76418\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.76418\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.76418\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.76418\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.76418\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.76418\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.76418\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.76418\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.76418\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.76418\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.76418\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.76418\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.76418\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.76418\n",
      "\n",
      "Epoch 00037: val_accuracy improved from 0.76418 to 0.76452, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.76452\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.76452\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.76452\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.76452\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.76452\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.76452\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.76452\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.76452\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.76452\n",
      "\n",
      "Epoch 00047: val_accuracy improved from 0.76452 to 0.76653, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.76653\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.76653\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.76653\n",
      "SCORE: 0.76653 at epoch 47\n",
      "Compilation Time :  0.002187013626098633\n",
      "Model: \"model_85\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_171 (InputLayer)          [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_255 (LSTM)                 (None, 240, 256)     265216      input_171[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_256 (LSTM)                 (None, 240, 256)     525312      lstm_255[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_257 (LSTM)                 (None, 256)          525312      lstm_256[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_172 (InputLayer)          [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_680 (Dense)               (None, 128)          32896       lstm_257[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_683 (Dense)               (None, 128)          384         input_172[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_681 (Dense)               (None, 64)           8256        dense_680[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_684 (Dense)               (None, 64)           8256        dense_683[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_682 (Dense)               (None, 32)           2080        dense_681[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_685 (Dense)               (None, 32)           2080        dense_684[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_85 (Concatenate)    (None, 64)           0           dense_682[0][0]                  \n",
      "                                                                 dense_685[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_686 (Dense)               (None, 8)            520         concatenate_85[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_687 (Dense)               (None, 1)            9           dense_686[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 1)            0           dense_687[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,370,321\n",
      "Trainable params: 1,370,321\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (22/32) *****\n",
      "Search({'dr1': 0.2, 'dr2': 0.1, 'dr3': 0.2, 'unit': 256, 'lr': 0.001, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.77690, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.77690\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.77690\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.77690\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.77690\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.77690\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.77690 to 0.78226, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.78226 to 0.80803, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.80803\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.80803\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.80803 to 0.81674, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.81674\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.81674\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.81674\n",
      "\n",
      "Epoch 00015: val_accuracy improved from 0.81674 to 0.83280, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.83280\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.83280\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.83280\n",
      "\n",
      "Epoch 00019: val_accuracy improved from 0.83280 to 0.83431, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.83431\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.83431\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.83431\n",
      "\n",
      "Epoch 00023: val_accuracy improved from 0.83431 to 0.83967, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.83967\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.83967\n",
      "\n",
      "Epoch 00026: val_accuracy improved from 0.83967 to 0.84368, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.84368\n",
      "\n",
      "Epoch 00028: val_accuracy improved from 0.84368 to 0.84971, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.84971\n",
      "\n",
      "Epoch 00030: val_accuracy improved from 0.84971 to 0.85121, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.85121\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.85121\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.85121\n",
      "\n",
      "Epoch 00034: val_accuracy improved from 0.85121 to 0.85473, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00035: val_accuracy improved from 0.85473 to 0.85640, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00036: val_accuracy improved from 0.85640 to 0.85841, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.85841\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.85841\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.85841\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.85841\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.85841\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.85841\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.85841\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.85841\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.85841\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.85841\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.85841\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.85841\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.85841\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.85841\n",
      "SCORE: 0.85841 at epoch 36\n",
      "Compilation Time :  0.0022001266479492188\n",
      "Model: \"model_86\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_173 (InputLayer)          [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_258 (LSTM)                 (None, 240, 384)     594432      input_173[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_259 (LSTM)                 (None, 240, 384)     1181184     lstm_258[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_260 (LSTM)                 (None, 384)          1181184     lstm_259[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_174 (InputLayer)          [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_688 (Dense)               (None, 128)          49280       lstm_260[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_691 (Dense)               (None, 128)          384         input_174[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_689 (Dense)               (None, 64)           8256        dense_688[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_692 (Dense)               (None, 64)           8256        dense_691[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_690 (Dense)               (None, 32)           2080        dense_689[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_693 (Dense)               (None, 32)           2080        dense_692[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_86 (Concatenate)    (None, 64)           0           dense_690[0][0]                  \n",
      "                                                                 dense_693[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_694 (Dense)               (None, 8)            520         concatenate_86[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_695 (Dense)               (None, 1)            9           dense_694[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 1)            0           dense_695[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,027,665\n",
      "Trainable params: 3,027,665\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (23/32) *****\n",
      "Search({'dr1': 0.2, 'dr2': 0.1, 'dr3': 0.2, 'unit': 384, 'lr': 0.01, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.70059, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.70059 to 0.73088, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.73088 to 0.74795, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.74795\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.74795\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.74795\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.74795 to 0.75331, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.75331\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.75331\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.75331\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.75331\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.75331\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.75331\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.75331\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.75331\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.75331\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.75331\n",
      "\n",
      "Epoch 00018: val_accuracy improved from 0.75331 to 0.75582, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.75582\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.75582\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.75582\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.75582\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.75582\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.75582\n",
      "\n",
      "Epoch 00025: val_accuracy improved from 0.75582 to 0.76502, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.76502\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.76502\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.76502\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.76502\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.76502\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.76502\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.76502\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.76502\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.76502\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.76502\n",
      "\n",
      "Epoch 00036: val_accuracy improved from 0.76502 to 0.77205, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.77205\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.77205\n",
      "\n",
      "Epoch 00039: val_accuracy improved from 0.77205 to 0.77891, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.77891\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.77891\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.77891\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.77891\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.77891\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.77891\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.77891\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.77891\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.77891\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.77891\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.77891\n",
      "SCORE: 0.77891 at epoch 39\n",
      "Compilation Time :  0.002441883087158203\n",
      "Model: \"model_87\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_175 (InputLayer)          [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_261 (LSTM)                 (None, 240, 384)     594432      input_175[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_262 (LSTM)                 (None, 240, 384)     1181184     lstm_261[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_263 (LSTM)                 (None, 384)          1181184     lstm_262[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_176 (InputLayer)          [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_696 (Dense)               (None, 128)          49280       lstm_263[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_699 (Dense)               (None, 128)          384         input_176[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_697 (Dense)               (None, 64)           8256        dense_696[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_700 (Dense)               (None, 64)           8256        dense_699[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_698 (Dense)               (None, 32)           2080        dense_697[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_701 (Dense)               (None, 32)           2080        dense_700[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_87 (Concatenate)    (None, 64)           0           dense_698[0][0]                  \n",
      "                                                                 dense_701[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_702 (Dense)               (None, 8)            520         concatenate_87[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_703 (Dense)               (None, 1)            9           dense_702[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 1)            0           dense_703[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,027,665\n",
      "Trainable params: 3,027,665\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (24/32) *****\n",
      "Search({'dr1': 0.2, 'dr2': 0.1, 'dr3': 0.2, 'unit': 384, 'lr': 0.001, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.76351, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.76351\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.76351\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.76351\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.76351 to 0.80904, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.80904\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.80904 to 0.83113, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.83113\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.83113\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.83113 to 0.84100, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.84100\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.84100\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.84100\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.84100\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.84100\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.84100\n",
      "\n",
      "Epoch 00017: val_accuracy improved from 0.84100 to 0.85707, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.85707\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.85707\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.85707\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.85707\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.85707\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.85707\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.85707\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.85707\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.85707\n",
      "\n",
      "Epoch 00027: val_accuracy improved from 0.85707 to 0.86393, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00028: val_accuracy improved from 0.86393 to 0.86845, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.86845\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.86845\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.86845\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.86845\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.86845\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.86845\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.86845\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.86845\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.86845\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.86845\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.86845\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.86845\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.86845\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.86845\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.86845\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.86845\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.86845\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.86845\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.86845\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.86845\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.86845\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.86845\n",
      "SCORE: 0.86845 at epoch 28\n",
      "Compilation Time :  0.0021941661834716797\n",
      "Model: \"model_88\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_177 (InputLayer)          [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_264 (LSTM)                 (None, 240, 256)     265216      input_177[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_265 (LSTM)                 (None, 240, 256)     525312      lstm_264[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_266 (LSTM)                 (None, 256)          525312      lstm_265[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_178 (InputLayer)          [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_704 (Dense)               (None, 128)          32896       lstm_266[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_707 (Dense)               (None, 128)          384         input_178[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_705 (Dense)               (None, 64)           8256        dense_704[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_708 (Dense)               (None, 64)           8256        dense_707[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_706 (Dense)               (None, 32)           2080        dense_705[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_709 (Dense)               (None, 32)           2080        dense_708[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_88 (Concatenate)    (None, 64)           0           dense_706[0][0]                  \n",
      "                                                                 dense_709[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_710 (Dense)               (None, 8)            520         concatenate_88[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_711 (Dense)               (None, 1)            9           dense_710[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 1)            0           dense_711[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,370,321\n",
      "Trainable params: 1,370,321\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (25/32) *****\n",
      "Search({'dr1': 0.2, 'dr2': 0.2, 'dr3': 0.1, 'unit': 256, 'lr': 0.01, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.63615, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.63615 to 0.70678, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.70678 to 0.72502, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.72502\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.72502 to 0.73674, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.73674 to 0.75950, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.75950\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.75950\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.75950\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.75950\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.75950\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.75950\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.75950\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.75950\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.75950\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.75950\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.75950\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.75950\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.75950\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.75950\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.75950\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.75950\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.75950\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.75950\n",
      "\n",
      "Epoch 00025: val_accuracy improved from 0.75950 to 0.76017, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.76017\n",
      "\n",
      "Epoch 00027: val_accuracy improved from 0.76017 to 0.77071, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.77071\n",
      "\n",
      "Epoch 00029: val_accuracy improved from 0.77071 to 0.77456, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.77456\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.77456\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.77456\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.77456\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.77456\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.77456\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.77456\n",
      "\n",
      "Epoch 00037: val_accuracy improved from 0.77456 to 0.78711, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.78711\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.78711\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.78711\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.78711\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.78711\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.78711\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.78711\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.78711\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.78711\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.78711\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.78711\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.78711\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.78711\n",
      "SCORE: 0.78711 at epoch 37\n",
      "Compilation Time :  0.0022263526916503906\n",
      "Model: \"model_89\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_179 (InputLayer)          [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_267 (LSTM)                 (None, 240, 256)     265216      input_179[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_268 (LSTM)                 (None, 240, 256)     525312      lstm_267[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_269 (LSTM)                 (None, 256)          525312      lstm_268[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_180 (InputLayer)          [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_712 (Dense)               (None, 128)          32896       lstm_269[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_715 (Dense)               (None, 128)          384         input_180[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_713 (Dense)               (None, 64)           8256        dense_712[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_716 (Dense)               (None, 64)           8256        dense_715[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_714 (Dense)               (None, 32)           2080        dense_713[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_717 (Dense)               (None, 32)           2080        dense_716[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_89 (Concatenate)    (None, 64)           0           dense_714[0][0]                  \n",
      "                                                                 dense_717[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_718 (Dense)               (None, 8)            520         concatenate_89[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_719 (Dense)               (None, 1)            9           dense_718[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 1)            0           dense_719[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,370,321\n",
      "Trainable params: 1,370,321\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (26/32) *****\n",
      "Search({'dr1': 0.2, 'dr2': 0.2, 'dr3': 0.1, 'unit': 256, 'lr': 0.001, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.74695, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.74695\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.74695\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.74695\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.74695\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.74695\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.74695\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.74695\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.74695 to 0.76301, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.76301 to 0.78259, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.78259\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.78259\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.78259\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.78259\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.78259\n",
      "\n",
      "Epoch 00016: val_accuracy improved from 0.78259 to 0.79849, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00017: val_accuracy improved from 0.79849 to 0.83983, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.83983\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.83983\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.83983\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.83983\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.83983\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.83983\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.83983\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.83983\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.83983\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.83983\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.83983\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.83983\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.83983\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.83983\n",
      "\n",
      "Epoch 00032: val_accuracy improved from 0.83983 to 0.84937, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.84937\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.84937\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.84937\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.84937\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.84937\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.84937\n",
      "\n",
      "Epoch 00039: val_accuracy improved from 0.84937 to 0.85121, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.85121\n",
      "\n",
      "Epoch 00041: val_accuracy improved from 0.85121 to 0.85573, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.85573\n",
      "\n",
      "Epoch 00043: val_accuracy improved from 0.85573 to 0.85808, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.85808\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.85808\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.85808\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.85808\n",
      "\n",
      "Epoch 00048: val_accuracy improved from 0.85808 to 0.86126, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.86126\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.86126\n",
      "SCORE: 0.86126 at epoch 48\n",
      "Compilation Time :  0.0022420883178710938\n",
      "Model: \"model_90\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_181 (InputLayer)          [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_270 (LSTM)                 (None, 240, 384)     594432      input_181[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_271 (LSTM)                 (None, 240, 384)     1181184     lstm_270[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_272 (LSTM)                 (None, 384)          1181184     lstm_271[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_182 (InputLayer)          [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_720 (Dense)               (None, 128)          49280       lstm_272[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_723 (Dense)               (None, 128)          384         input_182[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_721 (Dense)               (None, 64)           8256        dense_720[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_724 (Dense)               (None, 64)           8256        dense_723[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_722 (Dense)               (None, 32)           2080        dense_721[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_725 (Dense)               (None, 32)           2080        dense_724[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_90 (Concatenate)    (None, 64)           0           dense_722[0][0]                  \n",
      "                                                                 dense_725[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_726 (Dense)               (None, 8)            520         concatenate_90[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_727 (Dense)               (None, 1)            9           dense_726[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 1)            0           dense_727[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,027,665\n",
      "Trainable params: 3,027,665\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (27/32) *****\n",
      "Search({'dr1': 0.2, 'dr2': 0.2, 'dr3': 0.1, 'unit': 384, 'lr': 0.01, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.62962, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.62962 to 0.64335, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.64335 to 0.67950, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.67950 to 0.68251, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.68251\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.68251 to 0.74895, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.74895\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.74895\n",
      "SCORE: 0.74895 at epoch 6\n",
      "Compilation Time :  0.002187967300415039\n",
      "Model: \"model_91\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_183 (InputLayer)          [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_273 (LSTM)                 (None, 240, 384)     594432      input_183[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_274 (LSTM)                 (None, 240, 384)     1181184     lstm_273[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_275 (LSTM)                 (None, 384)          1181184     lstm_274[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_184 (InputLayer)          [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_728 (Dense)               (None, 128)          49280       lstm_275[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_731 (Dense)               (None, 128)          384         input_184[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_729 (Dense)               (None, 64)           8256        dense_728[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_732 (Dense)               (None, 64)           8256        dense_731[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_730 (Dense)               (None, 32)           2080        dense_729[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_733 (Dense)               (None, 32)           2080        dense_732[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_91 (Concatenate)    (None, 64)           0           dense_730[0][0]                  \n",
      "                                                                 dense_733[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_734 (Dense)               (None, 8)            520         concatenate_91[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_735 (Dense)               (None, 1)            9           dense_734[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 1)            0           dense_735[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,027,665\n",
      "Trainable params: 3,027,665\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (28/32) *****\n",
      "Search({'dr1': 0.2, 'dr2': 0.2, 'dr3': 0.1, 'unit': 384, 'lr': 0.001, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.78427, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.78427\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.78427\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.78427\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.78427\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.78427\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.78427\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.78427 to 0.80636, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.80636 to 0.80971, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.80971\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.80971\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.80971\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.80971 to 0.83816, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00014: val_accuracy improved from 0.83816 to 0.84335, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.84335\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.84335\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.84335\n",
      "\n",
      "Epoch 00018: val_accuracy improved from 0.84335 to 0.85021, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.85021\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.85021\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.85021\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.85021\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.85021\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.85021\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.85021\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.85021\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.85021\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.85021\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.85021\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.85021\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.85021\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.85021\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.85021\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.85021\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.85021\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.85021\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.85021\n",
      "\n",
      "Epoch 00038: val_accuracy improved from 0.85021 to 0.85054, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00039: val_accuracy improved from 0.85054 to 0.85540, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.85540\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.85540\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.85540\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.85540\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.85540\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.85540\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.85540\n",
      "\n",
      "Epoch 00047: val_accuracy improved from 0.85540 to 0.85674, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.85674\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.85674\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.85674\n",
      "SCORE: 0.85674 at epoch 47\n",
      "Compilation Time :  0.0021975040435791016\n",
      "Model: \"model_92\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_185 (InputLayer)          [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_276 (LSTM)                 (None, 240, 256)     265216      input_185[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_277 (LSTM)                 (None, 240, 256)     525312      lstm_276[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_278 (LSTM)                 (None, 256)          525312      lstm_277[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_186 (InputLayer)          [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_736 (Dense)               (None, 128)          32896       lstm_278[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_739 (Dense)               (None, 128)          384         input_186[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_737 (Dense)               (None, 64)           8256        dense_736[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_740 (Dense)               (None, 64)           8256        dense_739[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_738 (Dense)               (None, 32)           2080        dense_737[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_741 (Dense)               (None, 32)           2080        dense_740[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_92 (Concatenate)    (None, 64)           0           dense_738[0][0]                  \n",
      "                                                                 dense_741[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_742 (Dense)               (None, 8)            520         concatenate_92[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_743 (Dense)               (None, 1)            9           dense_742[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 1)            0           dense_743[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,370,321\n",
      "Trainable params: 1,370,321\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (29/32) *****\n",
      "Search({'dr1': 0.2, 'dr2': 0.2, 'dr3': 0.2, 'unit': 256, 'lr': 0.01, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.69305, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.69305\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.69305 to 0.69941, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.69941\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.69941\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.69941\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.69941 to 0.75029, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.75029\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.75029\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.75029 to 0.77054, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.77054\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.77054\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.77054\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.77054\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.77054\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.77054\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.77054\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.77054\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.77054\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.77054\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.77054\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.77054\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.77054\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.77054\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.77054\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.77054\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.77054\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.77054\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.77054\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.77054\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.77054\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.77054\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.77054\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.77054\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.77054\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.77054\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.77054\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.77054\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.77054\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.77054\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.77054\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.77054\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.77054\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.77054\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.77054\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.77054\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.77054\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.77054\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.77054\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.77054\n",
      "SCORE: 0.77054 at epoch 10\n",
      "Compilation Time :  0.002178192138671875\n",
      "Model: \"model_93\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_187 (InputLayer)          [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_279 (LSTM)                 (None, 240, 256)     265216      input_187[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_280 (LSTM)                 (None, 240, 256)     525312      lstm_279[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_281 (LSTM)                 (None, 256)          525312      lstm_280[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_188 (InputLayer)          [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_744 (Dense)               (None, 128)          32896       lstm_281[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_747 (Dense)               (None, 128)          384         input_188[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_745 (Dense)               (None, 64)           8256        dense_744[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_748 (Dense)               (None, 64)           8256        dense_747[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_746 (Dense)               (None, 32)           2080        dense_745[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_749 (Dense)               (None, 32)           2080        dense_748[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_93 (Concatenate)    (None, 64)           0           dense_746[0][0]                  \n",
      "                                                                 dense_749[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_750 (Dense)               (None, 8)            520         concatenate_93[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_751 (Dense)               (None, 1)            9           dense_750[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 1)            0           dense_751[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,370,321\n",
      "Trainable params: 1,370,321\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (30/32) *****\n",
      "Search({'dr1': 0.2, 'dr2': 0.2, 'dr3': 0.2, 'unit': 256, 'lr': 0.001, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.74360, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.74360\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.74360 to 0.77289, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.77289\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.77289\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.77289\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.77289\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.77289\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.77289\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.77289 to 0.77423, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.77423 to 0.82377, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.82377\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.82377\n",
      "\n",
      "Epoch 00014: val_accuracy improved from 0.82377 to 0.82544, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00015: val_accuracy improved from 0.82544 to 0.85004, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.85004\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.85004\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.85004\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.85004\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.85004\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.85004\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.85004\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.85004\n",
      "\n",
      "Epoch 00024: val_accuracy improved from 0.85004 to 0.85038, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.85038\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.85038\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.85038\n",
      "\n",
      "Epoch 00028: val_accuracy improved from 0.85038 to 0.85456, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.85456\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.85456\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.85456\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.85456\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.85456\n",
      "\n",
      "Epoch 00034: val_accuracy improved from 0.85456 to 0.86176, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.86176\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.86176\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.86176\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.86176\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.86176\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.86176\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.86176\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.86176\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.86176\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.86176\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.86176\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.86176\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.86176\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.86176\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.86176\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.86176\n",
      "SCORE: 0.86176 at epoch 34\n",
      "Compilation Time :  0.002239227294921875\n",
      "Model: \"model_94\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_189 (InputLayer)          [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_282 (LSTM)                 (None, 240, 384)     594432      input_189[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_283 (LSTM)                 (None, 240, 384)     1181184     lstm_282[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_284 (LSTM)                 (None, 384)          1181184     lstm_283[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_190 (InputLayer)          [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_752 (Dense)               (None, 128)          49280       lstm_284[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_755 (Dense)               (None, 128)          384         input_190[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_753 (Dense)               (None, 64)           8256        dense_752[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_756 (Dense)               (None, 64)           8256        dense_755[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_754 (Dense)               (None, 32)           2080        dense_753[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_757 (Dense)               (None, 32)           2080        dense_756[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_94 (Concatenate)    (None, 64)           0           dense_754[0][0]                  \n",
      "                                                                 dense_757[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_758 (Dense)               (None, 8)            520         concatenate_94[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_759 (Dense)               (None, 1)            9           dense_758[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 1)            0           dense_759[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,027,665\n",
      "Trainable params: 3,027,665\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (31/32) *****\n",
      "Search({'dr1': 0.2, 'dr2': 0.2, 'dr3': 0.2, 'unit': 384, 'lr': 0.01, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.72318, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.72318 to 0.73707, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.73707\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.73707\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.73707\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.73707\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.73707\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.73707\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.73707\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.73707\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.73707\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.73707\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.73707\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.73707\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.73707\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.73707\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.73707\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.73707\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.73707\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.73707\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.73707\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.73707\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.73707\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.73707\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.73707\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.73707\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.73707\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.73707\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.73707\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.73707\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.73707\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.73707\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.73707\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.73707\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.73707\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.73707\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.73707\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.73707\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.73707\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.73707\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.73707\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.73707\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.73707\n",
      "\n",
      "Epoch 00044: val_accuracy improved from 0.73707 to 0.74594, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.74594\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.74594\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.74594\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.74594\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.74594\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.74594\n",
      "SCORE: 0.74594 at epoch 44\n",
      "Compilation Time :  0.0022497177124023438\n",
      "Model: \"model_95\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_191 (InputLayer)          [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_285 (LSTM)                 (None, 240, 384)     594432      input_191[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_286 (LSTM)                 (None, 240, 384)     1181184     lstm_285[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_287 (LSTM)                 (None, 384)          1181184     lstm_286[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_192 (InputLayer)          [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_760 (Dense)               (None, 128)          49280       lstm_287[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_763 (Dense)               (None, 128)          384         input_192[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_761 (Dense)               (None, 64)           8256        dense_760[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_764 (Dense)               (None, 64)           8256        dense_763[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_762 (Dense)               (None, 32)           2080        dense_761[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_765 (Dense)               (None, 32)           2080        dense_764[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_95 (Concatenate)    (None, 64)           0           dense_762[0][0]                  \n",
      "                                                                 dense_765[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_766 (Dense)               (None, 8)            520         concatenate_95[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_767 (Dense)               (None, 1)            9           dense_766[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, 1)            0           dense_767[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,027,665\n",
      "Trainable params: 3,027,665\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (32/32) *****\n",
      "Search({'dr1': 0.2, 'dr2': 0.2, 'dr3': 0.2, 'unit': 384, 'lr': 0.001, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.77138, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.77138\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.77138 to 0.79264, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.79264\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.79264\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.79264\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.79264\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.79264 to 0.79515, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.79515\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.79515\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.79515 to 0.82126, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.82126\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.82126\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.82126\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.82126\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.82126\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.82126\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.82126\n",
      "\n",
      "Epoch 00019: val_accuracy improved from 0.82126 to 0.82745, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.82745\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.82745\n",
      "\n",
      "Epoch 00022: val_accuracy improved from 0.82745 to 0.82862, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00023: val_accuracy improved from 0.82862 to 0.84669, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.84669\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.84669\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.84669\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.84669\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.84669\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.84669\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.84669\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.84669\n",
      "\n",
      "Epoch 00032: val_accuracy improved from 0.84669 to 0.85121, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.85121\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.85121\n",
      "\n",
      "Epoch 00035: val_accuracy improved from 0.85121 to 0.85155, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.85155\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.85155\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.85155\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.85155\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.85155\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.85155\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.85155\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.85155\n",
      "\n",
      "Epoch 00044: val_accuracy improved from 0.85155 to 0.85205, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.85205\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.85205\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.85205\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.85205\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.85205\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.85205\n",
      "SCORE: 0.85205 at epoch 44\n",
      "\n",
      "##################\n",
      "###  Fold 004  ###\n",
      "##################\n",
      "\n",
      "32 trials detected for ('dr1', 'dr2', 'dr3', 'unit', 'lr', 'epochs', 'batch_size')\n",
      "Compilation Time :  0.002176523208618164\n",
      "Model: \"model_96\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_193 (InputLayer)          [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_288 (LSTM)                 (None, 240, 256)     265216      input_193[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_289 (LSTM)                 (None, 240, 256)     525312      lstm_288[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_290 (LSTM)                 (None, 256)          525312      lstm_289[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_194 (InputLayer)          [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_768 (Dense)               (None, 128)          32896       lstm_290[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_771 (Dense)               (None, 128)          384         input_194[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_769 (Dense)               (None, 64)           8256        dense_768[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_772 (Dense)               (None, 64)           8256        dense_771[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_770 (Dense)               (None, 32)           2080        dense_769[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_773 (Dense)               (None, 32)           2080        dense_772[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_96 (Concatenate)    (None, 64)           0           dense_770[0][0]                  \n",
      "                                                                 dense_773[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_774 (Dense)               (None, 8)            520         concatenate_96[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_775 (Dense)               (None, 1)            9           dense_774[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, 1)            0           dense_775[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,370,321\n",
      "Trainable params: 1,370,321\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (1/32) *****\n",
      "Search({'dr1': 0.1, 'dr2': 0.1, 'dr3': 0.1, 'unit': 256, 'lr': 0.01, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.72899, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.72899 to 0.73569, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.73569 to 0.75795, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.75795\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.75795\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.75795\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.75795\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.75795\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.75795\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.75795\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.75795\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.75795\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.75795\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.75795\n",
      "\n",
      "Epoch 00015: val_accuracy improved from 0.75795 to 0.76532, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.76532\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.76532\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.76532\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.76532\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.76532\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.76532\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.76532\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.76532\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.76532\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.76532\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.76532\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.76532\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.76532\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.76532\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.76532\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.76532\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.76532\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.76532\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.76532\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.76532\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.76532\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.76532\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.76532\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.76532\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.76532\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.76532\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.76532\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.76532\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.76532\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.76532\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.76532\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.76532\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.76532\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.76532\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.76532\n",
      "SCORE: 0.76532 at epoch 15\n",
      "Compilation Time :  0.002212047576904297\n",
      "Model: \"model_97\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_195 (InputLayer)          [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_291 (LSTM)                 (None, 240, 256)     265216      input_195[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_292 (LSTM)                 (None, 240, 256)     525312      lstm_291[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_293 (LSTM)                 (None, 256)          525312      lstm_292[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_196 (InputLayer)          [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_776 (Dense)               (None, 128)          32896       lstm_293[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_779 (Dense)               (None, 128)          384         input_196[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_777 (Dense)               (None, 64)           8256        dense_776[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_780 (Dense)               (None, 64)           8256        dense_779[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_778 (Dense)               (None, 32)           2080        dense_777[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_781 (Dense)               (None, 32)           2080        dense_780[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_97 (Concatenate)    (None, 64)           0           dense_778[0][0]                  \n",
      "                                                                 dense_781[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_782 (Dense)               (None, 8)            520         concatenate_97[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_783 (Dense)               (None, 1)            9           dense_782[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, 1)            0           dense_783[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,370,321\n",
      "Trainable params: 1,370,321\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (2/32) *****\n",
      "Search({'dr1': 0.1, 'dr2': 0.1, 'dr3': 0.1, 'unit': 256, 'lr': 0.001, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.76080, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.76080 to 0.77519, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.77519 to 0.78909, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.78909\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.78909 to 0.79444, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.79444 to 0.80365, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.80365\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.80365\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.80365 to 0.80867, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.80867 to 0.81453, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.81453 to 0.83244, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00012: val_accuracy improved from 0.83244 to 0.83847, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.83847\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.83847\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.83847\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.83847\n",
      "\n",
      "Epoch 00017: val_accuracy improved from 0.83847 to 0.84466, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.84466\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.84466\n",
      "\n",
      "Epoch 00020: val_accuracy improved from 0.84466 to 0.85018, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.85018\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.85018\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.85018\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.85018\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.85018\n",
      "\n",
      "Epoch 00026: val_accuracy improved from 0.85018 to 0.85136, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.85136\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.85136\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.85136\n",
      "\n",
      "Epoch 00030: val_accuracy improved from 0.85136 to 0.86173, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.86173\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.86173\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.86173\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.86173\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.86173\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.86173\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.86173\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.86173\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.86173\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.86173\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.86173\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.86173\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.86173\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.86173\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.86173\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.86173\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.86173\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.86173\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.86173\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.86173\n",
      "SCORE: 0.86173 at epoch 30\n",
      "Compilation Time :  0.0021598339080810547\n",
      "Model: \"model_98\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_197 (InputLayer)          [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_294 (LSTM)                 (None, 240, 384)     594432      input_197[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_295 (LSTM)                 (None, 240, 384)     1181184     lstm_294[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_296 (LSTM)                 (None, 384)          1181184     lstm_295[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_198 (InputLayer)          [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_784 (Dense)               (None, 128)          49280       lstm_296[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_787 (Dense)               (None, 128)          384         input_198[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_785 (Dense)               (None, 64)           8256        dense_784[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_788 (Dense)               (None, 64)           8256        dense_787[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_786 (Dense)               (None, 32)           2080        dense_785[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_789 (Dense)               (None, 32)           2080        dense_788[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_98 (Concatenate)    (None, 64)           0           dense_786[0][0]                  \n",
      "                                                                 dense_789[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_790 (Dense)               (None, 8)            520         concatenate_98[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_791 (Dense)               (None, 1)            9           dense_790[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, 1)            0           dense_791[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,027,665\n",
      "Trainable params: 3,027,665\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (3/32) *****\n",
      "Search({'dr1': 0.1, 'dr2': 0.1, 'dr3': 0.1, 'unit': 384, 'lr': 0.01, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.71577, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.71577 to 0.75109, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.75109\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.75109\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.75109\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.75109\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.75109\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.75109\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.75109\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.75109\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.75109\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.75109\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.75109\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.75109\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.75109\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.75109\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.75109\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.75109\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.75109\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.75109\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.75109\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.75109\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.75109\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.75109\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.75109\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.75109\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.75109\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.75109\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.75109\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.75109\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.75109\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.75109\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.75109\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.75109\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.75109\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.75109\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.75109\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.75109\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.75109\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.75109\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.75109\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.75109\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.75109\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.75109\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.75109\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.75109\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.75109\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.75109\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.75109\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.75109\n",
      "SCORE: 0.75109 at epoch 2\n",
      "Compilation Time :  0.0021712779998779297\n",
      "Model: \"model_99\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_199 (InputLayer)          [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_297 (LSTM)                 (None, 240, 384)     594432      input_199[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_298 (LSTM)                 (None, 240, 384)     1181184     lstm_297[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_299 (LSTM)                 (None, 384)          1181184     lstm_298[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_200 (InputLayer)          [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_792 (Dense)               (None, 128)          49280       lstm_299[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_795 (Dense)               (None, 128)          384         input_200[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_793 (Dense)               (None, 64)           8256        dense_792[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_796 (Dense)               (None, 64)           8256        dense_795[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_794 (Dense)               (None, 32)           2080        dense_793[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_797 (Dense)               (None, 32)           2080        dense_796[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_99 (Concatenate)    (None, 64)           0           dense_794[0][0]                  \n",
      "                                                                 dense_797[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_798 (Dense)               (None, 8)            520         concatenate_99[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_799 (Dense)               (None, 1)            9           dense_798[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, 1)            0           dense_799[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,027,665\n",
      "Trainable params: 3,027,665\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (4/32) *****\n",
      "Search({'dr1': 0.1, 'dr2': 0.1, 'dr3': 0.1, 'unit': 384, 'lr': 0.001, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.76281, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.76281\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.76281 to 0.76599, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.76599\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.76599 to 0.78775, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.78775 to 0.79310, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.79310 to 0.79428, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.79428 to 0.81419, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.81419 to 0.81570, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.81570\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.81570\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.81570\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.81570 to 0.81922, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.81922\n",
      "\n",
      "Epoch 00015: val_accuracy improved from 0.81922 to 0.83545, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00016: val_accuracy improved from 0.83545 to 0.84131, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.84131\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.84131\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.84131\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.84131\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.84131\n",
      "\n",
      "Epoch 00022: val_accuracy improved from 0.84131 to 0.84483, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.84483\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.84483\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.84483\n",
      "\n",
      "Epoch 00026: val_accuracy improved from 0.84483 to 0.84600, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00027: val_accuracy improved from 0.84600 to 0.84751, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.84751\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.84751\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.84751\n",
      "\n",
      "Epoch 00031: val_accuracy improved from 0.84751 to 0.85638, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.85638\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.85638\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.85638\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.85638\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.85638\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.85638\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.85638\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.85638\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.85638\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.85638\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.85638\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.85638\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.85638\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.85638\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.85638\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.85638\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.85638\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.85638\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.85638\n",
      "SCORE: 0.85638 at epoch 31\n",
      "Compilation Time :  0.002219676971435547\n",
      "Model: \"model_100\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_201 (InputLayer)          [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_300 (LSTM)                 (None, 240, 256)     265216      input_201[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_301 (LSTM)                 (None, 240, 256)     525312      lstm_300[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_302 (LSTM)                 (None, 256)          525312      lstm_301[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_202 (InputLayer)          [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_800 (Dense)               (None, 128)          32896       lstm_302[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_803 (Dense)               (None, 128)          384         input_202[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_801 (Dense)               (None, 64)           8256        dense_800[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_804 (Dense)               (None, 64)           8256        dense_803[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_802 (Dense)               (None, 32)           2080        dense_801[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_805 (Dense)               (None, 32)           2080        dense_804[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_100 (Concatenate)   (None, 64)           0           dense_802[0][0]                  \n",
      "                                                                 dense_805[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_806 (Dense)               (None, 8)            520         concatenate_100[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_807 (Dense)               (None, 1)            9           dense_806[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_100 (Activation)     (None, 1)            0           dense_807[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,370,321\n",
      "Trainable params: 1,370,321\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (5/32) *****\n",
      "Search({'dr1': 0.1, 'dr2': 0.1, 'dr3': 0.2, 'unit': 256, 'lr': 0.01, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.65082, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.65082 to 0.75745, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.75745\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.75745\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.75745\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.75745\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.75745\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.75745\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.75745 to 0.75795, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.75795\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.75795\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.75795\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.75795\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.75795\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.75795\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.75795\n",
      "\n",
      "Epoch 00017: val_accuracy improved from 0.75795 to 0.75845, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.75845\n",
      "\n",
      "Epoch 00019: val_accuracy improved from 0.75845 to 0.76096, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.76096\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.76096\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.76096\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.76096\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.76096\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.76096\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.76096\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.76096\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.76096\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.76096\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.76096\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.76096\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.76096\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.76096\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.76096\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.76096\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.76096\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.76096\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.76096\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.76096\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.76096\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.76096\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.76096\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.76096\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.76096\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.76096\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.76096\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.76096\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.76096\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.76096\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.76096\n",
      "SCORE: 0.76096 at epoch 19\n",
      "Compilation Time :  0.0022385120391845703\n",
      "Model: \"model_101\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_203 (InputLayer)          [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_303 (LSTM)                 (None, 240, 256)     265216      input_203[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_304 (LSTM)                 (None, 240, 256)     525312      lstm_303[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_305 (LSTM)                 (None, 256)          525312      lstm_304[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_204 (InputLayer)          [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_808 (Dense)               (None, 128)          32896       lstm_305[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_811 (Dense)               (None, 128)          384         input_204[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_809 (Dense)               (None, 64)           8256        dense_808[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_812 (Dense)               (None, 64)           8256        dense_811[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_810 (Dense)               (None, 32)           2080        dense_809[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_813 (Dense)               (None, 32)           2080        dense_812[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_101 (Concatenate)   (None, 64)           0           dense_810[0][0]                  \n",
      "                                                                 dense_813[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_814 (Dense)               (None, 8)            520         concatenate_101[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_815 (Dense)               (None, 1)            9           dense_814[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_101 (Activation)     (None, 1)            0           dense_815[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,370,321\n",
      "Trainable params: 1,370,321\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (6/32) *****\n",
      "Search({'dr1': 0.1, 'dr2': 0.1, 'dr3': 0.2, 'unit': 256, 'lr': 0.001, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.76448, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.76448\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.76448 to 0.78540, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.78540 to 0.78909, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.78909 to 0.80583, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.80583 to 0.81838, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.81838\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.81838\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.81838 to 0.83077, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.83077 to 0.83830, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.83830\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.83830\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.83830\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.83830\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.83830\n",
      "\n",
      "Epoch 00016: val_accuracy improved from 0.83830 to 0.84717, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00017: val_accuracy improved from 0.84717 to 0.84834, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.84834\n",
      "\n",
      "Epoch 00019: val_accuracy improved from 0.84834 to 0.85521, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.85521\n",
      "\n",
      "Epoch 00021: val_accuracy improved from 0.85521 to 0.85956, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.85956\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.85956\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.85956\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.85956\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.85956\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.85956\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.85956\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.85956\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.85956\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.85956\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.85956\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.85956\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.85956\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.85956\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.85956\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.85956\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.85956\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.85956\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.85956\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.85956\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.85956\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.85956\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.85956\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.85956\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.85956\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.85956\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.85956\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.85956\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.85956\n",
      "SCORE: 0.85956 at epoch 21\n",
      "Compilation Time :  0.002177000045776367\n",
      "Model: \"model_102\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_205 (InputLayer)          [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_306 (LSTM)                 (None, 240, 384)     594432      input_205[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_307 (LSTM)                 (None, 240, 384)     1181184     lstm_306[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_308 (LSTM)                 (None, 384)          1181184     lstm_307[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_206 (InputLayer)          [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_816 (Dense)               (None, 128)          49280       lstm_308[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_819 (Dense)               (None, 128)          384         input_206[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_817 (Dense)               (None, 64)           8256        dense_816[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_820 (Dense)               (None, 64)           8256        dense_819[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_818 (Dense)               (None, 32)           2080        dense_817[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_821 (Dense)               (None, 32)           2080        dense_820[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_102 (Concatenate)   (None, 64)           0           dense_818[0][0]                  \n",
      "                                                                 dense_821[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_822 (Dense)               (None, 8)            520         concatenate_102[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_823 (Dense)               (None, 1)            9           dense_822[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_102 (Activation)     (None, 1)            0           dense_823[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,027,665\n",
      "Trainable params: 3,027,665\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (7/32) *****\n",
      "Search({'dr1': 0.1, 'dr2': 0.1, 'dr3': 0.2, 'unit': 384, 'lr': 0.01, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.69886, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.69886 to 0.73803, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.73803\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.73803\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.73803\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.73803\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.73803\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.73803\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.73803 to 0.74305, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.74305\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.74741\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.74741\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.74741\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.74741\n",
      "\n",
      "Epoch 00018: val_accuracy improved from 0.74741 to 0.75410, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.75410\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.75410\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.75410\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.75410\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.75410\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.75410\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.75410\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.75410\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.75410\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.75410\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.75410\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.75410\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.75410\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.75410\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.75410\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.75410\n",
      "\n",
      "Epoch 00035: val_accuracy improved from 0.75410 to 0.76130, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.76130\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.76130\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.76130\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.76130\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.76130\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.76130\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.76130\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.76130\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.76130\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.76130\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.76130\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.76130\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.76130\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.76130\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.76130\n",
      "SCORE: 0.7613 at epoch 35\n",
      "Compilation Time :  0.0021719932556152344\n",
      "Model: \"model_103\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_207 (InputLayer)          [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_309 (LSTM)                 (None, 240, 384)     594432      input_207[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_310 (LSTM)                 (None, 240, 384)     1181184     lstm_309[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_311 (LSTM)                 (None, 384)          1181184     lstm_310[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_208 (InputLayer)          [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_824 (Dense)               (None, 128)          49280       lstm_311[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_827 (Dense)               (None, 128)          384         input_208[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_825 (Dense)               (None, 64)           8256        dense_824[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_828 (Dense)               (None, 64)           8256        dense_827[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_826 (Dense)               (None, 32)           2080        dense_825[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_829 (Dense)               (None, 32)           2080        dense_828[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_103 (Concatenate)   (None, 64)           0           dense_826[0][0]                  \n",
      "                                                                 dense_829[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_830 (Dense)               (None, 8)            520         concatenate_103[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_831 (Dense)               (None, 1)            9           dense_830[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_103 (Activation)     (None, 1)            0           dense_831[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,027,665\n",
      "Trainable params: 3,027,665\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (8/32) *****\n",
      "Search({'dr1': 0.1, 'dr2': 0.1, 'dr3': 0.2, 'unit': 384, 'lr': 0.001, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.73134, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.73134 to 0.77536, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.77536 to 0.79578, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.79578\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.79578\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.79578 to 0.79930, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.79930\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.79930 to 0.80700, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.80700 to 0.81754, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.81754\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.81754\n",
      "\n",
      "Epoch 00012: val_accuracy improved from 0.81754 to 0.82407, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.82407\n",
      "\n",
      "Epoch 00014: val_accuracy improved from 0.82407 to 0.83211, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.83211\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.83211\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.83211\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.83211\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.83211\n",
      "\n",
      "Epoch 00020: val_accuracy improved from 0.83211 to 0.84114, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.84114\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.84114\n",
      "\n",
      "Epoch 00023: val_accuracy improved from 0.84114 to 0.84516, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.84516\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.84516\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.84516\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.84516\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.84516\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.84516\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.84516\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.84516\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.84516\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.84516\n",
      "\n",
      "Epoch 00034: val_accuracy improved from 0.84516 to 0.84818, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.84818\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.84818\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.84818\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.84818\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.84818\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.84818\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.84818\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.84818\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.84818\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.84818\n",
      "\n",
      "Epoch 00045: val_accuracy improved from 0.84818 to 0.85085, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.85085\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.85085\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.85085\n",
      "\n",
      "Epoch 00049: val_accuracy improved from 0.85085 to 0.85119, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.85119\n",
      "SCORE: 0.85119 at epoch 49\n",
      "Compilation Time :  0.002140522003173828\n",
      "Model: \"model_104\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_209 (InputLayer)          [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_312 (LSTM)                 (None, 240, 256)     265216      input_209[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_313 (LSTM)                 (None, 240, 256)     525312      lstm_312[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_314 (LSTM)                 (None, 256)          525312      lstm_313[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_210 (InputLayer)          [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_832 (Dense)               (None, 128)          32896       lstm_314[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_835 (Dense)               (None, 128)          384         input_210[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_833 (Dense)               (None, 64)           8256        dense_832[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_836 (Dense)               (None, 64)           8256        dense_835[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_834 (Dense)               (None, 32)           2080        dense_833[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_837 (Dense)               (None, 32)           2080        dense_836[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_104 (Concatenate)   (None, 64)           0           dense_834[0][0]                  \n",
      "                                                                 dense_837[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_838 (Dense)               (None, 8)            520         concatenate_104[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_839 (Dense)               (None, 1)            9           dense_838[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_104 (Activation)     (None, 1)            0           dense_839[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,370,321\n",
      "Trainable params: 1,370,321\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (9/32) *****\n",
      "Search({'dr1': 0.1, 'dr2': 0.2, 'dr3': 0.1, 'unit': 256, 'lr': 0.01, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.63425, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.63425 to 0.75527, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.75527\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.75527\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.75527\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.75527\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.75527\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.75527\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.75527\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.75527\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.75527\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.75527\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.75527\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.75527\n",
      "\n",
      "Epoch 00015: val_accuracy improved from 0.75527 to 0.75912, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.75912\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.75912\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.75912\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.75912\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.75912\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.75912\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.75912\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.75912\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.75912\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.75912\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.75912\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.75912\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.75912\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.75912\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.75912\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.75912\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.75912\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.75912\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.75912\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.75912\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.75912\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.75912\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.75912\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.75912\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.75912\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.75912\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.75912\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.75912\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.75912\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.75912\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.75912\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.75912\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.75912\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.75912\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.75912\n",
      "SCORE: 0.75912 at epoch 15\n",
      "Compilation Time :  0.0022525787353515625\n",
      "Model: \"model_105\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_211 (InputLayer)          [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_315 (LSTM)                 (None, 240, 256)     265216      input_211[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_316 (LSTM)                 (None, 240, 256)     525312      lstm_315[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_317 (LSTM)                 (None, 256)          525312      lstm_316[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_212 (InputLayer)          [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_840 (Dense)               (None, 128)          32896       lstm_317[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_843 (Dense)               (None, 128)          384         input_212[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_841 (Dense)               (None, 64)           8256        dense_840[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_844 (Dense)               (None, 64)           8256        dense_843[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_842 (Dense)               (None, 32)           2080        dense_841[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_845 (Dense)               (None, 32)           2080        dense_844[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_105 (Concatenate)   (None, 64)           0           dense_842[0][0]                  \n",
      "                                                                 dense_845[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_846 (Dense)               (None, 8)            520         concatenate_105[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_847 (Dense)               (None, 1)            9           dense_846[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_105 (Activation)     (None, 1)            0           dense_847[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,370,321\n",
      "Trainable params: 1,370,321\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (10/32) *****\n",
      "Search({'dr1': 0.1, 'dr2': 0.2, 'dr3': 0.1, 'unit': 256, 'lr': 0.001, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.77335, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.77335 to 0.78591, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.78591 to 0.79310, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.79310\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.79310 to 0.79930, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.79930\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.79930 to 0.81068, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.81068 to 0.82290, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.82290 to 0.82809, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.82809\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.82809\n",
      "\n",
      "Epoch 00012: val_accuracy improved from 0.82809 to 0.83462, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.83462 to 0.83914, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00014: val_accuracy improved from 0.83914 to 0.84399, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.84399\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.84399\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.84399\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.84399\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.84399\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.84399\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.84399\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.84399\n",
      "\n",
      "Epoch 00023: val_accuracy improved from 0.84399 to 0.84751, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00024: val_accuracy improved from 0.84751 to 0.85119, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.85119\n",
      "\n",
      "Epoch 00026: val_accuracy improved from 0.85119 to 0.85169, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.85169\n",
      "\n",
      "Epoch 00028: val_accuracy improved from 0.85169 to 0.85219, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00029: val_accuracy improved from 0.85219 to 0.85655, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.85655\n",
      "\n",
      "Epoch 00031: val_accuracy improved from 0.85655 to 0.86173, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.86173\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.86173\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.86173\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.86173\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.86173\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.86173\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.86173\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.86173\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.86173\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.86173\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.86173\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.86173\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.86173\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.86173\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.86173\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.86173\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.86173\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.86173\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.86173\n",
      "SCORE: 0.86173 at epoch 31\n",
      "Compilation Time :  0.0022041797637939453\n",
      "Model: \"model_106\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_213 (InputLayer)          [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_318 (LSTM)                 (None, 240, 384)     594432      input_213[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_319 (LSTM)                 (None, 240, 384)     1181184     lstm_318[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_320 (LSTM)                 (None, 384)          1181184     lstm_319[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_214 (InputLayer)          [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_848 (Dense)               (None, 128)          49280       lstm_320[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_851 (Dense)               (None, 128)          384         input_214[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_849 (Dense)               (None, 64)           8256        dense_848[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_852 (Dense)               (None, 64)           8256        dense_851[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_850 (Dense)               (None, 32)           2080        dense_849[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_853 (Dense)               (None, 32)           2080        dense_852[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_106 (Concatenate)   (None, 64)           0           dense_850[0][0]                  \n",
      "                                                                 dense_853[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_854 (Dense)               (None, 8)            520         concatenate_106[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_855 (Dense)               (None, 1)            9           dense_854[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_106 (Activation)     (None, 1)            0           dense_855[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,027,665\n",
      "Trainable params: 3,027,665\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (11/32) *****\n",
      "Search({'dr1': 0.1, 'dr2': 0.2, 'dr3': 0.1, 'unit': 384, 'lr': 0.01, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.67677, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.67677\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.67677 to 0.72849, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.72849 to 0.73971, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.73971\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.73971\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.73971 to 0.74322, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.74322 to 0.75393, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.75393\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.75393\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.75393\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.75393\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.75393\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.75393\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.75393\n",
      "\n",
      "Epoch 00016: val_accuracy improved from 0.75393 to 0.76029, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.76029\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.76029\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.76029\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.76029\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.76029\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.76029\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.76029\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.76029\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.76029\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.76029\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.76029\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.76029\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.76029\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.76029\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.76029\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.76029\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.76029\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.76029\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.76029\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.76029\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.76029\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.76029\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.76029\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.76029\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.76029\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.76029\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.76029\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.76029\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.76029\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.76029\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.76029\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.76029\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.76029\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.76029\n",
      "SCORE: 0.76029 at epoch 16\n",
      "Compilation Time :  0.0022139549255371094\n",
      "Model: \"model_107\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_215 (InputLayer)          [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_321 (LSTM)                 (None, 240, 384)     594432      input_215[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_322 (LSTM)                 (None, 240, 384)     1181184     lstm_321[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_323 (LSTM)                 (None, 384)          1181184     lstm_322[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_216 (InputLayer)          [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_856 (Dense)               (None, 128)          49280       lstm_323[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_859 (Dense)               (None, 128)          384         input_216[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_857 (Dense)               (None, 64)           8256        dense_856[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_860 (Dense)               (None, 64)           8256        dense_859[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_858 (Dense)               (None, 32)           2080        dense_857[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_861 (Dense)               (None, 32)           2080        dense_860[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_107 (Concatenate)   (None, 64)           0           dense_858[0][0]                  \n",
      "                                                                 dense_861[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_862 (Dense)               (None, 8)            520         concatenate_107[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_863 (Dense)               (None, 1)            9           dense_862[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_107 (Activation)     (None, 1)            0           dense_863[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,027,665\n",
      "Trainable params: 3,027,665\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (12/32) *****\n",
      "Search({'dr1': 0.1, 'dr2': 0.2, 'dr3': 0.1, 'unit': 384, 'lr': 0.001, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.69066, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.69066 to 0.79143, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.79143 to 0.80248, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.80248 to 0.80398, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.80398 to 0.80666, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.80666 to 0.81235, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.81235\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.81235\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.81235 to 0.81704, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.81704 to 0.81888, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.81888 to 0.82608, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.82608\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.82608 to 0.83629, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.83629\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.83629\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.83629\n",
      "\n",
      "Epoch 00017: val_accuracy improved from 0.83629 to 0.83981, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.83981\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.83981\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.83981\n",
      "\n",
      "Epoch 00021: val_accuracy improved from 0.83981 to 0.84232, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.84232\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.84232\n",
      "\n",
      "Epoch 00024: val_accuracy improved from 0.84232 to 0.84248, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.84248\n",
      "\n",
      "Epoch 00026: val_accuracy improved from 0.84248 to 0.84516, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.84516\n",
      "\n",
      "Epoch 00028: val_accuracy improved from 0.84516 to 0.84918, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.84918\n",
      "\n",
      "Epoch 00030: val_accuracy improved from 0.84918 to 0.85721, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.85721\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.85721\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.85721\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.85721\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.85721\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.85721\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.85721\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.85721\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.85721\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.85721\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.85721\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.85721\n",
      "\n",
      "Epoch 00043: val_accuracy improved from 0.85721 to 0.85788, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.85788\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.85788\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.85788\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.85788\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.85788\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.85788\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.85788\n",
      "SCORE: 0.85788 at epoch 43\n",
      "Compilation Time :  0.0021719932556152344\n",
      "Model: \"model_108\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_217 (InputLayer)          [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_324 (LSTM)                 (None, 240, 256)     265216      input_217[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_325 (LSTM)                 (None, 240, 256)     525312      lstm_324[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_326 (LSTM)                 (None, 256)          525312      lstm_325[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_218 (InputLayer)          [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_864 (Dense)               (None, 128)          32896       lstm_326[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_867 (Dense)               (None, 128)          384         input_218[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_865 (Dense)               (None, 64)           8256        dense_864[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_868 (Dense)               (None, 64)           8256        dense_867[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_866 (Dense)               (None, 32)           2080        dense_865[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_869 (Dense)               (None, 32)           2080        dense_868[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_108 (Concatenate)   (None, 64)           0           dense_866[0][0]                  \n",
      "                                                                 dense_869[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_870 (Dense)               (None, 8)            520         concatenate_108[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_871 (Dense)               (None, 1)            9           dense_870[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_108 (Activation)     (None, 1)            0           dense_871[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,370,321\n",
      "Trainable params: 1,370,321\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (13/32) *****\n",
      "Search({'dr1': 0.1, 'dr2': 0.2, 'dr3': 0.2, 'unit': 256, 'lr': 0.01, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.62337, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.62337 to 0.71610, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.71610\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.71610 to 0.73753, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.73753\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.73753\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.73753\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.73753 to 0.75695, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.75695\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.75695\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.75695\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.75695\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.75695\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.75695\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.75695\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.75695\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.75695\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.75695\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.75695\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.75695\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.75695\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.75695\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.75695\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.75695\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.75695\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.75695\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.75695\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.75695\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.75695\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.75695\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.75695\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.75695\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.75695\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.75695\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.75695\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.75695\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.75695\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.75695\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.75695\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.75695\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.75695\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.75695\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.75695\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.75695\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.75695\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.75695\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.75695\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.75695\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.75695\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.75695\n",
      "SCORE: 0.75695 at epoch 8\n",
      "Compilation Time :  0.0022115707397460938\n",
      "Model: \"model_109\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_219 (InputLayer)          [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_327 (LSTM)                 (None, 240, 256)     265216      input_219[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_328 (LSTM)                 (None, 240, 256)     525312      lstm_327[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_329 (LSTM)                 (None, 256)          525312      lstm_328[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_220 (InputLayer)          [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_872 (Dense)               (None, 128)          32896       lstm_329[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_875 (Dense)               (None, 128)          384         input_220[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_873 (Dense)               (None, 64)           8256        dense_872[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_876 (Dense)               (None, 64)           8256        dense_875[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_874 (Dense)               (None, 32)           2080        dense_873[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_877 (Dense)               (None, 32)           2080        dense_876[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_109 (Concatenate)   (None, 64)           0           dense_874[0][0]                  \n",
      "                                                                 dense_877[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_878 (Dense)               (None, 8)            520         concatenate_109[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_879 (Dense)               (None, 1)            9           dense_878[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_109 (Activation)     (None, 1)            0           dense_879[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,370,321\n",
      "Trainable params: 1,370,321\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (14/32) *****\n",
      "Search({'dr1': 0.1, 'dr2': 0.2, 'dr3': 0.2, 'unit': 256, 'lr': 0.001, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.73719, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.73719 to 0.78239, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.78239 to 0.78741, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.78741 to 0.78825, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.78825 to 0.80348, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.80348\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.80348\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.80348\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.80348\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.80348 to 0.81336, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.81336 to 0.82256, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.82256\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.82256 to 0.82558, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00014: val_accuracy improved from 0.82558 to 0.83445, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.83445\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.83445\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.83445\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.83445\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.83445\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.83445\n",
      "\n",
      "Epoch 00021: val_accuracy improved from 0.83445 to 0.83947, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.83947\n",
      "\n",
      "Epoch 00023: val_accuracy improved from 0.83947 to 0.84332, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.84332\n",
      "\n",
      "Epoch 00025: val_accuracy improved from 0.84332 to 0.84499, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00026: val_accuracy improved from 0.84499 to 0.84935, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.84935\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.84935\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.84935\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.84935\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.84935\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.84935\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.84935\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.84935\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.84935\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.84935\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.84935\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.84935\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.84935\n",
      "\n",
      "Epoch 00040: val_accuracy improved from 0.84935 to 0.85253, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.85253\n",
      "\n",
      "Epoch 00042: val_accuracy improved from 0.85253 to 0.85303, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00043: val_accuracy improved from 0.85303 to 0.85604, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.85604\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.85604\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.85604\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.85604\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.85604\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.85604\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.85604\n",
      "SCORE: 0.85604 at epoch 43\n",
      "Compilation Time :  0.002142667770385742\n",
      "Model: \"model_110\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_221 (InputLayer)          [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_330 (LSTM)                 (None, 240, 384)     594432      input_221[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_331 (LSTM)                 (None, 240, 384)     1181184     lstm_330[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_332 (LSTM)                 (None, 384)          1181184     lstm_331[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_222 (InputLayer)          [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_880 (Dense)               (None, 128)          49280       lstm_332[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_883 (Dense)               (None, 128)          384         input_222[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_881 (Dense)               (None, 64)           8256        dense_880[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_884 (Dense)               (None, 64)           8256        dense_883[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_882 (Dense)               (None, 32)           2080        dense_881[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_885 (Dense)               (None, 32)           2080        dense_884[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_110 (Concatenate)   (None, 64)           0           dense_882[0][0]                  \n",
      "                                                                 dense_885[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_886 (Dense)               (None, 8)            520         concatenate_110[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_887 (Dense)               (None, 1)            9           dense_886[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_110 (Activation)     (None, 1)            0           dense_887[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,027,665\n",
      "Trainable params: 3,027,665\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (15/32) *****\n",
      "Search({'dr1': 0.1, 'dr2': 0.2, 'dr3': 0.2, 'unit': 384, 'lr': 0.01, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.73050, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.73050\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.73050\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.73050\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.73050\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.73050\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.73050\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.73050\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.73050\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.73050\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.73050\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.73050\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.73050\n",
      "\n",
      "Epoch 00014: val_accuracy improved from 0.73050 to 0.73703, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.73703\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.73703\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.73703\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.73703\n",
      "\n",
      "Epoch 00019: val_accuracy improved from 0.73703 to 0.73870, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.73870\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.73870\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.73870\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.73870\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.73870\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.73870\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.73870\n",
      "\n",
      "Epoch 00027: val_accuracy improved from 0.73870 to 0.74757, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.74757\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.74757\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.74757\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.74757\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.74757\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.74757\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.74757\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.74757\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.74757\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.74757\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.74757\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.74757\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.74757\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.74757\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.74757\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.74757\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.74757\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.74757\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.74757\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.74757\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.74757\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.74757\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.74757\n",
      "SCORE: 0.74757 at epoch 27\n",
      "Compilation Time :  0.002162933349609375\n",
      "Model: \"model_111\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_223 (InputLayer)          [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_333 (LSTM)                 (None, 240, 384)     594432      input_223[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_334 (LSTM)                 (None, 240, 384)     1181184     lstm_333[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_335 (LSTM)                 (None, 384)          1181184     lstm_334[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_224 (InputLayer)          [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_888 (Dense)               (None, 128)          49280       lstm_335[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_891 (Dense)               (None, 128)          384         input_224[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_889 (Dense)               (None, 64)           8256        dense_888[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_892 (Dense)               (None, 64)           8256        dense_891[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_890 (Dense)               (None, 32)           2080        dense_889[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_893 (Dense)               (None, 32)           2080        dense_892[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_111 (Concatenate)   (None, 64)           0           dense_890[0][0]                  \n",
      "                                                                 dense_893[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_894 (Dense)               (None, 8)            520         concatenate_111[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_895 (Dense)               (None, 1)            9           dense_894[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_111 (Activation)     (None, 1)            0           dense_895[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,027,665\n",
      "Trainable params: 3,027,665\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (16/32) *****\n",
      "Search({'dr1': 0.1, 'dr2': 0.2, 'dr3': 0.2, 'unit': 384, 'lr': 0.001, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.70941, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.70941 to 0.78189, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.78189\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.78189 to 0.79561, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.79561 to 0.80532, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.80532\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.80532 to 0.81453, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.81453\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.81453 to 0.82407, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.82407 to 0.82441, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.82441\n",
      "\n",
      "Epoch 00012: val_accuracy improved from 0.82441 to 0.82641, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.82641\n",
      "\n",
      "Epoch 00014: val_accuracy improved from 0.82641 to 0.83478, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.83478\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.83478\n",
      "\n",
      "Epoch 00017: val_accuracy improved from 0.83478 to 0.83612, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.83612\n",
      "\n",
      "Epoch 00019: val_accuracy improved from 0.83612 to 0.83696, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.83696\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.83696\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.83696\n",
      "\n",
      "Epoch 00023: val_accuracy improved from 0.83696 to 0.84533, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00024: val_accuracy improved from 0.84533 to 0.84700, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.84700\n",
      "\n",
      "Epoch 00026: val_accuracy improved from 0.84700 to 0.84784, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.84784\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.84784\n",
      "\n",
      "Epoch 00029: val_accuracy improved from 0.84784 to 0.85002, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.85002\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.85002\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.85002\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.85002\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.85002\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.85002\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.85002\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.85002\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.85002\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.85002\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.85002\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.85002\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.85002\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.85002\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.85002\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.85002\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.85002\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.85002\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.85002\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.85002\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.85002\n",
      "SCORE: 0.85002 at epoch 29\n",
      "Compilation Time :  0.0022013187408447266\n",
      "Model: \"model_112\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_225 (InputLayer)          [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_336 (LSTM)                 (None, 240, 256)     265216      input_225[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_337 (LSTM)                 (None, 240, 256)     525312      lstm_336[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_338 (LSTM)                 (None, 256)          525312      lstm_337[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_226 (InputLayer)          [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_896 (Dense)               (None, 128)          32896       lstm_338[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_899 (Dense)               (None, 128)          384         input_226[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_897 (Dense)               (None, 64)           8256        dense_896[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_900 (Dense)               (None, 64)           8256        dense_899[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_898 (Dense)               (None, 32)           2080        dense_897[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_901 (Dense)               (None, 32)           2080        dense_900[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_112 (Concatenate)   (None, 64)           0           dense_898[0][0]                  \n",
      "                                                                 dense_901[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_902 (Dense)               (None, 8)            520         concatenate_112[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_903 (Dense)               (None, 1)            9           dense_902[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_112 (Activation)     (None, 1)            0           dense_903[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,370,321\n",
      "Trainable params: 1,370,321\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (17/32) *****\n",
      "Search({'dr1': 0.2, 'dr2': 0.1, 'dr3': 0.1, 'unit': 256, 'lr': 0.01, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.68212, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.68212 to 0.70857, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.70857 to 0.74004, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.74004\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.74004\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.74004\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.74004\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.74004\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.74004\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.74004\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.74004\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.74004\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.74004\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.74004\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.74004\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.74004\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.74004\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.74004\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.74004\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.74004\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.74004\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.74004\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.74004\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.74004\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.74004\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.74004\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.74004\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.74004\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.74004\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.74004\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.74004\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.74004\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.74004\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.74004\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.74004\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.74004\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.74004\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.74004\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.74004\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.74004\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.74004\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.74004\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.74004\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.74004\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.74004\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.74004\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.74004\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.74004\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.74004\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.74004\n",
      "SCORE: 0.74004 at epoch 3\n",
      "Compilation Time :  0.0021789073944091797\n",
      "Model: \"model_113\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_227 (InputLayer)          [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_339 (LSTM)                 (None, 240, 256)     265216      input_227[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_340 (LSTM)                 (None, 240, 256)     525312      lstm_339[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_341 (LSTM)                 (None, 256)          525312      lstm_340[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_228 (InputLayer)          [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_904 (Dense)               (None, 128)          32896       lstm_341[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_907 (Dense)               (None, 128)          384         input_228[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_905 (Dense)               (None, 64)           8256        dense_904[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_908 (Dense)               (None, 64)           8256        dense_907[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_906 (Dense)               (None, 32)           2080        dense_905[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_909 (Dense)               (None, 32)           2080        dense_908[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_113 (Concatenate)   (None, 64)           0           dense_906[0][0]                  \n",
      "                                                                 dense_909[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_910 (Dense)               (None, 8)            520         concatenate_113[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_911 (Dense)               (None, 1)            9           dense_910[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_113 (Activation)     (None, 1)            0           dense_911[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,370,321\n",
      "Trainable params: 1,370,321\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (18/32) *****\n",
      "Search({'dr1': 0.2, 'dr2': 0.1, 'dr3': 0.1, 'unit': 256, 'lr': 0.001, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.70506, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.70506 to 0.75678, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.75678\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.75678 to 0.76230, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.76230\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.76230 to 0.79227, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.79227 to 0.81553, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.81553\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.81553\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.81553 to 0.81620, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.81620\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.81620\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.81620\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.81620\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.81620\n",
      "\n",
      "Epoch 00016: val_accuracy improved from 0.81620 to 0.82039, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00017: val_accuracy improved from 0.82039 to 0.82290, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.82290\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.82290\n",
      "\n",
      "Epoch 00020: val_accuracy improved from 0.82290 to 0.83763, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.83763\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.83763\n",
      "\n",
      "Epoch 00023: val_accuracy improved from 0.83763 to 0.84951, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.84951\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.84951\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.84951\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.84951\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.84951\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.84951\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.84951\n",
      "\n",
      "Epoch 00031: val_accuracy improved from 0.84951 to 0.85018, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.85018\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.85018\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.85018\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.85018\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.85018\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.85018\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.85018\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.85018\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.85018\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.85018\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.85018\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.85018\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.85018\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.85018\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.85018\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.85018\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.85018\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.85018\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.85018\n",
      "SCORE: 0.85018 at epoch 31\n",
      "Compilation Time :  0.002246379852294922\n",
      "Model: \"model_114\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_229 (InputLayer)          [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_342 (LSTM)                 (None, 240, 384)     594432      input_229[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_343 (LSTM)                 (None, 240, 384)     1181184     lstm_342[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_344 (LSTM)                 (None, 384)          1181184     lstm_343[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_230 (InputLayer)          [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_912 (Dense)               (None, 128)          49280       lstm_344[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_915 (Dense)               (None, 128)          384         input_230[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_913 (Dense)               (None, 64)           8256        dense_912[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_916 (Dense)               (None, 64)           8256        dense_915[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_914 (Dense)               (None, 32)           2080        dense_913[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_917 (Dense)               (None, 32)           2080        dense_916[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_114 (Concatenate)   (None, 64)           0           dense_914[0][0]                  \n",
      "                                                                 dense_917[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_918 (Dense)               (None, 8)            520         concatenate_114[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_919 (Dense)               (None, 1)            9           dense_918[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_114 (Activation)     (None, 1)            0           dense_919[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,027,665\n",
      "Trainable params: 3,027,665\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (19/32) *****\n",
      "Search({'dr1': 0.2, 'dr2': 0.1, 'dr3': 0.1, 'unit': 384, 'lr': 0.01, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.72079, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.72079\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.72079\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.72079 to 0.73837, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.73837 to 0.74908, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.74908\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.74908\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.74908\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.74908\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.74908\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.74908\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.74908\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.74908\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.74908\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.74908\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.74908\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.74908\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.74908\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.74908\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.74908\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.74908\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.74908\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.74908\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.74908\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.74908\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.74908\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.74908\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.74908\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.74908\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.74908\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.74908\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.74908\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.74908\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.74908\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.74908\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.74908\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.74908\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.74908\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.74908\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.74908\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.74908\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.74908\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.74908\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.74908\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.74908\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.74908\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.74908\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.74908\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.74908\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.74908\n",
      "SCORE: 0.74908 at epoch 5\n",
      "Compilation Time :  0.002166271209716797\n",
      "Model: \"model_115\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_231 (InputLayer)          [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_345 (LSTM)                 (None, 240, 384)     594432      input_231[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_346 (LSTM)                 (None, 240, 384)     1181184     lstm_345[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_347 (LSTM)                 (None, 384)          1181184     lstm_346[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_232 (InputLayer)          [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_920 (Dense)               (None, 128)          49280       lstm_347[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_923 (Dense)               (None, 128)          384         input_232[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_921 (Dense)               (None, 64)           8256        dense_920[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_924 (Dense)               (None, 64)           8256        dense_923[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_922 (Dense)               (None, 32)           2080        dense_921[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_925 (Dense)               (None, 32)           2080        dense_924[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_115 (Concatenate)   (None, 64)           0           dense_922[0][0]                  \n",
      "                                                                 dense_925[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_926 (Dense)               (None, 8)            520         concatenate_115[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_927 (Dense)               (None, 1)            9           dense_926[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_115 (Activation)     (None, 1)            0           dense_927[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,027,665\n",
      "Trainable params: 3,027,665\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (20/32) *****\n",
      "Search({'dr1': 0.2, 'dr2': 0.1, 'dr3': 0.1, 'unit': 384, 'lr': 0.001, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.78607, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.78607\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.78607\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.78607\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.78607\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.78607\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.78607\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.78607 to 0.78758, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.78758 to 0.80783, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.80783 to 0.81888, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.81888 to 0.82524, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.82524\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.82524\n",
      "\n",
      "Epoch 00014: val_accuracy improved from 0.82524 to 0.82859, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.82859\n",
      "\n",
      "Epoch 00016: val_accuracy improved from 0.82859 to 0.83194, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.83194\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.83194\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.83194\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.83194\n",
      "\n",
      "Epoch 00021: val_accuracy improved from 0.83194 to 0.83378, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.83378\n",
      "\n",
      "Epoch 00023: val_accuracy improved from 0.83378 to 0.83629, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.83629\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.83629\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.83629\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.83629\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.83629\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.83629\n",
      "\n",
      "Epoch 00030: val_accuracy improved from 0.83629 to 0.83646, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00031: val_accuracy improved from 0.83646 to 0.84332, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.84332\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.84332\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.84332\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.84332\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.84332\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.84332\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.84332\n",
      "\n",
      "Epoch 00039: val_accuracy improved from 0.84332 to 0.84349, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.84349\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.84349\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.84349\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.84349\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.84349\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.84349\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.84349\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.84349\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.84349\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.84349\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.84349\n",
      "SCORE: 0.84349 at epoch 39\n",
      "Compilation Time :  0.0022253990173339844\n",
      "Model: \"model_116\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_233 (InputLayer)          [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_348 (LSTM)                 (None, 240, 256)     265216      input_233[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_349 (LSTM)                 (None, 240, 256)     525312      lstm_348[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_350 (LSTM)                 (None, 256)          525312      lstm_349[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_234 (InputLayer)          [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_928 (Dense)               (None, 128)          32896       lstm_350[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_931 (Dense)               (None, 128)          384         input_234[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_929 (Dense)               (None, 64)           8256        dense_928[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_932 (Dense)               (None, 64)           8256        dense_931[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_930 (Dense)               (None, 32)           2080        dense_929[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_933 (Dense)               (None, 32)           2080        dense_932[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_116 (Concatenate)   (None, 64)           0           dense_930[0][0]                  \n",
      "                                                                 dense_933[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_934 (Dense)               (None, 8)            520         concatenate_116[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_935 (Dense)               (None, 1)            9           dense_934[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_116 (Activation)     (None, 1)            0           dense_935[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,370,321\n",
      "Trainable params: 1,370,321\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (21/32) *****\n",
      "Search({'dr1': 0.2, 'dr2': 0.1, 'dr3': 0.2, 'unit': 256, 'lr': 0.01, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.61316, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.61316 to 0.73703, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.73703 to 0.77335, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.77335\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.77335 to 0.77553, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.77553\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.77553\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.77553\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.77553\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.77553\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.77553\n",
      "\n",
      "Epoch 00012: val_accuracy improved from 0.77553 to 0.78289, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.78289\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.78289\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.78289\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.78289\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.78289\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.78289\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.78289\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.78289\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.78289\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.78289\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.78289\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.78289\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.78289\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.78289\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.78289\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.78289\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.78289\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.78289\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.78289\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.78289\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.78289\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.78289\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.78289\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.78289\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.78289\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.78289\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.78289\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.78289\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.78289\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.78289\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.78289\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.78289\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.78289\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.78289\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.78289\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.78289\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.78289\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.78289\n",
      "SCORE: 0.78289 at epoch 12\n",
      "Compilation Time :  0.0021359920501708984\n",
      "Model: \"model_117\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_235 (InputLayer)          [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_351 (LSTM)                 (None, 240, 256)     265216      input_235[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_352 (LSTM)                 (None, 240, 256)     525312      lstm_351[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_353 (LSTM)                 (None, 256)          525312      lstm_352[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_236 (InputLayer)          [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_936 (Dense)               (None, 128)          32896       lstm_353[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_939 (Dense)               (None, 128)          384         input_236[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_937 (Dense)               (None, 64)           8256        dense_936[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_940 (Dense)               (None, 64)           8256        dense_939[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_938 (Dense)               (None, 32)           2080        dense_937[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_941 (Dense)               (None, 32)           2080        dense_940[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_117 (Concatenate)   (None, 64)           0           dense_938[0][0]                  \n",
      "                                                                 dense_941[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_942 (Dense)               (None, 8)            520         concatenate_117[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_943 (Dense)               (None, 1)            9           dense_942[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_117 (Activation)     (None, 1)            0           dense_943[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,370,321\n",
      "Trainable params: 1,370,321\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (22/32) *****\n",
      "Search({'dr1': 0.2, 'dr2': 0.1, 'dr3': 0.2, 'unit': 256, 'lr': 0.001, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.69133, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.69133 to 0.72380, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.72380 to 0.73100, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.73100\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.73100\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.73100 to 0.76850, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.76850\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.76850 to 0.79997, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.79997\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.79997\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.79997\n",
      "\n",
      "Epoch 00012: val_accuracy improved from 0.79997 to 0.83010, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.83010\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.83010\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.83010\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.83010\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.83010\n",
      "\n",
      "Epoch 00018: val_accuracy improved from 0.83010 to 0.83110, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00019: val_accuracy improved from 0.83110 to 0.83144, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.83144\n",
      "\n",
      "Epoch 00021: val_accuracy improved from 0.83144 to 0.83211, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.83211\n",
      "\n",
      "Epoch 00023: val_accuracy improved from 0.83211 to 0.84315, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.84315\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.84315\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.84315\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.84315\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.84315\n",
      "\n",
      "Epoch 00029: val_accuracy improved from 0.84315 to 0.84382, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.84382\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.84382\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.84382\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.84382\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.84382\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.84382\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.84382\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.84382\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.84382\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.84382\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.84382\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.84382\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.84382\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.84382\n",
      "\n",
      "Epoch 00044: val_accuracy improved from 0.84382 to 0.84499, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.84499\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.84499\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.84499\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.84499\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.84499\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.84499\n",
      "SCORE: 0.84499 at epoch 44\n",
      "Compilation Time :  0.00217437744140625\n",
      "Model: \"model_118\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_237 (InputLayer)          [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_354 (LSTM)                 (None, 240, 384)     594432      input_237[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_355 (LSTM)                 (None, 240, 384)     1181184     lstm_354[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_356 (LSTM)                 (None, 384)          1181184     lstm_355[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_238 (InputLayer)          [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_944 (Dense)               (None, 128)          49280       lstm_356[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_947 (Dense)               (None, 128)          384         input_238[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_945 (Dense)               (None, 64)           8256        dense_944[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_948 (Dense)               (None, 64)           8256        dense_947[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_946 (Dense)               (None, 32)           2080        dense_945[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_949 (Dense)               (None, 32)           2080        dense_948[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_118 (Concatenate)   (None, 64)           0           dense_946[0][0]                  \n",
      "                                                                 dense_949[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_950 (Dense)               (None, 8)            520         concatenate_118[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_951 (Dense)               (None, 1)            9           dense_950[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_118 (Activation)     (None, 1)            0           dense_951[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,027,665\n",
      "Trainable params: 3,027,665\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (23/32) *****\n",
      "Search({'dr1': 0.2, 'dr2': 0.1, 'dr3': 0.2, 'unit': 384, 'lr': 0.01, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.61918, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.61918 to 0.72832, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.72832\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.72832 to 0.73033, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.73033 to 0.74155, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.74155\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.74155\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.74155\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.74155\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.74155\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.74155\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.74155\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.74155\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.74155\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.74155\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.74155\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.74155\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.74155\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.74155\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.74155\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.74155\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.74155\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.74155\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.74155\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.74155\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.74155\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.74155\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.74155\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.74155\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.74155\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.74155\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.74155\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.74155\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.74155\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.74155\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.74155\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.74155\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.74155\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.74155\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.74155\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.74155\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.74155\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.74155\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.74155\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.74155\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.74155\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.74155\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.74155\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.74155\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.74155\n",
      "SCORE: 0.74155 at epoch 5\n",
      "Compilation Time :  0.0022034645080566406\n",
      "Model: \"model_119\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_239 (InputLayer)          [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_357 (LSTM)                 (None, 240, 384)     594432      input_239[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_358 (LSTM)                 (None, 240, 384)     1181184     lstm_357[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_359 (LSTM)                 (None, 384)          1181184     lstm_358[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_240 (InputLayer)          [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_952 (Dense)               (None, 128)          49280       lstm_359[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_955 (Dense)               (None, 128)          384         input_240[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_953 (Dense)               (None, 64)           8256        dense_952[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_956 (Dense)               (None, 64)           8256        dense_955[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_954 (Dense)               (None, 32)           2080        dense_953[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_957 (Dense)               (None, 32)           2080        dense_956[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_119 (Concatenate)   (None, 64)           0           dense_954[0][0]                  \n",
      "                                                                 dense_957[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_958 (Dense)               (None, 8)            520         concatenate_119[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_959 (Dense)               (None, 1)            9           dense_958[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_119 (Activation)     (None, 1)            0           dense_959[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,027,665\n",
      "Trainable params: 3,027,665\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (24/32) *****\n",
      "Search({'dr1': 0.2, 'dr2': 0.1, 'dr3': 0.2, 'unit': 384, 'lr': 0.001, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.74975, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.74975 to 0.75276, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.75276 to 0.75544, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.75544\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.75544\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.75544 to 0.77268, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.77268\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.77268\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.77268 to 0.78323, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.78323 to 0.79377, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.79377\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.79377\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.79377 to 0.81938, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.81938\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.81938\n",
      "\n",
      "Epoch 00016: val_accuracy improved from 0.81938 to 0.82943, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.82943\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.82943\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.82943\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.82943\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.82943\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.82943\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.82943\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.82943\n",
      "\n",
      "Epoch 00025: val_accuracy improved from 0.82943 to 0.83612, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.83612\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.83612\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.83612\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.83612\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.83612\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.83612\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.83612\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.83612\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.83612\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.83612\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.83612\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.83612\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.83612\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.83612\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.83612\n",
      "\n",
      "Epoch 00041: val_accuracy improved from 0.83612 to 0.84232, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.84232\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.84232\n",
      "\n",
      "Epoch 00044: val_accuracy improved from 0.84232 to 0.84466, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.84466\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.84466\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.84466\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.84466\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.84466\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.84466\n",
      "SCORE: 0.84466 at epoch 44\n",
      "Compilation Time :  0.0021626949310302734\n",
      "Model: \"model_120\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_241 (InputLayer)          [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_360 (LSTM)                 (None, 240, 256)     265216      input_241[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_361 (LSTM)                 (None, 240, 256)     525312      lstm_360[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_362 (LSTM)                 (None, 256)          525312      lstm_361[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_242 (InputLayer)          [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_960 (Dense)               (None, 128)          32896       lstm_362[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_963 (Dense)               (None, 128)          384         input_242[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_961 (Dense)               (None, 64)           8256        dense_960[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_964 (Dense)               (None, 64)           8256        dense_963[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_962 (Dense)               (None, 32)           2080        dense_961[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_965 (Dense)               (None, 32)           2080        dense_964[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_120 (Concatenate)   (None, 64)           0           dense_962[0][0]                  \n",
      "                                                                 dense_965[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_966 (Dense)               (None, 8)            520         concatenate_120[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_967 (Dense)               (None, 1)            9           dense_966[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_120 (Activation)     (None, 1)            0           dense_967[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,370,321\n",
      "Trainable params: 1,370,321\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (25/32) *****\n",
      "Search({'dr1': 0.2, 'dr2': 0.2, 'dr3': 0.1, 'unit': 256, 'lr': 0.01, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.75427, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.75427\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.75427\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.75427\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.75427\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.75427\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.75427\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.75427\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.75427\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.75427\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.75427\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.75427\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.75427\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.75427\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.75427\n",
      "\n",
      "Epoch 00016: val_accuracy improved from 0.75427 to 0.75762, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.75762\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.75762\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.75762\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.75762\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.75762\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.75762\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.75762\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.75762\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.75762\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.75762\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.75762\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.75762\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.75762\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.75762\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.75762\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.75762\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.75762\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.75762\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.75762\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.75762\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.75762\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.75762\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.75762\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.75762\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.75762\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.75762\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.75762\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.75762\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.75762\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.75762\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.75762\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.75762\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.75762\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.75762\n",
      "SCORE: 0.75762 at epoch 16\n",
      "Compilation Time :  0.0022165775299072266\n",
      "Model: \"model_121\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_243 (InputLayer)          [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_363 (LSTM)                 (None, 240, 256)     265216      input_243[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_364 (LSTM)                 (None, 240, 256)     525312      lstm_363[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_365 (LSTM)                 (None, 256)          525312      lstm_364[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_244 (InputLayer)          [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_968 (Dense)               (None, 128)          32896       lstm_365[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_971 (Dense)               (None, 128)          384         input_244[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_969 (Dense)               (None, 64)           8256        dense_968[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_972 (Dense)               (None, 64)           8256        dense_971[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_970 (Dense)               (None, 32)           2080        dense_969[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_973 (Dense)               (None, 32)           2080        dense_972[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_121 (Concatenate)   (None, 64)           0           dense_970[0][0]                  \n",
      "                                                                 dense_973[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_974 (Dense)               (None, 8)            520         concatenate_121[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_975 (Dense)               (None, 1)            9           dense_974[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_121 (Activation)     (None, 1)            0           dense_975[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,370,321\n",
      "Trainable params: 1,370,321\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (26/32) *****\n",
      "Search({'dr1': 0.2, 'dr2': 0.2, 'dr3': 0.1, 'unit': 256, 'lr': 0.001, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.77151, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.77151\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.77151\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.77151\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.77151\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.77151\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.77151\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.77151 to 0.79243, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.79243\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.79243 to 0.79662, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.79662 to 0.81269, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.81269\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.81269 to 0.81654, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.81654\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.81654\n",
      "\n",
      "Epoch 00016: val_accuracy improved from 0.81654 to 0.81738, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00017: val_accuracy improved from 0.81738 to 0.82792, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.82792\n",
      "\n",
      "Epoch 00019: val_accuracy improved from 0.82792 to 0.82993, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.82993\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.82993\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.82993\n",
      "\n",
      "Epoch 00023: val_accuracy improved from 0.82993 to 0.83093, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.83093\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.83093\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.83093\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.83093\n",
      "\n",
      "Epoch 00028: val_accuracy improved from 0.83093 to 0.83278, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.83278\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.83278\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.83278\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.83278\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.83278\n",
      "\n",
      "Epoch 00034: val_accuracy improved from 0.83278 to 0.83997, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.83997\n",
      "\n",
      "Epoch 00036: val_accuracy improved from 0.83997 to 0.84583, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.84583\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.84583\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.84583\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.84583\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.84583\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.84583\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.84583\n",
      "\n",
      "Epoch 00044: val_accuracy improved from 0.84583 to 0.84751, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.84751\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.84751\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.84751\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.84751\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.84751\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.84751\n",
      "SCORE: 0.84751 at epoch 44\n",
      "Compilation Time :  0.002177715301513672\n",
      "Model: \"model_122\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_245 (InputLayer)          [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_366 (LSTM)                 (None, 240, 384)     594432      input_245[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_367 (LSTM)                 (None, 240, 384)     1181184     lstm_366[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_368 (LSTM)                 (None, 384)          1181184     lstm_367[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_246 (InputLayer)          [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_976 (Dense)               (None, 128)          49280       lstm_368[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_979 (Dense)               (None, 128)          384         input_246[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_977 (Dense)               (None, 64)           8256        dense_976[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_980 (Dense)               (None, 64)           8256        dense_979[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_978 (Dense)               (None, 32)           2080        dense_977[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_981 (Dense)               (None, 32)           2080        dense_980[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_122 (Concatenate)   (None, 64)           0           dense_978[0][0]                  \n",
      "                                                                 dense_981[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_982 (Dense)               (None, 8)            520         concatenate_122[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_983 (Dense)               (None, 1)            9           dense_982[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_122 (Activation)     (None, 1)            0           dense_983[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,027,665\n",
      "Trainable params: 3,027,665\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (27/32) *****\n",
      "Search({'dr1': 0.2, 'dr2': 0.2, 'dr3': 0.1, 'unit': 384, 'lr': 0.01, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.69200, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.69200 to 0.71761, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.71761\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.71761\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.71761\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.71761 to 0.73586, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.73586\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.73586\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.73586\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.73586\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.73586\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.73586\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.73586\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.73586\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.73586\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.73586\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.73586\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.73586\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.73586\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.73586\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.73586\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.73586\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.73586\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.73586\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.73586\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.73586\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.73586\n",
      "\n",
      "Epoch 00028: val_accuracy improved from 0.73586 to 0.74439, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.74439\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.74439\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.74439\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.74439\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.74439\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.74439\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.74439\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.74439\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.74439\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.74439\n",
      "\n",
      "Epoch 00039: val_accuracy improved from 0.74439 to 0.74590, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.74590\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.74590\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.74590\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.74590\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.74590\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.74590\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.74590\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.74590\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.74590\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.74590\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.74590\n",
      "SCORE: 0.7459 at epoch 39\n",
      "Compilation Time :  0.002232074737548828\n",
      "Model: \"model_123\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_247 (InputLayer)          [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_369 (LSTM)                 (None, 240, 384)     594432      input_247[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_370 (LSTM)                 (None, 240, 384)     1181184     lstm_369[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_371 (LSTM)                 (None, 384)          1181184     lstm_370[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_248 (InputLayer)          [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_984 (Dense)               (None, 128)          49280       lstm_371[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_987 (Dense)               (None, 128)          384         input_248[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_985 (Dense)               (None, 64)           8256        dense_984[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_988 (Dense)               (None, 64)           8256        dense_987[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_986 (Dense)               (None, 32)           2080        dense_985[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_989 (Dense)               (None, 32)           2080        dense_988[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_123 (Concatenate)   (None, 64)           0           dense_986[0][0]                  \n",
      "                                                                 dense_989[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_990 (Dense)               (None, 8)            520         concatenate_123[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_991 (Dense)               (None, 1)            9           dense_990[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_123 (Activation)     (None, 1)            0           dense_991[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,027,665\n",
      "Trainable params: 3,027,665\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (28/32) *****\n",
      "Search({'dr1': 0.2, 'dr2': 0.2, 'dr3': 0.1, 'unit': 384, 'lr': 0.001, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.77503, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.77503\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.77503\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.77503\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.77503\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.77503\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.77503 to 0.79846, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.79846\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.79846 to 0.81152, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.81152\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.81152\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.81152\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.81152\n",
      "\n",
      "Epoch 00014: val_accuracy improved from 0.81152 to 0.81771, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.81771\n",
      "\n",
      "Epoch 00016: val_accuracy improved from 0.81771 to 0.81989, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.81989\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.81989\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.81989\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.81989\n",
      "\n",
      "Epoch 00021: val_accuracy improved from 0.81989 to 0.82457, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.82457\n",
      "\n",
      "Epoch 00023: val_accuracy improved from 0.82457 to 0.83344, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.83344\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.83344\n",
      "\n",
      "Epoch 00026: val_accuracy improved from 0.83344 to 0.84600, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.84600\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.84600\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.84600\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.84600\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.84600\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.84600\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.84600\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.84600\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.84600\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.84600\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.84600\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.84600\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.84600\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.84600\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.84600\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.84600\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.84600\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.84600\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.84600\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.84600\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.84600\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.84600\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.84600\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.84600\n",
      "SCORE: 0.846 at epoch 26\n",
      "Compilation Time :  0.0021774768829345703\n",
      "Model: \"model_124\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_249 (InputLayer)          [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_372 (LSTM)                 (None, 240, 256)     265216      input_249[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_373 (LSTM)                 (None, 240, 256)     525312      lstm_372[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_374 (LSTM)                 (None, 256)          525312      lstm_373[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_250 (InputLayer)          [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_992 (Dense)               (None, 128)          32896       lstm_374[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_995 (Dense)               (None, 128)          384         input_250[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_993 (Dense)               (None, 64)           8256        dense_992[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_996 (Dense)               (None, 64)           8256        dense_995[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_994 (Dense)               (None, 32)           2080        dense_993[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_997 (Dense)               (None, 32)           2080        dense_996[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_124 (Concatenate)   (None, 64)           0           dense_994[0][0]                  \n",
      "                                                                 dense_997[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_998 (Dense)               (None, 8)            520         concatenate_124[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_999 (Dense)               (None, 1)            9           dense_998[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_124 (Activation)     (None, 1)            0           dense_999[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,370,321\n",
      "Trainable params: 1,370,321\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (29/32) *****\n",
      "Search({'dr1': 0.2, 'dr2': 0.2, 'dr3': 0.2, 'unit': 256, 'lr': 0.01, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.74305, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.74305\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.74305\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.74305\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.74305\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.74305\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.74305\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.74305\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.74305 to 0.75159, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.75159\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.75159\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.75159\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.75159\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.75159\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.75159\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.75159\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.75159\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.75159\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.75159\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.75159\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.75159\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.75159\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.75159\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.75159\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.75159\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.75159\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.75159\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.75159\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.75159\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.75159\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.75159\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.75159\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.75159\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.75159\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.75159\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.75159\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.75159\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.75159\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.75159\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.75159\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.75159\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.75159\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.75159\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.75159\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.75159\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.75159\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.75159\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.75159\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.75159\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.75159\n",
      "SCORE: 0.75159 at epoch 9\n",
      "Compilation Time :  0.00215911865234375\n",
      "Model: \"model_125\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_251 (InputLayer)          [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_375 (LSTM)                 (None, 240, 256)     265216      input_251[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_376 (LSTM)                 (None, 240, 256)     525312      lstm_375[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_377 (LSTM)                 (None, 256)          525312      lstm_376[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_252 (InputLayer)          [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1000 (Dense)              (None, 128)          32896       lstm_377[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1003 (Dense)              (None, 128)          384         input_252[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1001 (Dense)              (None, 64)           8256        dense_1000[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1004 (Dense)              (None, 64)           8256        dense_1003[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1002 (Dense)              (None, 32)           2080        dense_1001[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1005 (Dense)              (None, 32)           2080        dense_1004[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_125 (Concatenate)   (None, 64)           0           dense_1002[0][0]                 \n",
      "                                                                 dense_1005[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1006 (Dense)              (None, 8)            520         concatenate_125[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1007 (Dense)              (None, 1)            9           dense_1006[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_125 (Activation)     (None, 1)            0           dense_1007[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 1,370,321\n",
      "Trainable params: 1,370,321\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (30/32) *****\n",
      "Search({'dr1': 0.2, 'dr2': 0.2, 'dr3': 0.2, 'unit': 256, 'lr': 0.001, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.69284, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.69284 to 0.73837, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.73837\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.73837\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.73837 to 0.78222, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.78222\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.78222 to 0.79478, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.79478\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.79478 to 0.81671, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.81671\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.81671 to 0.82256, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.82256\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.82256\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.82256\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.82256\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.82256\n",
      "\n",
      "Epoch 00017: val_accuracy improved from 0.82256 to 0.82491, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00018: val_accuracy improved from 0.82491 to 0.83545, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.83545\n",
      "\n",
      "Epoch 00020: val_accuracy improved from 0.83545 to 0.83746, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.83746\n",
      "\n",
      "Epoch 00022: val_accuracy improved from 0.83746 to 0.84031, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.84031\n",
      "\n",
      "Epoch 00024: val_accuracy improved from 0.84031 to 0.84081, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00025: val_accuracy improved from 0.84081 to 0.84533, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.84533\n",
      "\n",
      "Epoch 00027: val_accuracy improved from 0.84533 to 0.84667, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.84667\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.84667\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.84667\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.84667\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.84667\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.84667\n",
      "\n",
      "Epoch 00034: val_accuracy improved from 0.84667 to 0.84885, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.84885\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.84885\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.84885\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.84885\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.84885\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.84885\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.84885\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.84885\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.84885\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.84885\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.84885\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.84885\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.84885\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.84885\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.84885\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.84885\n",
      "SCORE: 0.84885 at epoch 34\n",
      "Compilation Time :  0.002263784408569336\n",
      "Model: \"model_126\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_253 (InputLayer)          [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_378 (LSTM)                 (None, 240, 384)     594432      input_253[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_379 (LSTM)                 (None, 240, 384)     1181184     lstm_378[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_380 (LSTM)                 (None, 384)          1181184     lstm_379[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_254 (InputLayer)          [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1008 (Dense)              (None, 128)          49280       lstm_380[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1011 (Dense)              (None, 128)          384         input_254[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1009 (Dense)              (None, 64)           8256        dense_1008[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1012 (Dense)              (None, 64)           8256        dense_1011[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1010 (Dense)              (None, 32)           2080        dense_1009[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1013 (Dense)              (None, 32)           2080        dense_1012[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_126 (Concatenate)   (None, 64)           0           dense_1010[0][0]                 \n",
      "                                                                 dense_1013[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1014 (Dense)              (None, 8)            520         concatenate_126[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1015 (Dense)              (None, 1)            9           dense_1014[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_126 (Activation)     (None, 1)            0           dense_1015[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 3,027,665\n",
      "Trainable params: 3,027,665\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (31/32) *****\n",
      "Search({'dr1': 0.2, 'dr2': 0.2, 'dr3': 0.2, 'unit': 384, 'lr': 0.01, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.62688, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.62688\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.62688 to 0.74372, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.74372\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.74372\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.74372\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.74372\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.74372\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.74372\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.74372\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.74372\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.74372\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.74372\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.74372\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.74372\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.74372\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.74372\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.74372\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.74372\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.74372\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.74372\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.74372\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.74372\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.74372\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.74372\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.74372\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.74372\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.74372\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.74372\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.74372\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.74372\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.74372\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.74372\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.74372\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.74372\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.74372\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.74372\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.74372\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.74372\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.74372\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.74372\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.74372\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.74372\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.74372\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.74372\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.74372\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.74372\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.74372\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.74372\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.74372\n",
      "SCORE: 0.74372 at epoch 3\n",
      "Compilation Time :  0.002255678176879883\n",
      "Model: \"model_127\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_255 (InputLayer)          [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_381 (LSTM)                 (None, 240, 384)     594432      input_255[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_382 (LSTM)                 (None, 240, 384)     1181184     lstm_381[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_383 (LSTM)                 (None, 384)          1181184     lstm_382[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_256 (InputLayer)          [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1016 (Dense)              (None, 128)          49280       lstm_383[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1019 (Dense)              (None, 128)          384         input_256[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1017 (Dense)              (None, 64)           8256        dense_1016[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1020 (Dense)              (None, 64)           8256        dense_1019[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1018 (Dense)              (None, 32)           2080        dense_1017[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1021 (Dense)              (None, 32)           2080        dense_1020[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_127 (Concatenate)   (None, 64)           0           dense_1018[0][0]                 \n",
      "                                                                 dense_1021[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1022 (Dense)              (None, 8)            520         concatenate_127[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1023 (Dense)              (None, 1)            9           dense_1022[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_127 (Activation)     (None, 1)            0           dense_1023[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 3,027,665\n",
      "Trainable params: 3,027,665\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (32/32) *****\n",
      "Search({'dr1': 0.2, 'dr2': 0.2, 'dr3': 0.2, 'unit': 384, 'lr': 0.001, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.75243, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.75243 to 0.75594, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.75594 to 0.75611, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.75611\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.75611 to 0.79294, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.79294 to 0.79327, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.79327 to 0.79695, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.79695\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.79695\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.79695 to 0.79712, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.79712 to 0.81503, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.81503\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.81503 to 0.82374, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.82374\n",
      "\n",
      "Epoch 00015: val_accuracy improved from 0.82374 to 0.82591, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00016: val_accuracy improved from 0.82591 to 0.82826, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00017: val_accuracy improved from 0.82826 to 0.83144, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.83144\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.83144\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.83144\n",
      "\n",
      "Epoch 00021: val_accuracy improved from 0.83144 to 0.83495, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00022: val_accuracy improved from 0.83495 to 0.83629, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.83629\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.83629\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.83629\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.83629\n",
      "\n",
      "Epoch 00027: val_accuracy improved from 0.83629 to 0.83696, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.83696\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.83696\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.83696\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.83696\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.83696\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.83696\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.83696\n",
      "\n",
      "Epoch 00035: val_accuracy improved from 0.83696 to 0.84550, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.84550\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.84550\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.84550\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.84550\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.84550\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.84550\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.84550\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.84550\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.84550\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.84550\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.84550\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.84550\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.84550\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.84550\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.84550\n",
      "SCORE: 0.8455 at epoch 35\n",
      "\n",
      "##################\n",
      "###  Fold 005  ###\n",
      "##################\n",
      "\n",
      "32 trials detected for ('dr1', 'dr2', 'dr3', 'unit', 'lr', 'epochs', 'batch_size')\n",
      "Compilation Time :  0.002233743667602539\n",
      "Model: \"model_128\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_257 (InputLayer)          [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_384 (LSTM)                 (None, 240, 256)     265216      input_257[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_385 (LSTM)                 (None, 240, 256)     525312      lstm_384[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_386 (LSTM)                 (None, 256)          525312      lstm_385[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_258 (InputLayer)          [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1024 (Dense)              (None, 128)          32896       lstm_386[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1027 (Dense)              (None, 128)          384         input_258[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1025 (Dense)              (None, 64)           8256        dense_1024[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1028 (Dense)              (None, 64)           8256        dense_1027[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1026 (Dense)              (None, 32)           2080        dense_1025[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1029 (Dense)              (None, 32)           2080        dense_1028[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_128 (Concatenate)   (None, 64)           0           dense_1026[0][0]                 \n",
      "                                                                 dense_1029[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1030 (Dense)              (None, 8)            520         concatenate_128[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1031 (Dense)              (None, 1)            9           dense_1030[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_128 (Activation)     (None, 1)            0           dense_1031[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 1,370,321\n",
      "Trainable params: 1,370,321\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (1/32) *****\n",
      "Search({'dr1': 0.1, 'dr2': 0.1, 'dr3': 0.1, 'unit': 256, 'lr': 0.01, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.71861, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.71861 to 0.73586, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.73586\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.73586\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.73586 to 0.75310, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.75310\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.75310\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.75310\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.75310\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.75310\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.75310\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.75310\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.75310\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.75310\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.75310\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.75310\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.75310\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.75310\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.75310\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.75310\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.75310\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.75310\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.75310\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.75310\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.75310\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.75310\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.75310\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.75310\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.75310\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.75310\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.75310\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.75310\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.75310\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.75310\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.75310\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.75310\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.75310\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.75310\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.75310\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.75310\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.75310\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.75310\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.75310\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.75310\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.75310\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.75310\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.75310\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.75310\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.75310\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.75310\n",
      "SCORE: 0.7531 at epoch 5\n",
      "Compilation Time :  0.0022432804107666016\n",
      "Model: \"model_129\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_259 (InputLayer)          [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_387 (LSTM)                 (None, 240, 256)     265216      input_259[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_388 (LSTM)                 (None, 240, 256)     525312      lstm_387[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_389 (LSTM)                 (None, 256)          525312      lstm_388[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_260 (InputLayer)          [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1032 (Dense)              (None, 128)          32896       lstm_389[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1035 (Dense)              (None, 128)          384         input_260[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1033 (Dense)              (None, 64)           8256        dense_1032[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1036 (Dense)              (None, 64)           8256        dense_1035[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1034 (Dense)              (None, 32)           2080        dense_1033[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1037 (Dense)              (None, 32)           2080        dense_1036[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_129 (Concatenate)   (None, 64)           0           dense_1034[0][0]                 \n",
      "                                                                 dense_1037[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1038 (Dense)              (None, 8)            520         concatenate_129[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1039 (Dense)              (None, 1)            9           dense_1038[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_129 (Activation)     (None, 1)            0           dense_1039[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 1,370,321\n",
      "Trainable params: 1,370,321\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (2/32) *****\n",
      "Search({'dr1': 0.1, 'dr2': 0.1, 'dr3': 0.1, 'unit': 256, 'lr': 0.001, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.75946, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.75946 to 0.77402, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.77402 to 0.78490, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.78490 to 0.80415, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.80415\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.80415\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.80415 to 0.82089, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.82089\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.82089 to 0.82524, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.82524\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.82524\n",
      "\n",
      "Epoch 00012: val_accuracy improved from 0.82524 to 0.83160, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.83160 to 0.83947, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00014: val_accuracy improved from 0.83947 to 0.84031, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00015: val_accuracy improved from 0.84031 to 0.84483, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00016: val_accuracy improved from 0.84483 to 0.85303, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.85303\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.85303\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.85303\n",
      "\n",
      "Epoch 00020: val_accuracy improved from 0.85303 to 0.85788, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.85788\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.85788\n",
      "\n",
      "Epoch 00023: val_accuracy improved from 0.85788 to 0.85839, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.85839\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.85839\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.85839\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.85839\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.85839\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.85839\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.85839\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.85839\n",
      "\n",
      "Epoch 00032: val_accuracy improved from 0.85839 to 0.86374, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.86374\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.86374\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.86374\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.86374\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.86374\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.86374\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.86374\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.86374\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.86374\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.86374\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.86374\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.86374\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.86374\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.86374\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.86374\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.86374\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.86374\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.86374\n",
      "SCORE: 0.86374 at epoch 32\n",
      "Compilation Time :  0.0021462440490722656\n",
      "Model: \"model_130\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_261 (InputLayer)          [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_390 (LSTM)                 (None, 240, 384)     594432      input_261[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_391 (LSTM)                 (None, 240, 384)     1181184     lstm_390[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_392 (LSTM)                 (None, 384)          1181184     lstm_391[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_262 (InputLayer)          [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1040 (Dense)              (None, 128)          49280       lstm_392[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1043 (Dense)              (None, 128)          384         input_262[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1041 (Dense)              (None, 64)           8256        dense_1040[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1044 (Dense)              (None, 64)           8256        dense_1043[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1042 (Dense)              (None, 32)           2080        dense_1041[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1045 (Dense)              (None, 32)           2080        dense_1044[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_130 (Concatenate)   (None, 64)           0           dense_1042[0][0]                 \n",
      "                                                                 dense_1045[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1046 (Dense)              (None, 8)            520         concatenate_130[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1047 (Dense)              (None, 1)            9           dense_1046[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_130 (Activation)     (None, 1)            0           dense_1047[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 3,027,665\n",
      "Trainable params: 3,027,665\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (3/32) *****\n",
      "Search({'dr1': 0.1, 'dr2': 0.1, 'dr3': 0.1, 'unit': 384, 'lr': 0.01, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.73552, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.73552\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.73552\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.73552\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.73552 to 0.73636, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.73636\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.73636 to 0.74540, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.74540\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.74540 to 0.74607, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.74607\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.74607\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.74607\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.74607\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.74607\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.74607\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.74607\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.74607\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.74607\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.74607\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.74607\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.74607\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.74607\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.74607\n",
      "\n",
      "Epoch 00024: val_accuracy improved from 0.74607 to 0.76783, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.76783\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.76783\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.76783\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.76783\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.76783\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.76783\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.76783\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.76783\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.76783\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.76783\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.76783\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.76783\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.76783\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.76783\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.76783\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.76783\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.76783\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.76783\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.76783\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.76783\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.76783\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.76783\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.76783\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.76783\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.76783\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.76783\n",
      "SCORE: 0.76783 at epoch 24\n",
      "Compilation Time :  0.0021631717681884766\n",
      "Model: \"model_131\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_263 (InputLayer)          [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_393 (LSTM)                 (None, 240, 384)     594432      input_263[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_394 (LSTM)                 (None, 240, 384)     1181184     lstm_393[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_395 (LSTM)                 (None, 384)          1181184     lstm_394[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_264 (InputLayer)          [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1048 (Dense)              (None, 128)          49280       lstm_395[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1051 (Dense)              (None, 128)          384         input_264[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1049 (Dense)              (None, 64)           8256        dense_1048[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1052 (Dense)              (None, 64)           8256        dense_1051[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1050 (Dense)              (None, 32)           2080        dense_1049[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1053 (Dense)              (None, 32)           2080        dense_1052[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_131 (Concatenate)   (None, 64)           0           dense_1050[0][0]                 \n",
      "                                                                 dense_1053[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1054 (Dense)              (None, 8)            520         concatenate_131[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1055 (Dense)              (None, 1)            9           dense_1054[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_131 (Activation)     (None, 1)            0           dense_1055[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 3,027,665\n",
      "Trainable params: 3,027,665\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (4/32) *****\n",
      "Search({'dr1': 0.1, 'dr2': 0.1, 'dr3': 0.1, 'unit': 384, 'lr': 0.001, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.74623, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.74623 to 0.77954, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.77954\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.77954\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.77954\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.77954 to 0.78942, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.78942 to 0.79980, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.79980\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.79980 to 0.81855, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.81855\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.81855\n",
      "\n",
      "Epoch 00012: val_accuracy improved from 0.81855 to 0.83160, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.83160\n",
      "\n",
      "Epoch 00014: val_accuracy improved from 0.83160 to 0.83796, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00015: val_accuracy improved from 0.83796 to 0.83847, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.83847\n",
      "\n",
      "Epoch 00017: val_accuracy improved from 0.83847 to 0.84516, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.84516\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.84516\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.84516\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.84516\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.84516\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.84516\n",
      "\n",
      "Epoch 00024: val_accuracy improved from 0.84516 to 0.85002, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.85002\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.85002\n",
      "\n",
      "Epoch 00027: val_accuracy improved from 0.85002 to 0.85403, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.85403\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.85403\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.85403\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.85403\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.85403\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.85403\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.85403\n",
      "\n",
      "Epoch 00035: val_accuracy improved from 0.85403 to 0.85688, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.85688\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.85688\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.85688\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.85688\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.85688\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.85688\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.85688\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.85688\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.85688\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.85688\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.85688\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.85688\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.85688\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.85688\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.85688\n",
      "SCORE: 0.85688 at epoch 35\n",
      "Compilation Time :  0.0021767616271972656\n",
      "Model: \"model_132\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_265 (InputLayer)          [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_396 (LSTM)                 (None, 240, 256)     265216      input_265[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_397 (LSTM)                 (None, 240, 256)     525312      lstm_396[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_398 (LSTM)                 (None, 256)          525312      lstm_397[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_266 (InputLayer)          [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1056 (Dense)              (None, 128)          32896       lstm_398[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1059 (Dense)              (None, 128)          384         input_266[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1057 (Dense)              (None, 64)           8256        dense_1056[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1060 (Dense)              (None, 64)           8256        dense_1059[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1058 (Dense)              (None, 32)           2080        dense_1057[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1061 (Dense)              (None, 32)           2080        dense_1060[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_132 (Concatenate)   (None, 64)           0           dense_1058[0][0]                 \n",
      "                                                                 dense_1061[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1062 (Dense)              (None, 8)            520         concatenate_132[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1063 (Dense)              (None, 1)            9           dense_1062[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_132 (Activation)     (None, 1)            0           dense_1063[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 1,370,321\n",
      "Trainable params: 1,370,321\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (5/32) *****\n",
      "Search({'dr1': 0.1, 'dr2': 0.1, 'dr3': 0.2, 'unit': 256, 'lr': 0.01, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.70522, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.70522\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.70522 to 0.72682, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.72682 to 0.73251, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.73251 to 0.77452, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.77452\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.77452\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.77452\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.77452\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.77452\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.77452\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.77452\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.77452\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.77452\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.77452\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.77452\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.77452\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.77452\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.77452\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.77452\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.77452\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.77452\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.77452\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.77452\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.77452\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.77452\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.77452\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.77452\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.77452\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.77452\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.77452\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.77452\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.77452\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.77452\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.77452\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.77452\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.77452\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.77452\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.77452\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.77452\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.77452\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.77452\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.77452\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.77452\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.77452\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.77452\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.77452\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.77452\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.77452\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.77452\n",
      "SCORE: 0.77452 at epoch 5\n",
      "Compilation Time :  0.0021708011627197266\n",
      "Model: \"model_133\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_267 (InputLayer)          [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_399 (LSTM)                 (None, 240, 256)     265216      input_267[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_400 (LSTM)                 (None, 240, 256)     525312      lstm_399[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_401 (LSTM)                 (None, 256)          525312      lstm_400[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_268 (InputLayer)          [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1064 (Dense)              (None, 128)          32896       lstm_401[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1067 (Dense)              (None, 128)          384         input_268[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1065 (Dense)              (None, 64)           8256        dense_1064[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1068 (Dense)              (None, 64)           8256        dense_1067[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1066 (Dense)              (None, 32)           2080        dense_1065[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1069 (Dense)              (None, 32)           2080        dense_1068[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_133 (Concatenate)   (None, 64)           0           dense_1066[0][0]                 \n",
      "                                                                 dense_1069[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1070 (Dense)              (None, 8)            520         concatenate_133[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1071 (Dense)              (None, 1)            9           dense_1070[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_133 (Activation)     (None, 1)            0           dense_1071[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 1,370,321\n",
      "Trainable params: 1,370,321\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (6/32) *****\n",
      "Search({'dr1': 0.1, 'dr2': 0.1, 'dr3': 0.2, 'unit': 256, 'lr': 0.001, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.76297, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.76297 to 0.78758, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.78758\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.78758\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.78758 to 0.80198, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.80198\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.80198 to 0.80666, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.80666 to 0.81386, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.81386 to 0.83144, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.83144\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.83144 to 0.83663, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.83663\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.83663 to 0.84315, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.84315\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.84315\n",
      "\n",
      "Epoch 00016: val_accuracy improved from 0.84315 to 0.84499, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.84499\n",
      "\n",
      "Epoch 00018: val_accuracy improved from 0.84499 to 0.84583, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.84583\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.84583\n",
      "\n",
      "Epoch 00021: val_accuracy improved from 0.84583 to 0.85537, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.85537\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.85537\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.85537\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.85537\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.85537\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.85537\n",
      "\n",
      "Epoch 00028: val_accuracy improved from 0.85537 to 0.86073, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.86073\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.86073\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.86073\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.86073\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.86073\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.86073\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.86073\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.86073\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.86073\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.86073\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.86073\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.86073\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.86073\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.86073\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.86073\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.86073\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.86073\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.86073\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.86073\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.86073\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.86073\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.86073\n",
      "SCORE: 0.86073 at epoch 28\n",
      "Compilation Time :  0.0022475719451904297\n",
      "Model: \"model_134\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_269 (InputLayer)          [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_402 (LSTM)                 (None, 240, 384)     594432      input_269[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_403 (LSTM)                 (None, 240, 384)     1181184     lstm_402[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_404 (LSTM)                 (None, 384)          1181184     lstm_403[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_270 (InputLayer)          [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1072 (Dense)              (None, 128)          49280       lstm_404[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1075 (Dense)              (None, 128)          384         input_270[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1073 (Dense)              (None, 64)           8256        dense_1072[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1076 (Dense)              (None, 64)           8256        dense_1075[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1074 (Dense)              (None, 32)           2080        dense_1073[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1077 (Dense)              (None, 32)           2080        dense_1076[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_134 (Concatenate)   (None, 64)           0           dense_1074[0][0]                 \n",
      "                                                                 dense_1077[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1078 (Dense)              (None, 8)            520         concatenate_134[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1079 (Dense)              (None, 1)            9           dense_1078[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_134 (Activation)     (None, 1)            0           dense_1079[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 3,027,665\n",
      "Trainable params: 3,027,665\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (7/32) *****\n",
      "Search({'dr1': 0.1, 'dr2': 0.1, 'dr3': 0.2, 'unit': 384, 'lr': 0.01, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.62169, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.62169\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.62169\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.62169\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.62169\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.62169 to 0.62755, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.62755\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.62755\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.62755\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.62755\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.62755\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.62755\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.62755\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.62755\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.62755\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.62755\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.62755\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.62755\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.62755\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.62755\n",
      "\n",
      "Epoch 00021: val_accuracy improved from 0.62755 to 0.63157, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.63157\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.63157\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.63157\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.63157\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.63157\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.63157\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.63157\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.63157\n",
      "\n",
      "Epoch 00030: val_accuracy improved from 0.63157 to 0.65367, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.65367\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.65367\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.65367\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.65367\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.65367\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.65367\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.65367\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.65367\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.65367\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.65367\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.65367\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.65367\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.65367\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.65367\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.65367\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.65367\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.65367\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.65367\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.65367\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.65367\n",
      "SCORE: 0.65367 at epoch 30\n",
      "Compilation Time :  0.002187967300415039\n",
      "Model: \"model_135\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_271 (InputLayer)          [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_405 (LSTM)                 (None, 240, 384)     594432      input_271[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_406 (LSTM)                 (None, 240, 384)     1181184     lstm_405[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_407 (LSTM)                 (None, 384)          1181184     lstm_406[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_272 (InputLayer)          [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1080 (Dense)              (None, 128)          49280       lstm_407[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1083 (Dense)              (None, 128)          384         input_272[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1081 (Dense)              (None, 64)           8256        dense_1080[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1084 (Dense)              (None, 64)           8256        dense_1083[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1082 (Dense)              (None, 32)           2080        dense_1081[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1085 (Dense)              (None, 32)           2080        dense_1084[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_135 (Concatenate)   (None, 64)           0           dense_1082[0][0]                 \n",
      "                                                                 dense_1085[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1086 (Dense)              (None, 8)            520         concatenate_135[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1087 (Dense)              (None, 1)            9           dense_1086[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_135 (Activation)     (None, 1)            0           dense_1087[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 3,027,665\n",
      "Trainable params: 3,027,665\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (8/32) *****\n",
      "Search({'dr1': 0.1, 'dr2': 0.1, 'dr3': 0.2, 'unit': 384, 'lr': 0.001, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.77369, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.77369 to 0.77486, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.77486 to 0.78440, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.78440\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.78440 to 0.80683, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.80683\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.80683\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.80683\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.80683 to 0.81470, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.81470\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.81470\n",
      "\n",
      "Epoch 00012: val_accuracy improved from 0.81470 to 0.83144, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.83144 to 0.83462, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00014: val_accuracy improved from 0.83462 to 0.83796, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00015: val_accuracy improved from 0.83796 to 0.84918, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.84918\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.84918\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.84918\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.84918\n",
      "\n",
      "Epoch 00020: val_accuracy improved from 0.84918 to 0.85002, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.85002\n",
      "\n",
      "Epoch 00022: val_accuracy improved from 0.85002 to 0.85939, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.85939\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.85939\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.85939\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.85939\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.85939\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.85939\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.85939\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.85939\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.85939\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.85939\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.85939\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.85939\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.85939\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.85939\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.85939\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.85939\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.85939\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.85939\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.85939\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.85939\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.85939\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.85939\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.85939\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.85939\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.85939\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.85939\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.85939\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.85939\n",
      "SCORE: 0.85939 at epoch 22\n",
      "Compilation Time :  0.0021169185638427734\n",
      "Model: \"model_136\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_273 (InputLayer)          [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_408 (LSTM)                 (None, 240, 256)     265216      input_273[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_409 (LSTM)                 (None, 240, 256)     525312      lstm_408[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_410 (LSTM)                 (None, 256)          525312      lstm_409[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_274 (InputLayer)          [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1088 (Dense)              (None, 128)          32896       lstm_410[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1091 (Dense)              (None, 128)          384         input_274[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1089 (Dense)              (None, 64)           8256        dense_1088[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1092 (Dense)              (None, 64)           8256        dense_1091[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1090 (Dense)              (None, 32)           2080        dense_1089[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1093 (Dense)              (None, 32)           2080        dense_1092[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_136 (Concatenate)   (None, 64)           0           dense_1090[0][0]                 \n",
      "                                                                 dense_1093[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1094 (Dense)              (None, 8)            520         concatenate_136[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1095 (Dense)              (None, 1)            9           dense_1094[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_136 (Activation)     (None, 1)            0           dense_1095[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 1,370,321\n",
      "Trainable params: 1,370,321\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (9/32) *****\n",
      "Search({'dr1': 0.1, 'dr2': 0.2, 'dr3': 0.1, 'unit': 256, 'lr': 0.01, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.74037, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.74037\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.74037\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.74037\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.74037\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.74037\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.74037\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.74037\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.74037\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.74037\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.74037 to 0.76046, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.76046\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.76046\n",
      "\n",
      "Epoch 00014: val_accuracy improved from 0.76046 to 0.76615, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.76615\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.76615\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.76615\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.76615\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.76615\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.76615\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.76615\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.76615\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.76615\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.76615\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.76615\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.76615\n",
      "\n",
      "Epoch 00027: val_accuracy improved from 0.76615 to 0.77017, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.77017\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.77017\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.77017\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.77017\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.77017\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.77017\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.77017\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.77017\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.77017\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.77017\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.77017\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.77017\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.77017\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.77017\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.77017\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.77017\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.77017\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.77017\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.77017\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.77017\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.77017\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.77017\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.77017\n",
      "SCORE: 0.77017 at epoch 27\n",
      "Compilation Time :  0.0021851062774658203\n",
      "Model: \"model_137\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_275 (InputLayer)          [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_411 (LSTM)                 (None, 240, 256)     265216      input_275[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_412 (LSTM)                 (None, 240, 256)     525312      lstm_411[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_413 (LSTM)                 (None, 256)          525312      lstm_412[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_276 (InputLayer)          [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1096 (Dense)              (None, 128)          32896       lstm_413[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1099 (Dense)              (None, 128)          384         input_276[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1097 (Dense)              (None, 64)           8256        dense_1096[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1100 (Dense)              (None, 64)           8256        dense_1099[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1098 (Dense)              (None, 32)           2080        dense_1097[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1101 (Dense)              (None, 32)           2080        dense_1100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_137 (Concatenate)   (None, 64)           0           dense_1098[0][0]                 \n",
      "                                                                 dense_1101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1102 (Dense)              (None, 8)            520         concatenate_137[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1103 (Dense)              (None, 1)            9           dense_1102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_137 (Activation)     (None, 1)            0           dense_1103[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 1,370,321\n",
      "Trainable params: 1,370,321\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (10/32) *****\n",
      "Search({'dr1': 0.1, 'dr2': 0.2, 'dr3': 0.1, 'unit': 256, 'lr': 0.001, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.67744, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.67744 to 0.79059, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.79059\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.79059 to 0.79913, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.79913\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.79913 to 0.80884, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.80884 to 0.81353, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.81353 to 0.82022, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.82022 to 0.82876, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.82876\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.82876\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.82876\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.82876 to 0.83763, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00014: val_accuracy improved from 0.83763 to 0.84985, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.84985\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.84985\n",
      "\n",
      "Epoch 00017: val_accuracy improved from 0.84985 to 0.85470, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.85470\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.85470\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.85470\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.85470\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.85470\n",
      "\n",
      "Epoch 00023: val_accuracy improved from 0.85470 to 0.85705, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.85705\n",
      "\n",
      "Epoch 00025: val_accuracy improved from 0.85705 to 0.86324, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.86324\n",
      "\n",
      "Epoch 00027: val_accuracy improved from 0.86324 to 0.86358, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.86358\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.86358\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.86358\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.86358\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.86358\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.86358\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.86358\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.86358\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.86358\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.86358\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.86358\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.86358\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.86358\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.86358\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.86358\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.86358\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.86358\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.86358\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.86358\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.86358\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.86358\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.86358\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.86358\n",
      "SCORE: 0.86358 at epoch 27\n",
      "Compilation Time :  0.002185344696044922\n",
      "Model: \"model_138\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_277 (InputLayer)          [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_414 (LSTM)                 (None, 240, 384)     594432      input_277[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_415 (LSTM)                 (None, 240, 384)     1181184     lstm_414[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_416 (LSTM)                 (None, 384)          1181184     lstm_415[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_278 (InputLayer)          [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1104 (Dense)              (None, 128)          49280       lstm_416[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1107 (Dense)              (None, 128)          384         input_278[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1105 (Dense)              (None, 64)           8256        dense_1104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1108 (Dense)              (None, 64)           8256        dense_1107[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1106 (Dense)              (None, 32)           2080        dense_1105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1109 (Dense)              (None, 32)           2080        dense_1108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_138 (Concatenate)   (None, 64)           0           dense_1106[0][0]                 \n",
      "                                                                 dense_1109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1110 (Dense)              (None, 8)            520         concatenate_138[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1111 (Dense)              (None, 1)            9           dense_1110[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_138 (Activation)     (None, 1)            0           dense_1111[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 3,027,665\n",
      "Trainable params: 3,027,665\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (11/32) *****\n",
      "Search({'dr1': 0.1, 'dr2': 0.2, 'dr3': 0.1, 'unit': 384, 'lr': 0.01, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.61801, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.61801\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.61801\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.61801 to 0.62169, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.62169\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.62169\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.62169 to 0.64613, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.64613\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.64613\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.64613\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.64613\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.64613\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.64613\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.64613\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.64613\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.64613\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.64613\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.64613\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.64613\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.64613\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.64613\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.64613\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.64613\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.64613\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.64613\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.64613\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.64613\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.64613\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.64613\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.64613\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.64613\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.64613\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.64613\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.64613\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.64613\n",
      "\n",
      "Epoch 00036: val_accuracy improved from 0.64613 to 0.65367, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.65367\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.65367\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.65367\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.65367\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.65367\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.65367\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.65367\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.65367\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.65367\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.65367\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.65367\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.65367\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.65367\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.65367\n",
      "SCORE: 0.65367 at epoch 36\n",
      "Compilation Time :  0.002228260040283203\n",
      "Model: \"model_139\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_279 (InputLayer)          [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_417 (LSTM)                 (None, 240, 384)     594432      input_279[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_418 (LSTM)                 (None, 240, 384)     1181184     lstm_417[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_419 (LSTM)                 (None, 384)          1181184     lstm_418[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_280 (InputLayer)          [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1112 (Dense)              (None, 128)          49280       lstm_419[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1115 (Dense)              (None, 128)          384         input_280[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1113 (Dense)              (None, 64)           8256        dense_1112[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1116 (Dense)              (None, 64)           8256        dense_1115[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1114 (Dense)              (None, 32)           2080        dense_1113[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1117 (Dense)              (None, 32)           2080        dense_1116[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_139 (Concatenate)   (None, 64)           0           dense_1114[0][0]                 \n",
      "                                                                 dense_1117[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1118 (Dense)              (None, 8)            520         concatenate_139[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1119 (Dense)              (None, 1)            9           dense_1118[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_139 (Activation)     (None, 1)            0           dense_1119[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 3,027,665\n",
      "Trainable params: 3,027,665\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (12/32) *****\n",
      "Search({'dr1': 0.1, 'dr2': 0.2, 'dr3': 0.1, 'unit': 384, 'lr': 0.001, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.77519, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.77519\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.77519\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.77519 to 0.79645, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.79645 to 0.81687, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.81687\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.81687 to 0.82809, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.82809\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.82809\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.82809 to 0.83796, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.83796 to 0.84617, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.84617\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.84617\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.84617\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.84617\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.84617\n",
      "\n",
      "Epoch 00017: val_accuracy improved from 0.84617 to 0.85152, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00018: val_accuracy improved from 0.85152 to 0.85470, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.85470\n",
      "\n",
      "Epoch 00020: val_accuracy improved from 0.85470 to 0.85638, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.85638\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.85638\n",
      "\n",
      "Epoch 00023: val_accuracy improved from 0.85638 to 0.85705, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.85705\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.85705\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.85705\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.85705\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.85705\n",
      "\n",
      "Epoch 00029: val_accuracy improved from 0.85705 to 0.85772, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.85772\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.85772\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.85772\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.85772\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.85772\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.85772\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.85772\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.85772\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.85772\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.85772\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.85772\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.85772\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.85772\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.85772\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.85772\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.85772\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.85772\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.85772\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.85772\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.85772\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.85772\n",
      "SCORE: 0.85772 at epoch 29\n",
      "Compilation Time :  0.0021657943725585938\n",
      "Model: \"model_140\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_281 (InputLayer)          [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_420 (LSTM)                 (None, 240, 256)     265216      input_281[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_421 (LSTM)                 (None, 240, 256)     525312      lstm_420[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_422 (LSTM)                 (None, 256)          525312      lstm_421[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_282 (InputLayer)          [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1120 (Dense)              (None, 128)          32896       lstm_422[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1123 (Dense)              (None, 128)          384         input_282[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1121 (Dense)              (None, 64)           8256        dense_1120[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1124 (Dense)              (None, 64)           8256        dense_1123[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1122 (Dense)              (None, 32)           2080        dense_1121[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1125 (Dense)              (None, 32)           2080        dense_1124[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_140 (Concatenate)   (None, 64)           0           dense_1122[0][0]                 \n",
      "                                                                 dense_1125[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1126 (Dense)              (None, 8)            520         concatenate_140[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1127 (Dense)              (None, 1)            9           dense_1126[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_140 (Activation)     (None, 1)            0           dense_1127[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 1,370,321\n",
      "Trainable params: 1,370,321\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (13/32) *****\n",
      "Search({'dr1': 0.1, 'dr2': 0.2, 'dr3': 0.2, 'unit': 256, 'lr': 0.01, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.70321, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.70321 to 0.72297, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.72297 to 0.74138, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.74138 to 0.74305, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.74305\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.74305\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.74305\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.74305\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.74305 to 0.76297, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.76297 to 0.76699, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.76699\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.76699\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.76699\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.76699\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.76699\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.76699\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.76699\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.76699\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.76699\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.76699\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.76699\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.76699\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.76699\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.76699\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.76699\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.76699\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.76699\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.76699\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.76699\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.76699\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.76699\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.76699\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.76699\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.76699\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.76699\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.76699\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.76699\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.76699\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.76699\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.76699\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.76699\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.76699\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.76699\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.76699\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.76699\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.76699\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.76699\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.76699\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.76699\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.76699\n",
      "SCORE: 0.76699 at epoch 10\n",
      "Compilation Time :  0.002225637435913086\n",
      "Model: \"model_141\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_283 (InputLayer)          [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_423 (LSTM)                 (None, 240, 256)     265216      input_283[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_424 (LSTM)                 (None, 240, 256)     525312      lstm_423[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_425 (LSTM)                 (None, 256)          525312      lstm_424[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_284 (InputLayer)          [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1128 (Dense)              (None, 128)          32896       lstm_425[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1131 (Dense)              (None, 128)          384         input_284[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1129 (Dense)              (None, 64)           8256        dense_1128[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1132 (Dense)              (None, 64)           8256        dense_1131[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1130 (Dense)              (None, 32)           2080        dense_1129[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1133 (Dense)              (None, 32)           2080        dense_1132[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_141 (Concatenate)   (None, 64)           0           dense_1130[0][0]                 \n",
      "                                                                 dense_1133[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1134 (Dense)              (None, 8)            520         concatenate_141[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1135 (Dense)              (None, 1)            9           dense_1134[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_141 (Activation)     (None, 1)            0           dense_1135[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 1,370,321\n",
      "Trainable params: 1,370,321\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (14/32) *****\n",
      "Search({'dr1': 0.1, 'dr2': 0.2, 'dr3': 0.2, 'unit': 256, 'lr': 0.001, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.78708, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.78708 to 0.79813, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.79813\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.79813\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.79813\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.79813 to 0.81721, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.81721\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.81721 to 0.82374, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.82374 to 0.82842, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.82842\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.82842 to 0.83830, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.83830\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.83830\n",
      "\n",
      "Epoch 00014: val_accuracy improved from 0.83830 to 0.84165, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00015: val_accuracy improved from 0.84165 to 0.85203, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.85203\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.85203\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.85203\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.85203\n",
      "\n",
      "Epoch 00020: val_accuracy improved from 0.85203 to 0.85387, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.85387\n",
      "\n",
      "Epoch 00022: val_accuracy improved from 0.85387 to 0.85437, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00023: val_accuracy improved from 0.85437 to 0.85588, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.85588\n",
      "\n",
      "Epoch 00025: val_accuracy improved from 0.85588 to 0.85755, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00026: val_accuracy improved from 0.85755 to 0.85772, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.85772\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.85772\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.85772\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.85772\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.85772\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.85772\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.85772\n",
      "\n",
      "Epoch 00034: val_accuracy improved from 0.85772 to 0.85855, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.85855\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.85855\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.85855\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.85855\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.85855\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.85855\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.85855\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.85855\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.85855\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.85855\n",
      "\n",
      "Epoch 00045: val_accuracy improved from 0.85855 to 0.85922, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.85922\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.85922\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.85922\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.85922\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.85922\n",
      "SCORE: 0.85922 at epoch 45\n",
      "Compilation Time :  0.0021800994873046875\n",
      "Model: \"model_142\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_285 (InputLayer)          [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_426 (LSTM)                 (None, 240, 384)     594432      input_285[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_427 (LSTM)                 (None, 240, 384)     1181184     lstm_426[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_428 (LSTM)                 (None, 384)          1181184     lstm_427[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_286 (InputLayer)          [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1136 (Dense)              (None, 128)          49280       lstm_428[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1139 (Dense)              (None, 128)          384         input_286[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1137 (Dense)              (None, 64)           8256        dense_1136[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1140 (Dense)              (None, 64)           8256        dense_1139[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1138 (Dense)              (None, 32)           2080        dense_1137[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1141 (Dense)              (None, 32)           2080        dense_1140[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_142 (Concatenate)   (None, 64)           0           dense_1138[0][0]                 \n",
      "                                                                 dense_1141[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1142 (Dense)              (None, 8)            520         concatenate_142[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1143 (Dense)              (None, 1)            9           dense_1142[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_142 (Activation)     (None, 1)            0           dense_1143[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 3,027,665\n",
      "Trainable params: 3,027,665\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (15/32) *****\n",
      "Search({'dr1': 0.1, 'dr2': 0.2, 'dr3': 0.2, 'unit': 384, 'lr': 0.01, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.62287, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.62287 to 0.71861, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.71861\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.71861\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.71861\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.71861\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.71861 to 0.75444, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.75444 to 0.75611, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.75611\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.75611\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.75611\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.75611\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.75611\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.75611\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.75611\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.75611\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.75611\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.75611\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.75611\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.75611\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.75611\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.75611\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.75611\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.75611\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.75611\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.75611\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.75611\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.75611\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.75611\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.75611\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.75611\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.75611\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.75611\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.75611\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.75611\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.75611\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.75611\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.75611\n",
      "\n",
      "Epoch 00039: val_accuracy improved from 0.75611 to 0.76833, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.76833\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.76833\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.76833\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.76833\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.76833\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.76833\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.76833\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.76833\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.76833\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.76833\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.76833\n",
      "SCORE: 0.76833 at epoch 39\n",
      "Compilation Time :  0.0023984909057617188\n",
      "Model: \"model_143\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_287 (InputLayer)          [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_429 (LSTM)                 (None, 240, 384)     594432      input_287[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_430 (LSTM)                 (None, 240, 384)     1181184     lstm_429[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_431 (LSTM)                 (None, 384)          1181184     lstm_430[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_288 (InputLayer)          [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1144 (Dense)              (None, 128)          49280       lstm_431[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1147 (Dense)              (None, 128)          384         input_288[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1145 (Dense)              (None, 64)           8256        dense_1144[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1148 (Dense)              (None, 64)           8256        dense_1147[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1146 (Dense)              (None, 32)           2080        dense_1145[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1149 (Dense)              (None, 32)           2080        dense_1148[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_143 (Concatenate)   (None, 64)           0           dense_1146[0][0]                 \n",
      "                                                                 dense_1149[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1150 (Dense)              (None, 8)            520         concatenate_143[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1151 (Dense)              (None, 1)            9           dense_1150[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_143 (Activation)     (None, 1)            0           dense_1151[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 3,027,665\n",
      "Trainable params: 3,027,665\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (16/32) *****\n",
      "Search({'dr1': 0.1, 'dr2': 0.2, 'dr3': 0.2, 'unit': 384, 'lr': 0.001, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.78239, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.78239\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.78239\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.78239 to 0.79310, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.79310\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.79310\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.79310\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.79310 to 0.80767, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.80767\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.80767 to 0.82474, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.82474 to 0.83010, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00012: val_accuracy improved from 0.83010 to 0.83562, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.83562 to 0.83612, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.83612\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.83612\n",
      "\n",
      "Epoch 00016: val_accuracy improved from 0.83612 to 0.84014, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.84014\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.84014\n",
      "\n",
      "Epoch 00019: val_accuracy improved from 0.84014 to 0.84550, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00020: val_accuracy improved from 0.84550 to 0.85069, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.85069\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.85069\n",
      "\n",
      "Epoch 00023: val_accuracy improved from 0.85069 to 0.85437, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.85437\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.85437\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.85437\n",
      "\n",
      "Epoch 00027: val_accuracy improved from 0.85437 to 0.86056, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.86056\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.86056\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.86056\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.86056\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.86056\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.86056\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.86056\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.86056\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.86056\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.86056\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.86056\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.86056\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.86056\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.86056\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.86056\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.86056\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.86056\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.86056\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.86056\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.86056\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.86056\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.86056\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.86056\n",
      "SCORE: 0.86056 at epoch 27\n",
      "Compilation Time :  0.0021791458129882812\n",
      "Model: \"model_144\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_289 (InputLayer)          [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_432 (LSTM)                 (None, 240, 256)     265216      input_289[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_433 (LSTM)                 (None, 240, 256)     525312      lstm_432[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_434 (LSTM)                 (None, 256)          525312      lstm_433[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_290 (InputLayer)          [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1152 (Dense)              (None, 128)          32896       lstm_434[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1155 (Dense)              (None, 128)          384         input_290[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1153 (Dense)              (None, 64)           8256        dense_1152[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1156 (Dense)              (None, 64)           8256        dense_1155[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1154 (Dense)              (None, 32)           2080        dense_1153[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1157 (Dense)              (None, 32)           2080        dense_1156[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_144 (Concatenate)   (None, 64)           0           dense_1154[0][0]                 \n",
      "                                                                 dense_1157[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1158 (Dense)              (None, 8)            520         concatenate_144[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1159 (Dense)              (None, 1)            9           dense_1158[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_144 (Activation)     (None, 1)            0           dense_1159[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 1,370,321\n",
      "Trainable params: 1,370,321\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (17/32) *****\n",
      "Search({'dr1': 0.2, 'dr2': 0.1, 'dr3': 0.1, 'unit': 256, 'lr': 0.01, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.60981, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.60981 to 0.73334, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.73334 to 0.73485, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.73485\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.73485\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.73485 to 0.75979, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.75979\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.75979\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.75979\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.75979\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.75979\n",
      "\n",
      "Epoch 00012: val_accuracy improved from 0.75979 to 0.76113, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.76113\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.76113\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.76113\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.76113\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.76113\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.76113\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.76113\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.76113\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.76113\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.76113\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.76113\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.76113\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.76113\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.76113\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.76113\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.76113\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.76113\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.76113\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.76113\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.76113\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.76113\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.76113\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.76113\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.76113\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.76113\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.76113\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.76113\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.76113\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.76113\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.76113\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.76113\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.76113\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.76113\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.76113\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.76113\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.76113\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.76113\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.76113\n",
      "SCORE: 0.76113 at epoch 12\n",
      "Compilation Time :  0.0022568702697753906\n",
      "Model: \"model_145\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_291 (InputLayer)          [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_435 (LSTM)                 (None, 240, 256)     265216      input_291[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_436 (LSTM)                 (None, 240, 256)     525312      lstm_435[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_437 (LSTM)                 (None, 256)          525312      lstm_436[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_292 (InputLayer)          [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1160 (Dense)              (None, 128)          32896       lstm_437[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1163 (Dense)              (None, 128)          384         input_292[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1161 (Dense)              (None, 64)           8256        dense_1160[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1164 (Dense)              (None, 64)           8256        dense_1163[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1162 (Dense)              (None, 32)           2080        dense_1161[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1165 (Dense)              (None, 32)           2080        dense_1164[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_145 (Concatenate)   (None, 64)           0           dense_1162[0][0]                 \n",
      "                                                                 dense_1165[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1166 (Dense)              (None, 8)            520         concatenate_145[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1167 (Dense)              (None, 1)            9           dense_1166[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_145 (Activation)     (None, 1)            0           dense_1167[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 1,370,321\n",
      "Trainable params: 1,370,321\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (18/32) *****\n",
      "Search({'dr1': 0.2, 'dr2': 0.1, 'dr3': 0.1, 'unit': 256, 'lr': 0.001, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.71209, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.71209 to 0.74523, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.74523 to 0.77653, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.77653\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.77653\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.77653\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.77653\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.77653 to 0.79997, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.79997 to 0.80934, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.80934 to 0.81252, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.81252\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.81252\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.81252\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.81252\n",
      "\n",
      "Epoch 00015: val_accuracy improved from 0.81252 to 0.82809, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.82809\n",
      "\n",
      "Epoch 00017: val_accuracy improved from 0.82809 to 0.83495, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.83495\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.83495\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.83495\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.83495\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.83495\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.83495\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.83495\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.83495\n",
      "\n",
      "Epoch 00026: val_accuracy improved from 0.83495 to 0.84215, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.84215\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.84215\n",
      "\n",
      "Epoch 00029: val_accuracy improved from 0.84215 to 0.84600, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.84600\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.84600\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.84600\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.84600\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.84600\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.84600\n",
      "\n",
      "Epoch 00036: val_accuracy improved from 0.84600 to 0.85018, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.85018\n",
      "\n",
      "Epoch 00038: val_accuracy improved from 0.85018 to 0.85370, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.85370\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.85370\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.85370\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.85370\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.85370\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.85370\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.85370\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.85370\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.85370\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.85370\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.85370\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.85370\n",
      "SCORE: 0.8537 at epoch 38\n",
      "Compilation Time :  0.0021767616271972656\n",
      "Model: \"model_146\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_293 (InputLayer)          [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_438 (LSTM)                 (None, 240, 384)     594432      input_293[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_439 (LSTM)                 (None, 240, 384)     1181184     lstm_438[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_440 (LSTM)                 (None, 384)          1181184     lstm_439[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_294 (InputLayer)          [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1168 (Dense)              (None, 128)          49280       lstm_440[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1171 (Dense)              (None, 128)          384         input_294[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1169 (Dense)              (None, 64)           8256        dense_1168[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1172 (Dense)              (None, 64)           8256        dense_1171[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1170 (Dense)              (None, 32)           2080        dense_1169[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1173 (Dense)              (None, 32)           2080        dense_1172[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_146 (Concatenate)   (None, 64)           0           dense_1170[0][0]                 \n",
      "                                                                 dense_1173[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1174 (Dense)              (None, 8)            520         concatenate_146[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1175 (Dense)              (None, 1)            9           dense_1174[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_146 (Activation)     (None, 1)            0           dense_1175[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 3,027,665\n",
      "Trainable params: 3,027,665\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (19/32) *****\n",
      "Search({'dr1': 0.2, 'dr2': 0.1, 'dr3': 0.1, 'unit': 384, 'lr': 0.01, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.76431, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.76431\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.76431\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.76431\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.76431\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.76431\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.76431\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.76431\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.76431\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.76431\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.76431\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.76431\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.76431\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.76431\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.76431\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.76431\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.76431\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.76431\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.76431\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.76431\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.76431\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.76431\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.76431\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.76431\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.76431\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.76431\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.76431\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.76431\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.76431\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.76431\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.76431\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.76431\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.76431\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.76431\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.76431\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.76431\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.76431\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.76431\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.76431\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.76431\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.76431\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.76431\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.76431\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.76431\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.76431\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.76431\n",
      "SCORE: 0.76431 at epoch 1\n",
      "Compilation Time :  0.002224445343017578\n",
      "Model: \"model_147\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_295 (InputLayer)          [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_441 (LSTM)                 (None, 240, 384)     594432      input_295[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_442 (LSTM)                 (None, 240, 384)     1181184     lstm_441[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_443 (LSTM)                 (None, 384)          1181184     lstm_442[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_296 (InputLayer)          [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1176 (Dense)              (None, 128)          49280       lstm_443[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1179 (Dense)              (None, 128)          384         input_296[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1177 (Dense)              (None, 64)           8256        dense_1176[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1180 (Dense)              (None, 64)           8256        dense_1179[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1178 (Dense)              (None, 32)           2080        dense_1177[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1181 (Dense)              (None, 32)           2080        dense_1180[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_147 (Concatenate)   (None, 64)           0           dense_1178[0][0]                 \n",
      "                                                                 dense_1181[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1182 (Dense)              (None, 8)            520         concatenate_147[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1183 (Dense)              (None, 1)            9           dense_1182[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_147 (Activation)     (None, 1)            0           dense_1183[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 3,027,665\n",
      "Trainable params: 3,027,665\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (20/32) *****\n",
      "Search({'dr1': 0.2, 'dr2': 0.1, 'dr3': 0.1, 'unit': 384, 'lr': 0.001, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.70874, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.70874 to 0.71292, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.71292\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.71292\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.71292 to 0.77118, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.77118\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.77118\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.77118 to 0.78256, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.78256 to 0.80716, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.80716\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.80716\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.80716\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.80716 to 0.83478, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.83478\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.83478\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.83478\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.83478\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.83478\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.83478\n",
      "\n",
      "Epoch 00020: val_accuracy improved from 0.83478 to 0.83629, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00021: val_accuracy improved from 0.83629 to 0.84851, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.84851\n",
      "\n",
      "Epoch 00023: val_accuracy improved from 0.84851 to 0.85035, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.85035\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.85035\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.85035\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.85035\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.85035\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.85035\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.85035\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.85035\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.85035\n",
      "\n",
      "Epoch 00033: val_accuracy improved from 0.85035 to 0.85504, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.85504\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.85504\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.85504\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.85504\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.85504\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.85504\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.85504\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.85504\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.85504\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.85504\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.85504\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.85504\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.85504\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.85504\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.85504\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.85504\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.85504\n",
      "SCORE: 0.85504 at epoch 33\n",
      "Compilation Time :  0.002193450927734375\n",
      "Model: \"model_148\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_297 (InputLayer)          [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_444 (LSTM)                 (None, 240, 256)     265216      input_297[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_445 (LSTM)                 (None, 240, 256)     525312      lstm_444[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_446 (LSTM)                 (None, 256)          525312      lstm_445[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_298 (InputLayer)          [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1184 (Dense)              (None, 128)          32896       lstm_446[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1187 (Dense)              (None, 128)          384         input_298[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1185 (Dense)              (None, 64)           8256        dense_1184[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1188 (Dense)              (None, 64)           8256        dense_1187[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1186 (Dense)              (None, 32)           2080        dense_1185[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1189 (Dense)              (None, 32)           2080        dense_1188[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_148 (Concatenate)   (None, 64)           0           dense_1186[0][0]                 \n",
      "                                                                 dense_1189[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1190 (Dense)              (None, 8)            520         concatenate_148[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1191 (Dense)              (None, 1)            9           dense_1190[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_148 (Activation)     (None, 1)            0           dense_1191[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 1,370,321\n",
      "Trainable params: 1,370,321\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (21/32) *****\n",
      "Search({'dr1': 0.2, 'dr2': 0.1, 'dr3': 0.2, 'unit': 256, 'lr': 0.01, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.73351, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.73351 to 0.75059, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.75059\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.75059\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.75059\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.75059\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.75059\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.75059\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.75059\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.75059\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.75059\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.75059\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.75059\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.75059\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.75059\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.75059\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.75059\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.75059\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.75059\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.75059\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.75059\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.75059\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.75059\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.75059\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.75059\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.75059\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.75059\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.75059\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.75059\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.75059\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.75059\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.75059\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.75059\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.75059\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.75059\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.75059\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.75059\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.75059\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.75059\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.75059\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.75059\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.75059\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.75059\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.75059\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.75059\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.75059\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.75059\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.75059\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.75059\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.75059\n",
      "SCORE: 0.75059 at epoch 2\n",
      "Compilation Time :  0.0078089237213134766\n",
      "Model: \"model_149\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_299 (InputLayer)          [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_447 (LSTM)                 (None, 240, 256)     265216      input_299[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_448 (LSTM)                 (None, 240, 256)     525312      lstm_447[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_449 (LSTM)                 (None, 256)          525312      lstm_448[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_300 (InputLayer)          [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1192 (Dense)              (None, 128)          32896       lstm_449[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1195 (Dense)              (None, 128)          384         input_300[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1193 (Dense)              (None, 64)           8256        dense_1192[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1196 (Dense)              (None, 64)           8256        dense_1195[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1194 (Dense)              (None, 32)           2080        dense_1193[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1197 (Dense)              (None, 32)           2080        dense_1196[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_149 (Concatenate)   (None, 64)           0           dense_1194[0][0]                 \n",
      "                                                                 dense_1197[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1198 (Dense)              (None, 8)            520         concatenate_149[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1199 (Dense)              (None, 1)            9           dense_1198[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_149 (Activation)     (None, 1)            0           dense_1199[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 1,370,321\n",
      "Trainable params: 1,370,321\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (22/32) *****\n",
      "Search({'dr1': 0.2, 'dr2': 0.1, 'dr3': 0.2, 'unit': 256, 'lr': 0.001, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.73719, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.73719 to 0.74707, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.74707 to 0.74908, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.74908\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.74908\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.74908\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.74908\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.74908 to 0.79779, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.79779\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.79779\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.79779\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.79779\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.79779\n",
      "\n",
      "Epoch 00014: val_accuracy improved from 0.79779 to 0.82675, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.82675\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.82675\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.82675\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.82675\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.82675\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.82675\n",
      "\n",
      "Epoch 00021: val_accuracy improved from 0.82675 to 0.82692, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.82692\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.82692\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.82692\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.82692\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.82692\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.82692\n",
      "\n",
      "Epoch 00028: val_accuracy improved from 0.82692 to 0.84114, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.84114\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.84114\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.84114\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.84114\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.84114\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.84114\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.84114\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.84114\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.84114\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.84114\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.84114\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.84114\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.84114\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.84114\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.84114\n",
      "\n",
      "Epoch 00044: val_accuracy improved from 0.84114 to 0.85136, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.85136\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.85136\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.85136\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.85136\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.85136\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.85136\n",
      "SCORE: 0.85136 at epoch 44\n",
      "Compilation Time :  0.002160787582397461\n",
      "Model: \"model_150\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_301 (InputLayer)          [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_450 (LSTM)                 (None, 240, 384)     594432      input_301[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_451 (LSTM)                 (None, 240, 384)     1181184     lstm_450[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_452 (LSTM)                 (None, 384)          1181184     lstm_451[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_302 (InputLayer)          [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1200 (Dense)              (None, 128)          49280       lstm_452[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1203 (Dense)              (None, 128)          384         input_302[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1201 (Dense)              (None, 64)           8256        dense_1200[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1204 (Dense)              (None, 64)           8256        dense_1203[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1202 (Dense)              (None, 32)           2080        dense_1201[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1205 (Dense)              (None, 32)           2080        dense_1204[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_150 (Concatenate)   (None, 64)           0           dense_1202[0][0]                 \n",
      "                                                                 dense_1205[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1206 (Dense)              (None, 8)            520         concatenate_150[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1207 (Dense)              (None, 1)            9           dense_1206[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_150 (Activation)     (None, 1)            0           dense_1207[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 3,027,665\n",
      "Trainable params: 3,027,665\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (23/32) *****\n",
      "Search({'dr1': 0.2, 'dr2': 0.1, 'dr3': 0.2, 'unit': 384, 'lr': 0.01, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.70941, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.70941 to 0.71527, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.71527 to 0.72581, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.72581\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.72581\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.72581\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.72581\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.72581\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.72581 to 0.73770, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.73770\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.73770 to 0.73803, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00012: val_accuracy improved from 0.73803 to 0.74205, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.74205\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.74205\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.74205\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.74205\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.74205\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.74205\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.74205\n",
      "\n",
      "Epoch 00020: val_accuracy improved from 0.74205 to 0.76883, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.76883\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.76883\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.76883\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.76883\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.76883\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.76883\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.76883\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.76883\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.76883\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.76883\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.76883\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.76883\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.76883\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.76883\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.76883\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.76883\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.76883\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.76883\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.76883\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.76883\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.76883\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.76883\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.76883\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.76883\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.76883\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.76883\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.76883\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.76883\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.76883\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.76883\n",
      "SCORE: 0.76883 at epoch 20\n",
      "Compilation Time :  0.002171039581298828\n",
      "Model: \"model_151\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_303 (InputLayer)          [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_453 (LSTM)                 (None, 240, 384)     594432      input_303[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_454 (LSTM)                 (None, 240, 384)     1181184     lstm_453[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_455 (LSTM)                 (None, 384)          1181184     lstm_454[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_304 (InputLayer)          [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1208 (Dense)              (None, 128)          49280       lstm_455[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1211 (Dense)              (None, 128)          384         input_304[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1209 (Dense)              (None, 64)           8256        dense_1208[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1212 (Dense)              (None, 64)           8256        dense_1211[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1210 (Dense)              (None, 32)           2080        dense_1209[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1213 (Dense)              (None, 32)           2080        dense_1212[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_151 (Concatenate)   (None, 64)           0           dense_1210[0][0]                 \n",
      "                                                                 dense_1213[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1214 (Dense)              (None, 8)            520         concatenate_151[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1215 (Dense)              (None, 1)            9           dense_1214[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_151 (Activation)     (None, 1)            0           dense_1215[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 3,027,665\n",
      "Trainable params: 3,027,665\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (24/32) *****\n",
      "Search({'dr1': 0.2, 'dr2': 0.1, 'dr3': 0.2, 'unit': 384, 'lr': 0.001, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.72313, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.72313\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.72313 to 0.76900, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.76900\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.76900\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.76900\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.76900\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.76900\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.76900 to 0.77586, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.77586 to 0.79997, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.79997\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.79997\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.79997\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.79997\n",
      "\n",
      "Epoch 00015: val_accuracy improved from 0.79997 to 0.81570, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.81570\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.81570\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.81570\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.81570\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.81570\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.81570\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.81570\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.81570\n",
      "\n",
      "Epoch 00024: val_accuracy improved from 0.81570 to 0.82357, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00025: val_accuracy improved from 0.82357 to 0.82424, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.82424\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.82424\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.82424\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.82424\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.82424\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.82424\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.82424\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.82424\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.82424\n",
      "\n",
      "Epoch 00035: val_accuracy improved from 0.82424 to 0.83612, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.83612\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.83612\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.83612\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.83612\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.83612\n",
      "\n",
      "Epoch 00041: val_accuracy improved from 0.83612 to 0.83847, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.83847\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.83847\n",
      "\n",
      "Epoch 00044: val_accuracy improved from 0.83847 to 0.85018, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.85018\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.85018\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.85018\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.85018\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.85018\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.85018\n",
      "SCORE: 0.85018 at epoch 44\n",
      "Compilation Time :  0.002272367477416992\n",
      "Model: \"model_152\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_305 (InputLayer)          [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_456 (LSTM)                 (None, 240, 256)     265216      input_305[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_457 (LSTM)                 (None, 240, 256)     525312      lstm_456[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_458 (LSTM)                 (None, 256)          525312      lstm_457[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_306 (InputLayer)          [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1216 (Dense)              (None, 128)          32896       lstm_458[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1219 (Dense)              (None, 128)          384         input_306[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1217 (Dense)              (None, 64)           8256        dense_1216[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1220 (Dense)              (None, 64)           8256        dense_1219[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1218 (Dense)              (None, 32)           2080        dense_1217[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1221 (Dense)              (None, 32)           2080        dense_1220[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_152 (Concatenate)   (None, 64)           0           dense_1218[0][0]                 \n",
      "                                                                 dense_1221[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1222 (Dense)              (None, 8)            520         concatenate_152[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1223 (Dense)              (None, 1)            9           dense_1222[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_152 (Activation)     (None, 1)            0           dense_1223[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 1,370,321\n",
      "Trainable params: 1,370,321\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (25/32) *****\n",
      "Search({'dr1': 0.2, 'dr2': 0.2, 'dr3': 0.1, 'unit': 256, 'lr': 0.01, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.72129, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.72129 to 0.74607, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.74607\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.74607 to 0.75109, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.75109\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.75109\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.75109\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.75109\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.75109\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.75109\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.75109 to 0.75360, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.75360\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.75360\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.75360\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.75360\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.75360\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.75360\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.75360\n",
      "\n",
      "Epoch 00019: val_accuracy improved from 0.75360 to 0.75544, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00020: val_accuracy improved from 0.75544 to 0.76582, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.76582\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.76582\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.76582\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.76582\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.76582\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.76582\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.76582\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.76582\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.76582\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.76582\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.76582\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.76582\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.76582\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.76582\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.76582\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.76582\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.76582\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.76582\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.76582\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.76582\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.76582\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.76582\n",
      "\n",
      "Epoch 00043: val_accuracy improved from 0.76582 to 0.76766, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.76766\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.76766\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.76766\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.76766\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.76766\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.76766\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.76766\n",
      "SCORE: 0.76766 at epoch 43\n",
      "Compilation Time :  0.002246856689453125\n",
      "Model: \"model_153\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_307 (InputLayer)          [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_459 (LSTM)                 (None, 240, 256)     265216      input_307[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_460 (LSTM)                 (None, 240, 256)     525312      lstm_459[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_461 (LSTM)                 (None, 256)          525312      lstm_460[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_308 (InputLayer)          [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1224 (Dense)              (None, 128)          32896       lstm_461[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1227 (Dense)              (None, 128)          384         input_308[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1225 (Dense)              (None, 64)           8256        dense_1224[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1228 (Dense)              (None, 64)           8256        dense_1227[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1226 (Dense)              (None, 32)           2080        dense_1225[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1229 (Dense)              (None, 32)           2080        dense_1228[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_153 (Concatenate)   (None, 64)           0           dense_1226[0][0]                 \n",
      "                                                                 dense_1229[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1230 (Dense)              (None, 8)            520         concatenate_153[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1231 (Dense)              (None, 1)            9           dense_1230[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_153 (Activation)     (None, 1)            0           dense_1231[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 1,370,321\n",
      "Trainable params: 1,370,321\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (26/32) *****\n",
      "Search({'dr1': 0.2, 'dr2': 0.2, 'dr3': 0.1, 'unit': 256, 'lr': 0.001, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.76431, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.76431\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.76431 to 0.77051, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.77051\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.77051 to 0.78122, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.78122 to 0.81888, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.81888\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.81888\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.81888\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.81888\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.81888 to 0.82558, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.82558\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.82558 to 0.82742, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.82742\n",
      "\n",
      "Epoch 00015: val_accuracy improved from 0.82742 to 0.82959, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00016: val_accuracy improved from 0.82959 to 0.84717, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.84717\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.84717\n",
      "\n",
      "Epoch 00019: val_accuracy improved from 0.84717 to 0.84985, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00020: val_accuracy improved from 0.84985 to 0.85303, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.85303\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.85303\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.85303\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.85303\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.85303\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.85303\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.85303\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.85303\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.85303\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.85303\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.85303\n",
      "\n",
      "Epoch 00032: val_accuracy improved from 0.85303 to 0.85604, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.85604\n",
      "\n",
      "Epoch 00034: val_accuracy improved from 0.85604 to 0.85755, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.85755\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.85755\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.85755\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.85755\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.85755\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.85755\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.85755\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.85755\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.85755\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.85755\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.85755\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.85755\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.85755\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.85755\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.85755\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.85755\n",
      "SCORE: 0.85755 at epoch 34\n",
      "Compilation Time :  0.0021736621856689453\n",
      "Model: \"model_154\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_309 (InputLayer)          [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_462 (LSTM)                 (None, 240, 384)     594432      input_309[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_463 (LSTM)                 (None, 240, 384)     1181184     lstm_462[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_464 (LSTM)                 (None, 384)          1181184     lstm_463[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_310 (InputLayer)          [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1232 (Dense)              (None, 128)          49280       lstm_464[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1235 (Dense)              (None, 128)          384         input_310[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1233 (Dense)              (None, 64)           8256        dense_1232[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1236 (Dense)              (None, 64)           8256        dense_1235[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1234 (Dense)              (None, 32)           2080        dense_1233[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1237 (Dense)              (None, 32)           2080        dense_1236[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_154 (Concatenate)   (None, 64)           0           dense_1234[0][0]                 \n",
      "                                                                 dense_1237[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1238 (Dense)              (None, 8)            520         concatenate_154[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1239 (Dense)              (None, 1)            9           dense_1238[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_154 (Activation)     (None, 1)            0           dense_1239[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 3,027,665\n",
      "Trainable params: 3,027,665\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (27/32) *****\n",
      "Search({'dr1': 0.2, 'dr2': 0.2, 'dr3': 0.1, 'unit': 384, 'lr': 0.01, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.72916, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.72916\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.72916\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.72916 to 0.73786, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.73786\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.73786\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.73786\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.73786 to 0.74205, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.74205\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.74205\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.74205\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.74205\n",
      "\n",
      "Epoch 00013: val_accuracy improved from 0.74205 to 0.75142, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00014: val_accuracy improved from 0.75142 to 0.75745, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.75745\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.75745\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.75745\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.75745\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.75745\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.75745\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.75745\n",
      "\n",
      "Epoch 00022: val_accuracy improved from 0.75745 to 0.76682, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.76682\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.76682\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.76682\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.76682\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.76682\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.76682\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.76682\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.76682\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.76682\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.76682\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.76682\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.76682\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.76682\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.76682\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.76682\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.76682\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.76682\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.76682\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.76682\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.76682\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.76682\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.76682\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.76682\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.76682\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.76682\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.76682\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.76682\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.76682\n",
      "SCORE: 0.76682 at epoch 22\n",
      "Compilation Time :  0.0022344589233398438\n",
      "Model: \"model_155\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_311 (InputLayer)          [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_465 (LSTM)                 (None, 240, 384)     594432      input_311[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_466 (LSTM)                 (None, 240, 384)     1181184     lstm_465[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_467 (LSTM)                 (None, 384)          1181184     lstm_466[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_312 (InputLayer)          [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1240 (Dense)              (None, 128)          49280       lstm_467[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1243 (Dense)              (None, 128)          384         input_312[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1241 (Dense)              (None, 64)           8256        dense_1240[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1244 (Dense)              (None, 64)           8256        dense_1243[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1242 (Dense)              (None, 32)           2080        dense_1241[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1245 (Dense)              (None, 32)           2080        dense_1244[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_155 (Concatenate)   (None, 64)           0           dense_1242[0][0]                 \n",
      "                                                                 dense_1245[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1246 (Dense)              (None, 8)            520         concatenate_155[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1247 (Dense)              (None, 1)            9           dense_1246[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_155 (Activation)     (None, 1)            0           dense_1247[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 3,027,665\n",
      "Trainable params: 3,027,665\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (28/32) *****\n",
      "Search({'dr1': 0.2, 'dr2': 0.2, 'dr3': 0.1, 'unit': 384, 'lr': 0.001, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.75745, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.75745\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.75745\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.75745\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.75745\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.75745 to 0.76498, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.76498\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.76498 to 0.80147, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.80147\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.80147\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.80147\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.80147\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.80147\n",
      "\n",
      "Epoch 00014: val_accuracy improved from 0.80147 to 0.80198, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.80198\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.80198\n",
      "\n",
      "Epoch 00017: val_accuracy improved from 0.80198 to 0.82809, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.82809\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.82809\n",
      "\n",
      "Epoch 00020: val_accuracy improved from 0.82809 to 0.82993, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.82993\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.82993\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.82993\n",
      "\n",
      "Epoch 00024: val_accuracy improved from 0.82993 to 0.84098, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.84098\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.84098\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.84533\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.84533\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.84533\n",
      "\n",
      "Epoch 00034: val_accuracy improved from 0.84533 to 0.84885, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.84885\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.84885\n",
      "\n",
      "Epoch 00037: val_accuracy improved from 0.84885 to 0.85504, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.85504\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.85504\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.85504\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.85504\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.85504\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.85504\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.85504\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.85504\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.85504\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.85504\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.85504\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.85504\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.85504\n",
      "SCORE: 0.85504 at epoch 37\n",
      "Compilation Time :  0.002183198928833008\n",
      "Model: \"model_156\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_313 (InputLayer)          [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_468 (LSTM)                 (None, 240, 256)     265216      input_313[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_469 (LSTM)                 (None, 240, 256)     525312      lstm_468[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_470 (LSTM)                 (None, 256)          525312      lstm_469[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_314 (InputLayer)          [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1248 (Dense)              (None, 128)          32896       lstm_470[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1251 (Dense)              (None, 128)          384         input_314[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1249 (Dense)              (None, 64)           8256        dense_1248[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1252 (Dense)              (None, 64)           8256        dense_1251[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1250 (Dense)              (None, 32)           2080        dense_1249[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1253 (Dense)              (None, 32)           2080        dense_1252[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_156 (Concatenate)   (None, 64)           0           dense_1250[0][0]                 \n",
      "                                                                 dense_1253[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1254 (Dense)              (None, 8)            520         concatenate_156[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1255 (Dense)              (None, 1)            9           dense_1254[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_156 (Activation)     (None, 1)            0           dense_1255[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 1,370,321\n",
      "Trainable params: 1,370,321\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (29/32) *****\n",
      "Search({'dr1': 0.2, 'dr2': 0.2, 'dr3': 0.2, 'unit': 256, 'lr': 0.01, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.70221, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.70221\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.70221 to 0.74757, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.74757\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.74757\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.74757\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.74757\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.74757\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.74757\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.74757\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.74757 to 0.75594, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.75594\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.75594\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.75594\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.75594\n",
      "\n",
      "Epoch 00016: val_accuracy improved from 0.75594 to 0.76247, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.76247\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.76247\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.76247\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.76247\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.76247\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.76247\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.76247\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.76247\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.76247\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.76247\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.76247\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.76247\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.76247\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.76247\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.76247\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.76247\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.76247\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.76247\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.76247\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.76247\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.76247\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.76247\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.76247\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.76247\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.76247\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.76247\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.76247\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.76247\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.76247\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.76247\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.76247\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.76247\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.76247\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.76247\n",
      "SCORE: 0.76247 at epoch 16\n",
      "Compilation Time :  0.0021860599517822266\n",
      "Model: \"model_157\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_315 (InputLayer)          [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_471 (LSTM)                 (None, 240, 256)     265216      input_315[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_472 (LSTM)                 (None, 240, 256)     525312      lstm_471[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_473 (LSTM)                 (None, 256)          525312      lstm_472[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_316 (InputLayer)          [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1256 (Dense)              (None, 128)          32896       lstm_473[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1259 (Dense)              (None, 128)          384         input_316[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1257 (Dense)              (None, 64)           8256        dense_1256[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1260 (Dense)              (None, 64)           8256        dense_1259[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1258 (Dense)              (None, 32)           2080        dense_1257[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1261 (Dense)              (None, 32)           2080        dense_1260[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_157 (Concatenate)   (None, 64)           0           dense_1258[0][0]                 \n",
      "                                                                 dense_1261[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1262 (Dense)              (None, 8)            520         concatenate_157[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1263 (Dense)              (None, 1)            9           dense_1262[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_157 (Activation)     (None, 1)            0           dense_1263[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 1,370,321\n",
      "Trainable params: 1,370,321\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (30/32) *****\n",
      "Search({'dr1': 0.2, 'dr2': 0.2, 'dr3': 0.2, 'unit': 256, 'lr': 0.001, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.74021, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.74021 to 0.75829, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.75829\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.75829\n",
      "\n",
      "Epoch 00005: val_accuracy improved from 0.75829 to 0.78992, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.78992\n",
      "\n",
      "Epoch 00007: val_accuracy improved from 0.78992 to 0.81319, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.81319\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.81319\n",
      "\n",
      "Epoch 00010: val_accuracy improved from 0.81319 to 0.82139, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.82139\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.82139\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.82139\n",
      "\n",
      "Epoch 00014: val_accuracy improved from 0.82139 to 0.82541, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.82541\n",
      "\n",
      "Epoch 00016: val_accuracy improved from 0.82541 to 0.83428, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.83428\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.83428\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.83428\n",
      "\n",
      "Epoch 00020: val_accuracy improved from 0.83428 to 0.84349, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00021: val_accuracy improved from 0.84349 to 0.85069, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.85069\n",
      "\n",
      "Epoch 00023: val_accuracy improved from 0.85069 to 0.85169, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.85169\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.85169\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.85169\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.85169\n",
      "\n",
      "Epoch 00028: val_accuracy improved from 0.85169 to 0.85203, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00029: val_accuracy improved from 0.85203 to 0.85705, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.85705\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.85705\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.85705\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.85705\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.85705\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.85705\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.85705\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.85705\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.85705\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.85705\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.85705\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.85705\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.85705\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.85705\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.85705\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.85705\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.85705\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.85705\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.85705\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.85705\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.85705\n",
      "SCORE: 0.85705 at epoch 29\n",
      "Compilation Time :  0.0021893978118896484\n",
      "Model: \"model_158\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_317 (InputLayer)          [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_474 (LSTM)                 (None, 240, 384)     594432      input_317[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_475 (LSTM)                 (None, 240, 384)     1181184     lstm_474[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_476 (LSTM)                 (None, 384)          1181184     lstm_475[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_318 (InputLayer)          [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1264 (Dense)              (None, 128)          49280       lstm_476[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1267 (Dense)              (None, 128)          384         input_318[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1265 (Dense)              (None, 64)           8256        dense_1264[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1268 (Dense)              (None, 64)           8256        dense_1267[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1266 (Dense)              (None, 32)           2080        dense_1265[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1269 (Dense)              (None, 32)           2080        dense_1268[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_158 (Concatenate)   (None, 64)           0           dense_1266[0][0]                 \n",
      "                                                                 dense_1269[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1270 (Dense)              (None, 8)            520         concatenate_158[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1271 (Dense)              (None, 1)            9           dense_1270[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_158 (Activation)     (None, 1)            0           dense_1271[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 3,027,665\n",
      "Trainable params: 3,027,665\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (31/32) *****\n",
      "Search({'dr1': 0.2, 'dr2': 0.2, 'dr3': 0.2, 'unit': 384, 'lr': 0.01, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.61801, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.61801 to 0.62169, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.62169 to 0.63157, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.63157\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.63157\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.63157\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.63157\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.63157 to 0.65367, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.65367\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.65367\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.65367\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.65367\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.65367\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.65367\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.65367\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.65367\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.65367\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.65367\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.65367\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.65367\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.65367\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.65367\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.65367\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.65367\n",
      "\n",
      "Epoch 00025: val_accuracy did not improve from 0.65367\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.65367\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.65367\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.65367\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.65367\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.65367\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.65367\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.65367\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.65367\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.65367\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.65367\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.65367\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.65367\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.65367\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.65367\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.65367\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.65367\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.65367\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.65367\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.65367\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.65367\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.65367\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.65367\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.65367\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.65367\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.65367\n",
      "SCORE: 0.65367 at epoch 8\n",
      "Compilation Time :  0.002216815948486328\n",
      "Model: \"model_159\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_319 (InputLayer)          [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_477 (LSTM)                 (None, 240, 384)     594432      input_319[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_478 (LSTM)                 (None, 240, 384)     1181184     lstm_477[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_479 (LSTM)                 (None, 384)          1181184     lstm_478[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_320 (InputLayer)          [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1272 (Dense)              (None, 128)          49280       lstm_479[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1275 (Dense)              (None, 128)          384         input_320[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1273 (Dense)              (None, 64)           8256        dense_1272[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1276 (Dense)              (None, 64)           8256        dense_1275[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1274 (Dense)              (None, 32)           2080        dense_1273[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1277 (Dense)              (None, 32)           2080        dense_1276[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_159 (Concatenate)   (None, 64)           0           dense_1274[0][0]                 \n",
      "                                                                 dense_1277[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1278 (Dense)              (None, 8)            520         concatenate_159[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1279 (Dense)              (None, 1)            9           dense_1278[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_159 (Activation)     (None, 1)            0           dense_1279[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 3,027,665\n",
      "Trainable params: 3,027,665\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "\n",
      "***** (32/32) *****\n",
      "Search({'dr1': 0.2, 'dr2': 0.2, 'dr3': 0.2, 'unit': 384, 'lr': 0.001, 'epochs': 50, 'batch_size': 64})\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.65886, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.65886 to 0.74037, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.74037 to 0.76515, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.76515\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.76515\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.76515\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.76515\n",
      "\n",
      "Epoch 00008: val_accuracy improved from 0.76515 to 0.76883, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00009: val_accuracy improved from 0.76883 to 0.78189, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.78189\n",
      "\n",
      "Epoch 00011: val_accuracy improved from 0.78189 to 0.83796, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.83796\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.83796\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.83796\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.83796\n",
      "\n",
      "Epoch 00016: val_accuracy did not improve from 0.83796\n",
      "\n",
      "Epoch 00017: val_accuracy did not improve from 0.83796\n",
      "\n",
      "Epoch 00018: val_accuracy did not improve from 0.83796\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.83796\n",
      "\n",
      "Epoch 00020: val_accuracy improved from 0.83796 to 0.84014, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.84014\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.84014\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.84014\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.84014\n",
      "\n",
      "Epoch 00025: val_accuracy improved from 0.84014 to 0.85236, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.85236\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.85236\n",
      "\n",
      "Epoch 00028: val_accuracy improved from 0.85236 to 0.86341, saving model to hyper_tuning.h5\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.86341\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.86341\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.86341\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.86341\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.86341\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.86341\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.86341\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.86341\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.86341\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.86341\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.86341\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.86341\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.86341\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.86341\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.86341\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.86341\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.86341\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.86341\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.86341\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.86341\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.86341\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.86341\n",
      "SCORE: 0.86341 at epoch 28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>best_score</th>\n",
       "      <th>best_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>our_model</td>\n",
       "      <td>{'fold 1': 0.86828, 'fold 2': 0.86728, 'fold 3': 0.8723, 'fold 4': 0.86173, 'fold 5': 0.86374}</td>\n",
       "      <td>{'fold 1': {'dr1': 0.1, 'dr2': 0.1, 'dr3': 0.2, 'unit': 384, 'lr': 0.001, 'epochs': 44, 'batch_size': 64, 'steps_per_epoch': 374}, 'fold 2': {'dr1': 0.1, 'dr2': 0.1, 'dr3': 0.2, 'unit': 384, 'lr': 0.001, 'epochs': 38, 'batch_size': 64, 'steps_per_epoch': 374}, 'fold 3': {'dr1': 0.1, 'dr2': 0.2, 'dr3': 0.1, 'unit': 384, 'lr': 0.001, 'epochs': 41, 'batch_size': 64, 'steps_per_epoch': 374}, 'fold 4': {'dr1': 0.1, 'dr2': 0.1, 'dr3': 0.1, 'unit': 256, 'lr': 0.001, 'epochs': 30, 'batch_size': 64, 'steps_per_epoch': 374}, 'fold 5': {'dr1': 0.1, 'dr2': 0.1, 'dr3': 0.1, 'unit': 256, 'lr': 0.001, 'epochs': 32, 'batch_size': 64, 'steps_per_epoch': 374}}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       model  \\\n",
       "0  our_model   \n",
       "\n",
       "                                                                                       best_score  \\\n",
       "0  {'fold 1': 0.86828, 'fold 2': 0.86728, 'fold 3': 0.8723, 'fold 4': 0.86173, 'fold 5': 0.86374}   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  best_params  \n",
       "0  {'fold 1': {'dr1': 0.1, 'dr2': 0.1, 'dr3': 0.2, 'unit': 384, 'lr': 0.001, 'epochs': 44, 'batch_size': 64, 'steps_per_epoch': 374}, 'fold 2': {'dr1': 0.1, 'dr2': 0.1, 'dr3': 0.2, 'unit': 384, 'lr': 0.001, 'epochs': 38, 'batch_size': 64, 'steps_per_epoch': 374}, 'fold 3': {'dr1': 0.1, 'dr2': 0.2, 'dr3': 0.1, 'unit': 384, 'lr': 0.001, 'epochs': 41, 'batch_size': 64, 'steps_per_epoch': 374}, 'fold 4': {'dr1': 0.1, 'dr2': 0.1, 'dr3': 0.1, 'unit': 256, 'lr': 0.001, 'epochs': 30, 'batch_size': 64, 'steps_per_epoch': 374}, 'fold 5': {'dr1': 0.1, 'dr2': 0.1, 'dr3': 0.1, 'unit': 256, 'lr': 0.001, 'epochs': 32, 'batch_size': 64, 'steps_per_epoch': 374}}  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # greater_is_better : bool, default=False\n",
    " #        Whether the quantity to monitor is a score function, meaning high\n",
    " #        is good, or a loss function (as default), meaning low is good.\n",
    "scores = []\n",
    "log_dir = \"logs/hp/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "mc = ModelCheckpoint('hyper_tuning.h5', monitor='val_accuracy', verbose=1, save_best_only=True)\n",
    "\n",
    "for model_name, mp in model_params.items():\n",
    "    kgs = KerasGridSearchCV(mp['model'], mp['params'], cv=cv, monitor='val_accuracy', greater_is_better=True)\n",
    "    kgs.search([X_train1,X_train2], y_train, callbacks=[tensorboard_callback, mc])\n",
    "    scores.append({\n",
    "        'model': model_name,\n",
    "        'best_score': kgs.folds_best_score,\n",
    "        'best_params': kgs.folds_best_params\n",
    "    })\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "df = pd.DataFrame(scores,columns=['model','best_score','best_params'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fold 1': {'dr1': 0.1,\n",
       "  'dr2': 0.1,\n",
       "  'dr3': 0.2,\n",
       "  'unit': 384,\n",
       "  'lr': 0.001,\n",
       "  'epochs': 44,\n",
       "  'batch_size': 64,\n",
       "  'steps_per_epoch': 374},\n",
       " 'fold 2': {'dr1': 0.1,\n",
       "  'dr2': 0.1,\n",
       "  'dr3': 0.2,\n",
       "  'unit': 384,\n",
       "  'lr': 0.001,\n",
       "  'epochs': 38,\n",
       "  'batch_size': 64,\n",
       "  'steps_per_epoch': 374},\n",
       " 'fold 3': {'dr1': 0.1,\n",
       "  'dr2': 0.2,\n",
       "  'dr3': 0.1,\n",
       "  'unit': 384,\n",
       "  'lr': 0.001,\n",
       "  'epochs': 41,\n",
       "  'batch_size': 64,\n",
       "  'steps_per_epoch': 374},\n",
       " 'fold 4': {'dr1': 0.1,\n",
       "  'dr2': 0.1,\n",
       "  'dr3': 0.1,\n",
       "  'unit': 256,\n",
       "  'lr': 0.001,\n",
       "  'epochs': 30,\n",
       "  'batch_size': 64,\n",
       "  'steps_per_epoch': 374},\n",
       " 'fold 5': {'dr1': 0.1,\n",
       "  'dr2': 0.1,\n",
       "  'dr3': 0.1,\n",
       "  'unit': 256,\n",
       "  'lr': 0.001,\n",
       "  'epochs': 32,\n",
       "  'batch_size': 64,\n",
       "  'steps_per_epoch': 374}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kgs.folds_best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### kgs.folds_best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-train with the best hyper-paremeters and test on the val-set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter Number of Epochs (or enter default 1000):  8\n"
     ]
    }
   ],
   "source": [
    "epochs = int(input('Enter Number of Epochs (or enter default 1000): '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    # The number of hidden units is a direct representation of the learning capacity of a neural network -- it reflects the number of learned parameters. \n",
    "    # The value 256 was selected arbitrarily or empirically \n",
    "    layers = {'input': 2, 'hidden1': 378, 'hidden2': 378, 'hidden3':378, 'output': 1}\n",
    "    # sequence_length is the timestep (Tx) ( a 1' window)\n",
    "    #The `Input()` layer is used for defining the input `X` as well as the initial hidden state 'a0' and cell state `c0`.\n",
    "    #The `shape` parameter takes a tuple that does not include the batch dimension (`m`).\n",
    "    #Samples. One sequence is one sample. A batch is comprised of one or more samples.\n",
    "    #Time Steps. One time step is one point of observation in the sample.\n",
    "    #Features. One feature is one observation at a time step.\n",
    "    #shape=(240,2) indicates that the expected input will be batches of 240-dimensional vectors, and 2 input features (RRI + R-peak amplitude)\n",
    "    x1 = tf.keras.layers.Input(shape=(sequence_length, layers['input']))\n",
    "    \n",
    "    #units (256)- dimensionality of the output space.\n",
    "    #fraction of the units to drop for the linear transformation of the recurrent state = 0.5\n",
    "    # return sequences return the hidden state output for each input time step (many-to-many)\n",
    "    m1 = tf.keras.layers.LSTM(layers['hidden1'],\n",
    "                              use_bias=True,\n",
    "                              dropout=0.1,\n",
    "                    recurrent_dropout=0,\n",
    "                   return_sequences=True)(x1)\n",
    "    m1 = tf.keras.layers.LSTM(\n",
    "            layers['hidden2'],\n",
    "            use_bias=True,\n",
    "            dropout=0.2,\n",
    "            recurrent_dropout=0,\n",
    "            return_sequences=True)(m1)\n",
    "\n",
    "    m1 = tf.keras.layers.LSTM(\n",
    "            layers['hidden3'],\n",
    "            use_bias=True,\n",
    "            dropout=0.2,\n",
    "            recurrent_dropout=0,\n",
    "            return_sequences=False)(m1)\n",
    "\n",
    "    m1 = tf.keras.layers.Dense(128)(m1)\n",
    "    m1 = tf.keras.layers.Dense(64)(m1)\n",
    "    m1 = tf.keras.layers.Dense(32)(m1)\n",
    "    \n",
    "    x2 = tf.keras.layers.Input(shape=(2,))\n",
    "    m2 = tf.keras.layers.Dense(128)(x2)\n",
    "    m2 = tf.keras.layers.Dense(64)(m2) \n",
    "    m2 = tf.keras.layers.Dense(32)(m2)\n",
    "    #merged = Merge([model1, model2], mode='concat')\n",
    "    merged = tf.keras.layers.Concatenate(axis=1)([m1, m2])\n",
    "\n",
    "    out = tf.keras.layers.Dense(8)(merged)\n",
    "    out = tf.keras.layers.Dense(layers['output'], kernel_initializer='normal')(out)\n",
    "    out = tf.keras.layers.Activation(\"sigmoid\")(out)\n",
    "    \n",
    "    model = tf.keras.models.Model(inputs=[x1, x2], outputs=[out])\n",
    "\n",
    "    start = time.time()\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                  metrics=\"accuracy\")\n",
    "    print (\"Compilation Time : \", time.time() - start)\n",
    "    \n",
    "    #he None dimension in the shape tuple refers to the batch dimension which simply means that the layer can accept input of any size.\n",
    "    # plot_model(model, to_file='model_plot_quoc.png', show_shapes=True, show_layer_names=True)\n",
    "    \n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.80411844 1.32204815]\n",
      "Compilation Time :  0.0023360252380371094\n",
      "Model: \"model_8\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_17 (InputLayer)           [(None, 240, 2)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_24 (LSTM)                  (None, 240, 378)     576072      input_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_25 (LSTM)                  (None, 240, 378)     1144584     lstm_24[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_26 (LSTM)                  (None, 378)          1144584     lstm_25[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_18 (InputLayer)           [(None, 2)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_64 (Dense)                (None, 128)          48512       lstm_26[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_67 (Dense)                (None, 128)          384         input_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_65 (Dense)                (None, 64)           8256        dense_64[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_68 (Dense)                (None, 64)           8256        dense_67[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_66 (Dense)                (None, 32)           2080        dense_65[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_69 (Dense)                (None, 32)           2080        dense_68[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 64)           0           dense_66[0][0]                   \n",
      "                                                                 dense_69[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_70 (Dense)                (None, 8)            520         concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_71 (Dense)                (None, 1)            9           dense_70[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 1)            0           dense_71[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 2,935,337\n",
      "Trainable params: 2,935,337\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Training\n",
      "Epoch 1/8\n",
      "467/467 [==============================] - 31s 62ms/step - loss: 0.5412 - accuracy: 0.7267\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "Epoch 2/8\n",
      "467/467 [==============================] - 28s 60ms/step - loss: 0.4800 - accuracy: 0.7747\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "Epoch 3/8\n",
      "467/467 [==============================] - 28s 60ms/step - loss: 0.4550 - accuracy: 0.7850\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "Epoch 4/8\n",
      "467/467 [==============================] - 28s 60ms/step - loss: 0.4316 - accuracy: 0.7953\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "Epoch 5/8\n",
      "467/467 [==============================] - 28s 60ms/step - loss: 0.4167 - accuracy: 0.8057\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "Epoch 6/8\n",
      "467/467 [==============================] - 28s 60ms/step - loss: 0.3982 - accuracy: 0.8173\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "Epoch 7/8\n",
      "467/467 [==============================] - 28s 60ms/step - loss: 0.3818 - accuracy: 0.8267\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "Epoch 8/8\n",
      "467/467 [==============================] - 28s 60ms/step - loss: 0.3791 - accuracy: 0.8289\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "Training duration (s) :  230.75260043144226\n"
     ]
    }
   ],
   "source": [
    "\n",
    "global_start_time = time.time()\n",
    "\n",
    "class_w = class_weight.compute_class_weight('balanced',\n",
    "                                                 np.unique(y_train),\n",
    "                                                 y_train)\n",
    "\n",
    "print (class_w)\n",
    "\n",
    "# if model is None:\n",
    "model = build_model()\n",
    "\n",
    "try:\n",
    "    print(\"Training\")\n",
    "\n",
    "    log_dir = \"logs/hp/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "    # simple early stopping\n",
    "    \n",
    "    # es = EarlyStopping(monitor='accuracy', mode='max', verbose=1, patience=35)\n",
    "    mc = ModelCheckpoint('hyper_tuning.h5', monitor='val_accuracy', verbose=1, save_best_only=True)\n",
    "\n",
    "    class_w = {i : class_w[i] for i in range(2)}\n",
    "    history = model.fit([X_train1, X_train2], y_train, epochs=epochs, batch_size=64, class_weight=class_w, callbacks=[tensorboard_callback, mc])\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"prediction exception\")\n",
    "    print ('Training duration (s) : ', time.time() - global_start_time)\n",
    "    # model.save(\"break_my_model_400.h5\") \n",
    "#     return model\n",
    "print ('Training duration (s) : ', time.time() - global_start_time)\n",
    "# model.save(\"my_model_80.h5\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104/104 [==============================] - 3s 20ms/step - loss: 0.3800 - accuracy: 0.8250\n",
      "accuracy: 82.50%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Model\n",
    "y_pred = (model.predict([X_test1, X_test2]) >= 0.50).astype(int)\n",
    "scores = model.evaluate([X_test1, X_test2], y_test)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot = True, fmt=\"d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FPR:  (778,)\n",
      "TPR:  (778,)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(778,)\n"
     ]
    }
   ],
   "source": [
    "y_preds = model.predict([X_test1, X_test2]).ravel()\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_preds)\n",
    "print(\"FPR: \", fpr.shape)\n",
    "print(\"TPR: \", tpr.shape)\n",
    "\n",
    "plt.figure(1)\n",
    "plt.plot([0,1], [0,1], 'y--')\n",
    "plt.plot(fpr, tpr, marker='x')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.show()\n",
    "print(thresholds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9161081776527322"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc_value = auc(fpr, tpr)\n",
    "auc_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save fpr, tpr into files\n",
    "with open('roc_log/sad/fpr2.npy', 'wb') as f:\n",
    "    np.save(f, fpr)\n",
    "with open('roc_log/sad/tpr2.npy', 'wb') as f:\n",
    "    np.save(f, tpr)\n",
    "with open('roc_log/sad/auc2.npy', 'wb') as f:\n",
    "    np.save(f, auc_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('roc_log/sad/auc1.npy', 'rb') as f:\n",
    "    auc1 = np.load(f)\n",
    "with open('roc_log/sad/auc2.npy', 'rb') as f:\n",
    "    auc2 = np.load(f)\n",
    "with open('roc_log/sad/auc3.npy', 'rb') as f:\n",
    "    auc3 = np.load(f)\n",
    "with open('roc_log/sad/auc4.npy', 'rb') as f:\n",
    "    auc4 = np.load(f)\n",
    "with open('roc_log/sad/auc5.npy', 'rb') as f:\n",
    "    auc5 = np.load(f)\n",
    "\n",
    "with open('roc_log/sad/fpr1.npy', 'rb') as f:\n",
    "    fpr1 = np.load(f)\n",
    "with open('roc_log/sad/fpr2.npy', 'rb') as f:\n",
    "    fpr2 = np.load(f)\n",
    "with open('roc_log/sad/fpr3.npy', 'rb') as f:\n",
    "    fpr3 = np.load(f)\n",
    "with open('roc_log/sad/fpr4.npy', 'rb') as f:\n",
    "    fpr4 = np.load(f)\n",
    "with open('roc_log/sad/fpr5.npy', 'rb') as f:\n",
    "    fpr5 = np.load(f)\n",
    "    \n",
    "with open('roc_log/sad/tpr1.npy', 'rb') as f:\n",
    "    tpr1 = np.load(f)\n",
    "with open('roc_log/sad/tpr2.npy', 'rb') as f:\n",
    "    tpr2 = np.load(f)\n",
    "with open('roc_log/sad/tpr3.npy', 'rb') as f:\n",
    "    tpr3 = np.load(f)\n",
    "with open('roc_log/sad/tpr4.npy', 'rb') as f:\n",
    "    tpr4 = np.load(f)\n",
    "with open('roc_log/sad/tpr5.npy', 'rb') as f:\n",
    "    tpr5 = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "aucs = []\n",
    "\n",
    "aucs.append(auc1)\n",
    "aucs.append(auc2)\n",
    "aucs.append(auc3)\n",
    "aucs.append(auc4)\n",
    "aucs.append(auc5)\n",
    "print(len(aucs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interpolate fpr , tpr to the same scale\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "tprs = []\n",
    "\n",
    "interp_tpr = np.interp(mean_fpr, fpr1, tpr1)\n",
    "interp_tpr[0] = 0.0\n",
    "tprs.append(interp_tpr)\n",
    "\n",
    "interp_tpr = np.interp(mean_fpr, fpr2, tpr2)\n",
    "interp_tpr[0] = 0.0\n",
    "tprs.append(interp_tpr)\n",
    "\n",
    "interp_tpr = np.interp(mean_fpr, fpr3, tpr3)\n",
    "interp_tpr[0] = 0.0\n",
    "tprs.append(interp_tpr)\n",
    "\n",
    "interp_tpr = np.interp(mean_fpr, fpr4, tpr4)\n",
    "interp_tpr[0] = 0.0\n",
    "tprs.append(interp_tpr)\n",
    "\n",
    "interp_tpr = np.interp(mean_fpr, fpr5, tpr5)\n",
    "interp_tpr[0] = 0.0\n",
    "tprs.append(interp_tpr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array(0.92662742), array(0.91610818), array(0.93296529), array(0.92242507), array(0.8749473)]\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "print(aucs)\n",
    "print(len(tprs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# fig, ax = plt.subplots()\n",
    "plt.plot([0, 1], [0, 1], linestyle=\"--\", lw=2, color=\"r\", label=\"\", alpha=0.5)\n",
    "\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "std_auc = np.std(aucs)\n",
    "\n",
    "plt.plot(\n",
    "    mean_fpr,\n",
    "    mean_tpr,\n",
    "    color=\"b\",\n",
    "    label=r\"Mean ROC (AUC = %0.2f $\\pm$ %0.2f)\" % (mean_auc, std_auc),\n",
    "    lw=2,\n",
    "    alpha=0.8,\n",
    "    # marker='x'\n",
    ")\n",
    "plt.plot(\n",
    "    fpr1,\n",
    "    tpr1,\n",
    "    \n",
    "    label=r\"Fold 1 ROC (AUC = %0.2f)\" % (auc1),\n",
    "    lw=1,\n",
    "    alpha=0.3,\n",
    ")\n",
    "plt.plot(\n",
    "    fpr5,\n",
    "    tpr5,\n",
    "    \n",
    "    label=r\"Fold 2 ROC (AUC = %0.2f)\" % (auc2),\n",
    "    lw=1,\n",
    "    alpha=0.3,\n",
    ")\n",
    "plt.plot(\n",
    "    fpr3,\n",
    "    tpr3,\n",
    "    \n",
    "    label=r\"Fold 3 ROC (AUC = %0.2f)\" % (auc3),\n",
    "    lw=1,\n",
    "    alpha=0.3,\n",
    ")\n",
    "plt.plot(\n",
    "    fpr4,\n",
    "    tpr4,\n",
    "    \n",
    "    label=r\"Fold 4 ROC (AUC = %0.2f)\" % (auc4),\n",
    "    lw=1,\n",
    "    alpha=0.3,\n",
    ")\n",
    "plt.plot(\n",
    "    fpr5,\n",
    "    tpr5,\n",
    "    \n",
    "    label=r\"Fold 5 ROC (AUC = %0.2f)\" % (auc5),\n",
    "    lw=1,\n",
    "    alpha=0.3,\n",
    ")\n",
    "# std_tpr = 0.05\n",
    "std_tpr = np.std(tprs, axis=0)\n",
    "# print(\"std: \", std_tpr)\n",
    "tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "plt.fill_between(\n",
    "    mean_fpr,\n",
    "    tprs_lower,\n",
    "    tprs_upper,\n",
    "    color=\"grey\",\n",
    "    alpha=0.2,\n",
    "    label=\"\",\n",
    ")\n",
    "\n",
    "# Title\n",
    "# plt.title('ROC Plot')\n",
    "# Axis labels\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "# Show legend\n",
    "plt.legend() # \n",
    "plt.savefig('5_fold_ROC_plot_SAD.pdf')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0c8b2d4de26fa1c636f00324ff9f96f6d8cbc199785d8af2b0d8586b59b42196"
  },
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
